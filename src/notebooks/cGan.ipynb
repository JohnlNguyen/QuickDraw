{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "channels = 1\n",
    "img_size = 28\n",
    "n_classes = 10\n",
    "latent_dim = 100\n",
    "batch_size = 32\n",
    "learning_rate = .0002\n",
    "b1 = .5\n",
    "b2 = .999\n",
    "sample_interval = 1\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [  nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim+n_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.label_embedding = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image to produce input\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row**2, latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, 'images/%d.png' % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickDrawDataset(Dataset):\n",
    "    \"\"\"Quick Draw dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, label, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = np.load(f'data/{label}.npy')\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data_frame[idx]\n",
    "        label = self.label\n",
    "        return image, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = QuickDrawDataset(label='panda', transform=transforms.Compose([\n",
    "                        transforms.Resize(img_size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
    "dataloader = DataLoader(data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 0/3551] [D loss: 83.517715] [G loss: 1.003725]\n",
      "[Epoch 0/1] [Batch 1/3551] [D loss: 52.275719] [G loss: 1.031304]\n",
      "[Epoch 0/1] [Batch 2/3551] [D loss: 19.278305] [G loss: 1.021687]\n",
      "[Epoch 0/1] [Batch 3/3551] [D loss: 14.314573] [G loss: 1.012913]\n",
      "[Epoch 0/1] [Batch 4/3551] [D loss: 24.394438] [G loss: 1.013031]\n",
      "[Epoch 0/1] [Batch 5/3551] [D loss: 12.876037] [G loss: 1.005726]\n",
      "[Epoch 0/1] [Batch 6/3551] [D loss: 17.008179] [G loss: 1.012735]\n",
      "[Epoch 0/1] [Batch 7/3551] [D loss: 13.743367] [G loss: 0.999223]\n",
      "[Epoch 0/1] [Batch 8/3551] [D loss: 21.078283] [G loss: 1.003845]\n",
      "[Epoch 0/1] [Batch 9/3551] [D loss: 8.406813] [G loss: 1.000113]\n",
      "[Epoch 0/1] [Batch 10/3551] [D loss: 8.706357] [G loss: 1.003444]\n",
      "[Epoch 0/1] [Batch 11/3551] [D loss: 12.011793] [G loss: 1.003147]\n",
      "[Epoch 0/1] [Batch 12/3551] [D loss: 12.344916] [G loss: 0.996042]\n",
      "[Epoch 0/1] [Batch 13/3551] [D loss: 7.106085] [G loss: 0.993984]\n",
      "[Epoch 0/1] [Batch 14/3551] [D loss: 6.892169] [G loss: 0.991791]\n",
      "[Epoch 0/1] [Batch 15/3551] [D loss: 9.185846] [G loss: 0.982173]\n",
      "[Epoch 0/1] [Batch 16/3551] [D loss: 8.606138] [G loss: 0.986429]\n",
      "[Epoch 0/1] [Batch 17/3551] [D loss: 12.518778] [G loss: 0.981989]\n",
      "[Epoch 0/1] [Batch 18/3551] [D loss: 6.082804] [G loss: 0.983376]\n",
      "[Epoch 0/1] [Batch 19/3551] [D loss: 6.249016] [G loss: 0.983909]\n",
      "[Epoch 0/1] [Batch 20/3551] [D loss: 8.771636] [G loss: 0.984597]\n",
      "[Epoch 0/1] [Batch 21/3551] [D loss: 3.710815] [G loss: 0.985258]\n",
      "[Epoch 0/1] [Batch 22/3551] [D loss: 4.911325] [G loss: 0.977358]\n",
      "[Epoch 0/1] [Batch 23/3551] [D loss: 6.657351] [G loss: 0.976455]\n",
      "[Epoch 0/1] [Batch 24/3551] [D loss: 8.072594] [G loss: 0.977352]\n",
      "[Epoch 0/1] [Batch 25/3551] [D loss: 7.496088] [G loss: 0.982385]\n",
      "[Epoch 0/1] [Batch 26/3551] [D loss: 7.542504] [G loss: 0.977966]\n",
      "[Epoch 0/1] [Batch 27/3551] [D loss: 5.799263] [G loss: 0.971551]\n",
      "[Epoch 0/1] [Batch 28/3551] [D loss: 7.968454] [G loss: 0.975332]\n",
      "[Epoch 0/1] [Batch 29/3551] [D loss: 4.735859] [G loss: 0.969110]\n",
      "[Epoch 0/1] [Batch 30/3551] [D loss: 5.578117] [G loss: 0.957909]\n",
      "[Epoch 0/1] [Batch 31/3551] [D loss: 4.207908] [G loss: 0.960934]\n",
      "[Epoch 0/1] [Batch 32/3551] [D loss: 8.197473] [G loss: 0.963624]\n",
      "[Epoch 0/1] [Batch 33/3551] [D loss: 3.103297] [G loss: 0.960329]\n",
      "[Epoch 0/1] [Batch 34/3551] [D loss: 8.671994] [G loss: 0.951512]\n",
      "[Epoch 0/1] [Batch 35/3551] [D loss: 4.891998] [G loss: 0.949781]\n",
      "[Epoch 0/1] [Batch 36/3551] [D loss: 6.052252] [G loss: 0.949812]\n",
      "[Epoch 0/1] [Batch 37/3551] [D loss: 4.587634] [G loss: 0.934873]\n",
      "[Epoch 0/1] [Batch 38/3551] [D loss: 4.926575] [G loss: 0.930568]\n",
      "[Epoch 0/1] [Batch 39/3551] [D loss: 9.433059] [G loss: 0.931154]\n",
      "[Epoch 0/1] [Batch 40/3551] [D loss: 3.091114] [G loss: 0.935761]\n",
      "[Epoch 0/1] [Batch 41/3551] [D loss: 4.435677] [G loss: 0.930475]\n",
      "[Epoch 0/1] [Batch 42/3551] [D loss: 3.530798] [G loss: 0.917580]\n",
      "[Epoch 0/1] [Batch 43/3551] [D loss: 3.740117] [G loss: 0.911952]\n",
      "[Epoch 0/1] [Batch 44/3551] [D loss: 3.650033] [G loss: 0.911986]\n",
      "[Epoch 0/1] [Batch 45/3551] [D loss: 2.959539] [G loss: 0.897452]\n",
      "[Epoch 0/1] [Batch 46/3551] [D loss: 6.202307] [G loss: 0.901936]\n",
      "[Epoch 0/1] [Batch 47/3551] [D loss: 5.151598] [G loss: 0.885324]\n",
      "[Epoch 0/1] [Batch 48/3551] [D loss: 3.089296] [G loss: 0.878427]\n",
      "[Epoch 0/1] [Batch 49/3551] [D loss: 4.149852] [G loss: 0.855771]\n",
      "[Epoch 0/1] [Batch 50/3551] [D loss: 5.347776] [G loss: 0.855413]\n",
      "[Epoch 0/1] [Batch 51/3551] [D loss: 3.766474] [G loss: 0.846160]\n",
      "[Epoch 0/1] [Batch 52/3551] [D loss: 3.017973] [G loss: 0.835496]\n",
      "[Epoch 0/1] [Batch 53/3551] [D loss: 4.710543] [G loss: 0.807417]\n",
      "[Epoch 0/1] [Batch 54/3551] [D loss: 2.804685] [G loss: 0.780210]\n",
      "[Epoch 0/1] [Batch 55/3551] [D loss: 1.740708] [G loss: 0.783949]\n",
      "[Epoch 0/1] [Batch 56/3551] [D loss: 2.395719] [G loss: 0.756955]\n",
      "[Epoch 0/1] [Batch 57/3551] [D loss: 3.239577] [G loss: 0.747581]\n",
      "[Epoch 0/1] [Batch 58/3551] [D loss: 3.097637] [G loss: 0.742018]\n",
      "[Epoch 0/1] [Batch 59/3551] [D loss: 3.122330] [G loss: 0.700279]\n",
      "[Epoch 0/1] [Batch 60/3551] [D loss: 4.142124] [G loss: 0.726567]\n",
      "[Epoch 0/1] [Batch 61/3551] [D loss: 1.926801] [G loss: 0.684750]\n",
      "[Epoch 0/1] [Batch 62/3551] [D loss: 3.508265] [G loss: 0.654028]\n",
      "[Epoch 0/1] [Batch 63/3551] [D loss: 3.134434] [G loss: 0.677153]\n",
      "[Epoch 0/1] [Batch 64/3551] [D loss: 4.543722] [G loss: 0.629562]\n",
      "[Epoch 0/1] [Batch 65/3551] [D loss: 2.008090] [G loss: 0.658396]\n",
      "[Epoch 0/1] [Batch 66/3551] [D loss: 1.210124] [G loss: 0.628611]\n",
      "[Epoch 0/1] [Batch 67/3551] [D loss: 4.408715] [G loss: 0.586682]\n",
      "[Epoch 0/1] [Batch 68/3551] [D loss: 2.790636] [G loss: 0.577766]\n",
      "[Epoch 0/1] [Batch 69/3551] [D loss: 1.516033] [G loss: 0.613084]\n",
      "[Epoch 0/1] [Batch 70/3551] [D loss: 1.699896] [G loss: 0.584307]\n",
      "[Epoch 0/1] [Batch 71/3551] [D loss: 1.964995] [G loss: 0.590973]\n",
      "[Epoch 0/1] [Batch 72/3551] [D loss: 2.445763] [G loss: 0.579934]\n",
      "[Epoch 0/1] [Batch 73/3551] [D loss: 3.960778] [G loss: 0.571988]\n",
      "[Epoch 0/1] [Batch 74/3551] [D loss: 2.877444] [G loss: 0.593512]\n",
      "[Epoch 0/1] [Batch 75/3551] [D loss: 1.716740] [G loss: 0.601357]\n",
      "[Epoch 0/1] [Batch 76/3551] [D loss: 2.703111] [G loss: 0.558013]\n",
      "[Epoch 0/1] [Batch 77/3551] [D loss: 2.342616] [G loss: 0.547284]\n",
      "[Epoch 0/1] [Batch 78/3551] [D loss: 2.415531] [G loss: 0.571005]\n",
      "[Epoch 0/1] [Batch 79/3551] [D loss: 2.106452] [G loss: 0.574440]\n",
      "[Epoch 0/1] [Batch 80/3551] [D loss: 2.452726] [G loss: 0.579565]\n",
      "[Epoch 0/1] [Batch 81/3551] [D loss: 1.661217] [G loss: 0.595339]\n",
      "[Epoch 0/1] [Batch 82/3551] [D loss: 2.391735] [G loss: 0.568184]\n",
      "[Epoch 0/1] [Batch 83/3551] [D loss: 2.633168] [G loss: 0.530828]\n",
      "[Epoch 0/1] [Batch 84/3551] [D loss: 2.496752] [G loss: 0.515720]\n",
      "[Epoch 0/1] [Batch 85/3551] [D loss: 0.919524] [G loss: 0.546658]\n",
      "[Epoch 0/1] [Batch 86/3551] [D loss: 2.259625] [G loss: 0.563397]\n",
      "[Epoch 0/1] [Batch 87/3551] [D loss: 1.699194] [G loss: 0.506735]\n",
      "[Epoch 0/1] [Batch 88/3551] [D loss: 2.480315] [G loss: 0.558905]\n",
      "[Epoch 0/1] [Batch 89/3551] [D loss: 2.381216] [G loss: 0.591814]\n",
      "[Epoch 0/1] [Batch 90/3551] [D loss: 3.112830] [G loss: 0.540219]\n",
      "[Epoch 0/1] [Batch 91/3551] [D loss: 1.783523] [G loss: 0.589562]\n",
      "[Epoch 0/1] [Batch 92/3551] [D loss: 1.219837] [G loss: 0.593889]\n",
      "[Epoch 0/1] [Batch 93/3551] [D loss: 2.300276] [G loss: 0.553893]\n",
      "[Epoch 0/1] [Batch 94/3551] [D loss: 1.483629] [G loss: 0.539527]\n",
      "[Epoch 0/1] [Batch 95/3551] [D loss: 1.246311] [G loss: 0.507162]\n",
      "[Epoch 0/1] [Batch 96/3551] [D loss: 1.700085] [G loss: 0.584495]\n",
      "[Epoch 0/1] [Batch 97/3551] [D loss: 2.447413] [G loss: 0.549433]\n",
      "[Epoch 0/1] [Batch 98/3551] [D loss: 1.484813] [G loss: 0.552452]\n",
      "[Epoch 0/1] [Batch 99/3551] [D loss: 1.560428] [G loss: 0.587369]\n",
      "[Epoch 0/1] [Batch 100/3551] [D loss: 1.525465] [G loss: 0.560661]\n",
      "[Epoch 0/1] [Batch 101/3551] [D loss: 1.181685] [G loss: 0.574352]\n",
      "[Epoch 0/1] [Batch 102/3551] [D loss: 2.272860] [G loss: 0.549730]\n",
      "[Epoch 0/1] [Batch 103/3551] [D loss: 1.680856] [G loss: 0.570644]\n",
      "[Epoch 0/1] [Batch 104/3551] [D loss: 0.911600] [G loss: 0.564526]\n",
      "[Epoch 0/1] [Batch 105/3551] [D loss: 2.209867] [G loss: 0.564886]\n",
      "[Epoch 0/1] [Batch 106/3551] [D loss: 2.319010] [G loss: 0.615512]\n",
      "[Epoch 0/1] [Batch 107/3551] [D loss: 1.548098] [G loss: 0.559582]\n",
      "[Epoch 0/1] [Batch 108/3551] [D loss: 1.802639] [G loss: 0.552818]\n",
      "[Epoch 0/1] [Batch 109/3551] [D loss: 1.266128] [G loss: 0.574955]\n",
      "[Epoch 0/1] [Batch 110/3551] [D loss: 1.512261] [G loss: 0.556366]\n",
      "[Epoch 0/1] [Batch 111/3551] [D loss: 1.439027] [G loss: 0.588172]\n",
      "[Epoch 0/1] [Batch 112/3551] [D loss: 1.529172] [G loss: 0.582161]\n",
      "[Epoch 0/1] [Batch 113/3551] [D loss: 1.881238] [G loss: 0.607279]\n",
      "[Epoch 0/1] [Batch 114/3551] [D loss: 2.190746] [G loss: 0.562803]\n",
      "[Epoch 0/1] [Batch 115/3551] [D loss: 1.106536] [G loss: 0.592511]\n",
      "[Epoch 0/1] [Batch 116/3551] [D loss: 2.134130] [G loss: 0.620938]\n",
      "[Epoch 0/1] [Batch 117/3551] [D loss: 0.799577] [G loss: 0.559667]\n",
      "[Epoch 0/1] [Batch 118/3551] [D loss: 1.548140] [G loss: 0.564925]\n",
      "[Epoch 0/1] [Batch 119/3551] [D loss: 1.272119] [G loss: 0.600281]\n",
      "[Epoch 0/1] [Batch 120/3551] [D loss: 1.426486] [G loss: 0.577884]\n",
      "[Epoch 0/1] [Batch 121/3551] [D loss: 1.014656] [G loss: 0.584005]\n",
      "[Epoch 0/1] [Batch 122/3551] [D loss: 1.557615] [G loss: 0.577014]\n",
      "[Epoch 0/1] [Batch 123/3551] [D loss: 1.174257] [G loss: 0.607108]\n",
      "[Epoch 0/1] [Batch 124/3551] [D loss: 1.478814] [G loss: 0.616798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 125/3551] [D loss: 1.494734] [G loss: 0.556255]\n",
      "[Epoch 0/1] [Batch 126/3551] [D loss: 1.230061] [G loss: 0.602888]\n",
      "[Epoch 0/1] [Batch 127/3551] [D loss: 0.992658] [G loss: 0.592320]\n",
      "[Epoch 0/1] [Batch 128/3551] [D loss: 1.004657] [G loss: 0.595488]\n",
      "[Epoch 0/1] [Batch 129/3551] [D loss: 1.423864] [G loss: 0.633839]\n",
      "[Epoch 0/1] [Batch 130/3551] [D loss: 2.265957] [G loss: 0.612206]\n",
      "[Epoch 0/1] [Batch 131/3551] [D loss: 1.013640] [G loss: 0.627333]\n",
      "[Epoch 0/1] [Batch 132/3551] [D loss: 1.242804] [G loss: 0.635159]\n",
      "[Epoch 0/1] [Batch 133/3551] [D loss: 1.877136] [G loss: 0.631804]\n",
      "[Epoch 0/1] [Batch 134/3551] [D loss: 1.456555] [G loss: 0.622109]\n",
      "[Epoch 0/1] [Batch 135/3551] [D loss: 1.046024] [G loss: 0.607634]\n",
      "[Epoch 0/1] [Batch 136/3551] [D loss: 1.699797] [G loss: 0.640790]\n",
      "[Epoch 0/1] [Batch 137/3551] [D loss: 1.282310] [G loss: 0.600635]\n",
      "[Epoch 0/1] [Batch 138/3551] [D loss: 1.063629] [G loss: 0.620258]\n",
      "[Epoch 0/1] [Batch 139/3551] [D loss: 1.444834] [G loss: 0.629203]\n",
      "[Epoch 0/1] [Batch 140/3551] [D loss: 1.005852] [G loss: 0.649812]\n",
      "[Epoch 0/1] [Batch 141/3551] [D loss: 1.417868] [G loss: 0.652644]\n",
      "[Epoch 0/1] [Batch 142/3551] [D loss: 0.687319] [G loss: 0.662965]\n",
      "[Epoch 0/1] [Batch 143/3551] [D loss: 1.698010] [G loss: 0.629960]\n",
      "[Epoch 0/1] [Batch 144/3551] [D loss: 1.265610] [G loss: 0.667665]\n",
      "[Epoch 0/1] [Batch 145/3551] [D loss: 1.675255] [G loss: 0.630780]\n",
      "[Epoch 0/1] [Batch 146/3551] [D loss: 1.177438] [G loss: 0.665737]\n",
      "[Epoch 0/1] [Batch 147/3551] [D loss: 1.261019] [G loss: 0.650816]\n",
      "[Epoch 0/1] [Batch 148/3551] [D loss: 1.454099] [G loss: 0.610679]\n",
      "[Epoch 0/1] [Batch 149/3551] [D loss: 1.551749] [G loss: 0.650101]\n",
      "[Epoch 0/1] [Batch 150/3551] [D loss: 1.105249] [G loss: 0.600268]\n",
      "[Epoch 0/1] [Batch 151/3551] [D loss: 1.781557] [G loss: 0.635192]\n",
      "[Epoch 0/1] [Batch 152/3551] [D loss: 0.966236] [G loss: 0.635930]\n",
      "[Epoch 0/1] [Batch 153/3551] [D loss: 1.243394] [G loss: 0.640376]\n",
      "[Epoch 0/1] [Batch 154/3551] [D loss: 1.401513] [G loss: 0.635587]\n",
      "[Epoch 0/1] [Batch 155/3551] [D loss: 1.343269] [G loss: 0.626475]\n",
      "[Epoch 0/1] [Batch 156/3551] [D loss: 1.044434] [G loss: 0.645930]\n",
      "[Epoch 0/1] [Batch 157/3551] [D loss: 1.340717] [G loss: 0.669812]\n",
      "[Epoch 0/1] [Batch 158/3551] [D loss: 1.341911] [G loss: 0.620970]\n",
      "[Epoch 0/1] [Batch 159/3551] [D loss: 1.051501] [G loss: 0.642785]\n",
      "[Epoch 0/1] [Batch 160/3551] [D loss: 0.792611] [G loss: 0.676462]\n",
      "[Epoch 0/1] [Batch 161/3551] [D loss: 0.961093] [G loss: 0.645447]\n",
      "[Epoch 0/1] [Batch 162/3551] [D loss: 1.127816] [G loss: 0.663102]\n",
      "[Epoch 0/1] [Batch 163/3551] [D loss: 0.895725] [G loss: 0.658968]\n",
      "[Epoch 0/1] [Batch 164/3551] [D loss: 1.517705] [G loss: 0.677602]\n",
      "[Epoch 0/1] [Batch 165/3551] [D loss: 0.714089] [G loss: 0.642136]\n",
      "[Epoch 0/1] [Batch 166/3551] [D loss: 1.086818] [G loss: 0.628748]\n",
      "[Epoch 0/1] [Batch 167/3551] [D loss: 0.716308] [G loss: 0.671748]\n",
      "[Epoch 0/1] [Batch 168/3551] [D loss: 0.818642] [G loss: 0.665321]\n",
      "[Epoch 0/1] [Batch 169/3551] [D loss: 0.777172] [G loss: 0.675564]\n",
      "[Epoch 0/1] [Batch 170/3551] [D loss: 1.129126] [G loss: 0.665524]\n",
      "[Epoch 0/1] [Batch 171/3551] [D loss: 0.983579] [G loss: 0.666418]\n",
      "[Epoch 0/1] [Batch 172/3551] [D loss: 1.253116] [G loss: 0.660348]\n",
      "[Epoch 0/1] [Batch 173/3551] [D loss: 0.918745] [G loss: 0.672482]\n",
      "[Epoch 0/1] [Batch 174/3551] [D loss: 1.104823] [G loss: 0.692065]\n",
      "[Epoch 0/1] [Batch 175/3551] [D loss: 0.984928] [G loss: 0.708875]\n",
      "[Epoch 0/1] [Batch 176/3551] [D loss: 1.084126] [G loss: 0.649999]\n",
      "[Epoch 0/1] [Batch 177/3551] [D loss: 0.946273] [G loss: 0.704816]\n",
      "[Epoch 0/1] [Batch 178/3551] [D loss: 1.295658] [G loss: 0.685215]\n",
      "[Epoch 0/1] [Batch 179/3551] [D loss: 0.583954] [G loss: 0.664347]\n",
      "[Epoch 0/1] [Batch 180/3551] [D loss: 0.890663] [G loss: 0.720860]\n",
      "[Epoch 0/1] [Batch 181/3551] [D loss: 1.192363] [G loss: 0.695224]\n",
      "[Epoch 0/1] [Batch 182/3551] [D loss: 1.060896] [G loss: 0.665483]\n",
      "[Epoch 0/1] [Batch 183/3551] [D loss: 0.719646] [G loss: 0.663969]\n",
      "[Epoch 0/1] [Batch 184/3551] [D loss: 0.596839] [G loss: 0.698679]\n",
      "[Epoch 0/1] [Batch 185/3551] [D loss: 0.913494] [G loss: 0.691862]\n",
      "[Epoch 0/1] [Batch 186/3551] [D loss: 0.808402] [G loss: 0.729910]\n",
      "[Epoch 0/1] [Batch 187/3551] [D loss: 0.766805] [G loss: 0.699922]\n",
      "[Epoch 0/1] [Batch 188/3551] [D loss: 0.649708] [G loss: 0.718017]\n",
      "[Epoch 0/1] [Batch 189/3551] [D loss: 0.723401] [G loss: 0.692884]\n",
      "[Epoch 0/1] [Batch 190/3551] [D loss: 1.182847] [G loss: 0.717641]\n",
      "[Epoch 0/1] [Batch 191/3551] [D loss: 0.718835] [G loss: 0.698720]\n",
      "[Epoch 0/1] [Batch 192/3551] [D loss: 0.601847] [G loss: 0.672575]\n",
      "[Epoch 0/1] [Batch 193/3551] [D loss: 1.090505] [G loss: 0.705796]\n",
      "[Epoch 0/1] [Batch 194/3551] [D loss: 0.737262] [G loss: 0.706577]\n",
      "[Epoch 0/1] [Batch 195/3551] [D loss: 0.911671] [G loss: 0.690473]\n",
      "[Epoch 0/1] [Batch 196/3551] [D loss: 0.693296] [G loss: 0.712578]\n",
      "[Epoch 0/1] [Batch 197/3551] [D loss: 1.005134] [G loss: 0.716933]\n",
      "[Epoch 0/1] [Batch 198/3551] [D loss: 0.833120] [G loss: 0.736116]\n",
      "[Epoch 0/1] [Batch 199/3551] [D loss: 0.957154] [G loss: 0.732284]\n",
      "[Epoch 0/1] [Batch 200/3551] [D loss: 0.923185] [G loss: 0.727696]\n",
      "[Epoch 0/1] [Batch 201/3551] [D loss: 1.027329] [G loss: 0.735255]\n",
      "[Epoch 0/1] [Batch 202/3551] [D loss: 0.547192] [G loss: 0.688681]\n",
      "[Epoch 0/1] [Batch 203/3551] [D loss: 0.835682] [G loss: 0.724621]\n",
      "[Epoch 0/1] [Batch 204/3551] [D loss: 0.615420] [G loss: 0.701799]\n",
      "[Epoch 0/1] [Batch 205/3551] [D loss: 0.653137] [G loss: 0.723101]\n",
      "[Epoch 0/1] [Batch 206/3551] [D loss: 0.922289] [G loss: 0.732335]\n",
      "[Epoch 0/1] [Batch 207/3551] [D loss: 1.035150] [G loss: 0.705734]\n",
      "[Epoch 0/1] [Batch 208/3551] [D loss: 0.732248] [G loss: 0.725994]\n",
      "[Epoch 0/1] [Batch 209/3551] [D loss: 0.594536] [G loss: 0.705340]\n",
      "[Epoch 0/1] [Batch 210/3551] [D loss: 0.958622] [G loss: 0.698728]\n",
      "[Epoch 0/1] [Batch 211/3551] [D loss: 1.251521] [G loss: 0.711488]\n",
      "[Epoch 0/1] [Batch 212/3551] [D loss: 0.777062] [G loss: 0.733868]\n",
      "[Epoch 0/1] [Batch 213/3551] [D loss: 0.968892] [G loss: 0.762622]\n",
      "[Epoch 0/1] [Batch 214/3551] [D loss: 0.851450] [G loss: 0.747099]\n",
      "[Epoch 0/1] [Batch 215/3551] [D loss: 0.683923] [G loss: 0.761094]\n",
      "[Epoch 0/1] [Batch 216/3551] [D loss: 0.887337] [G loss: 0.780681]\n",
      "[Epoch 0/1] [Batch 217/3551] [D loss: 0.824261] [G loss: 0.755759]\n",
      "[Epoch 0/1] [Batch 218/3551] [D loss: 0.419517] [G loss: 0.733518]\n",
      "[Epoch 0/1] [Batch 219/3551] [D loss: 1.095333] [G loss: 0.735207]\n",
      "[Epoch 0/1] [Batch 220/3551] [D loss: 0.741834] [G loss: 0.709869]\n",
      "[Epoch 0/1] [Batch 221/3551] [D loss: 0.800213] [G loss: 0.756408]\n",
      "[Epoch 0/1] [Batch 222/3551] [D loss: 0.538792] [G loss: 0.750660]\n",
      "[Epoch 0/1] [Batch 223/3551] [D loss: 0.903528] [G loss: 0.715761]\n",
      "[Epoch 0/1] [Batch 224/3551] [D loss: 0.439482] [G loss: 0.743861]\n",
      "[Epoch 0/1] [Batch 225/3551] [D loss: 0.566986] [G loss: 0.725072]\n",
      "[Epoch 0/1] [Batch 226/3551] [D loss: 0.656851] [G loss: 0.750223]\n",
      "[Epoch 0/1] [Batch 227/3551] [D loss: 0.598180] [G loss: 0.743612]\n",
      "[Epoch 0/1] [Batch 228/3551] [D loss: 0.868715] [G loss: 0.733535]\n",
      "[Epoch 0/1] [Batch 229/3551] [D loss: 0.873013] [G loss: 0.765718]\n",
      "[Epoch 0/1] [Batch 230/3551] [D loss: 1.049627] [G loss: 0.794278]\n",
      "[Epoch 0/1] [Batch 231/3551] [D loss: 0.595164] [G loss: 0.726687]\n",
      "[Epoch 0/1] [Batch 232/3551] [D loss: 0.838703] [G loss: 0.771476]\n",
      "[Epoch 0/1] [Batch 233/3551] [D loss: 1.151491] [G loss: 0.736436]\n",
      "[Epoch 0/1] [Batch 234/3551] [D loss: 1.265107] [G loss: 0.726302]\n",
      "[Epoch 0/1] [Batch 235/3551] [D loss: 0.660781] [G loss: 0.723578]\n",
      "[Epoch 0/1] [Batch 236/3551] [D loss: 0.524381] [G loss: 0.737397]\n",
      "[Epoch 0/1] [Batch 237/3551] [D loss: 0.759380] [G loss: 0.724064]\n",
      "[Epoch 0/1] [Batch 238/3551] [D loss: 0.496700] [G loss: 0.743029]\n",
      "[Epoch 0/1] [Batch 239/3551] [D loss: 0.722207] [G loss: 0.762654]\n",
      "[Epoch 0/1] [Batch 240/3551] [D loss: 0.785587] [G loss: 0.796233]\n",
      "[Epoch 0/1] [Batch 241/3551] [D loss: 0.578505] [G loss: 0.755710]\n",
      "[Epoch 0/1] [Batch 242/3551] [D loss: 0.557710] [G loss: 0.762438]\n",
      "[Epoch 0/1] [Batch 243/3551] [D loss: 0.589804] [G loss: 0.753701]\n",
      "[Epoch 0/1] [Batch 244/3551] [D loss: 0.464031] [G loss: 0.787806]\n",
      "[Epoch 0/1] [Batch 245/3551] [D loss: 0.696435] [G loss: 0.784063]\n",
      "[Epoch 0/1] [Batch 246/3551] [D loss: 0.438780] [G loss: 0.784917]\n",
      "[Epoch 0/1] [Batch 247/3551] [D loss: 0.603043] [G loss: 0.734004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 248/3551] [D loss: 0.656189] [G loss: 0.740933]\n",
      "[Epoch 0/1] [Batch 249/3551] [D loss: 0.757444] [G loss: 0.771180]\n",
      "[Epoch 0/1] [Batch 250/3551] [D loss: 0.727734] [G loss: 0.747837]\n",
      "[Epoch 0/1] [Batch 251/3551] [D loss: 0.712137] [G loss: 0.814939]\n",
      "[Epoch 0/1] [Batch 252/3551] [D loss: 0.488173] [G loss: 0.797995]\n",
      "[Epoch 0/1] [Batch 253/3551] [D loss: 0.743201] [G loss: 0.772696]\n",
      "[Epoch 0/1] [Batch 254/3551] [D loss: 0.698039] [G loss: 0.801273]\n",
      "[Epoch 0/1] [Batch 255/3551] [D loss: 0.570249] [G loss: 0.803734]\n",
      "[Epoch 0/1] [Batch 256/3551] [D loss: 0.846992] [G loss: 0.784910]\n",
      "[Epoch 0/1] [Batch 257/3551] [D loss: 1.073954] [G loss: 0.778411]\n",
      "[Epoch 0/1] [Batch 258/3551] [D loss: 0.838016] [G loss: 0.836499]\n",
      "[Epoch 0/1] [Batch 259/3551] [D loss: 0.676630] [G loss: 0.793436]\n",
      "[Epoch 0/1] [Batch 260/3551] [D loss: 0.496900] [G loss: 0.789631]\n",
      "[Epoch 0/1] [Batch 261/3551] [D loss: 0.438696] [G loss: 0.834114]\n",
      "[Epoch 0/1] [Batch 262/3551] [D loss: 0.420588] [G loss: 0.820661]\n",
      "[Epoch 0/1] [Batch 263/3551] [D loss: 0.485842] [G loss: 0.786268]\n",
      "[Epoch 0/1] [Batch 264/3551] [D loss: 0.565911] [G loss: 0.814308]\n",
      "[Epoch 0/1] [Batch 265/3551] [D loss: 0.609426] [G loss: 0.833097]\n",
      "[Epoch 0/1] [Batch 266/3551] [D loss: 0.890330] [G loss: 0.813132]\n",
      "[Epoch 0/1] [Batch 267/3551] [D loss: 0.413243] [G loss: 0.826713]\n",
      "[Epoch 0/1] [Batch 268/3551] [D loss: 0.641003] [G loss: 0.797448]\n",
      "[Epoch 0/1] [Batch 269/3551] [D loss: 0.670106] [G loss: 0.776055]\n",
      "[Epoch 0/1] [Batch 270/3551] [D loss: 0.430199] [G loss: 0.816450]\n",
      "[Epoch 0/1] [Batch 271/3551] [D loss: 0.580291] [G loss: 0.806349]\n",
      "[Epoch 0/1] [Batch 272/3551] [D loss: 0.678605] [G loss: 0.801868]\n",
      "[Epoch 0/1] [Batch 273/3551] [D loss: 0.461587] [G loss: 0.795159]\n",
      "[Epoch 0/1] [Batch 274/3551] [D loss: 0.450584] [G loss: 0.811792]\n",
      "[Epoch 0/1] [Batch 275/3551] [D loss: 0.444651] [G loss: 0.791285]\n",
      "[Epoch 0/1] [Batch 276/3551] [D loss: 0.418440] [G loss: 0.824681]\n",
      "[Epoch 0/1] [Batch 277/3551] [D loss: 0.807522] [G loss: 0.833986]\n",
      "[Epoch 0/1] [Batch 278/3551] [D loss: 0.619576] [G loss: 0.810445]\n",
      "[Epoch 0/1] [Batch 279/3551] [D loss: 0.668309] [G loss: 0.809119]\n",
      "[Epoch 0/1] [Batch 280/3551] [D loss: 0.543016] [G loss: 0.820661]\n",
      "[Epoch 0/1] [Batch 281/3551] [D loss: 0.603754] [G loss: 0.808684]\n",
      "[Epoch 0/1] [Batch 282/3551] [D loss: 0.628891] [G loss: 0.791532]\n",
      "[Epoch 0/1] [Batch 283/3551] [D loss: 0.614253] [G loss: 0.857386]\n",
      "[Epoch 0/1] [Batch 284/3551] [D loss: 0.759532] [G loss: 0.831030]\n",
      "[Epoch 0/1] [Batch 285/3551] [D loss: 0.625547] [G loss: 0.792157]\n",
      "[Epoch 0/1] [Batch 286/3551] [D loss: 0.666293] [G loss: 0.799719]\n",
      "[Epoch 0/1] [Batch 287/3551] [D loss: 0.584001] [G loss: 0.765397]\n",
      "[Epoch 0/1] [Batch 288/3551] [D loss: 0.633807] [G loss: 0.813602]\n",
      "[Epoch 0/1] [Batch 289/3551] [D loss: 0.666619] [G loss: 0.811246]\n",
      "[Epoch 0/1] [Batch 290/3551] [D loss: 0.441023] [G loss: 0.768212]\n",
      "[Epoch 0/1] [Batch 291/3551] [D loss: 0.649708] [G loss: 0.847971]\n",
      "[Epoch 0/1] [Batch 292/3551] [D loss: 0.408221] [G loss: 0.815863]\n",
      "[Epoch 0/1] [Batch 293/3551] [D loss: 0.723997] [G loss: 0.828427]\n",
      "[Epoch 0/1] [Batch 294/3551] [D loss: 0.564900] [G loss: 0.848257]\n",
      "[Epoch 0/1] [Batch 295/3551] [D loss: 0.506922] [G loss: 0.848030]\n",
      "[Epoch 0/1] [Batch 296/3551] [D loss: 0.692918] [G loss: 0.832189]\n",
      "[Epoch 0/1] [Batch 297/3551] [D loss: 0.491847] [G loss: 0.840124]\n",
      "[Epoch 0/1] [Batch 298/3551] [D loss: 0.549978] [G loss: 0.837720]\n",
      "[Epoch 0/1] [Batch 299/3551] [D loss: 0.517268] [G loss: 0.841343]\n",
      "[Epoch 0/1] [Batch 300/3551] [D loss: 0.409798] [G loss: 0.812571]\n",
      "[Epoch 0/1] [Batch 301/3551] [D loss: 0.421950] [G loss: 0.838123]\n",
      "[Epoch 0/1] [Batch 302/3551] [D loss: 0.491785] [G loss: 0.841401]\n",
      "[Epoch 0/1] [Batch 303/3551] [D loss: 0.679381] [G loss: 0.810190]\n",
      "[Epoch 0/1] [Batch 304/3551] [D loss: 0.578884] [G loss: 0.826636]\n",
      "[Epoch 0/1] [Batch 305/3551] [D loss: 0.628628] [G loss: 0.843254]\n",
      "[Epoch 0/1] [Batch 306/3551] [D loss: 0.610788] [G loss: 0.852413]\n",
      "[Epoch 0/1] [Batch 307/3551] [D loss: 0.322942] [G loss: 0.820930]\n",
      "[Epoch 0/1] [Batch 308/3551] [D loss: 0.487084] [G loss: 0.798824]\n",
      "[Epoch 0/1] [Batch 309/3551] [D loss: 0.447454] [G loss: 0.803764]\n",
      "[Epoch 0/1] [Batch 310/3551] [D loss: 0.476975] [G loss: 0.853918]\n",
      "[Epoch 0/1] [Batch 311/3551] [D loss: 0.526901] [G loss: 0.817062]\n",
      "[Epoch 0/1] [Batch 312/3551] [D loss: 0.482116] [G loss: 0.843051]\n",
      "[Epoch 0/1] [Batch 313/3551] [D loss: 0.281520] [G loss: 0.818934]\n",
      "[Epoch 0/1] [Batch 314/3551] [D loss: 0.358370] [G loss: 0.830858]\n",
      "[Epoch 0/1] [Batch 315/3551] [D loss: 0.273339] [G loss: 0.852105]\n",
      "[Epoch 0/1] [Batch 316/3551] [D loss: 0.531275] [G loss: 0.820262]\n",
      "[Epoch 0/1] [Batch 317/3551] [D loss: 0.236060] [G loss: 0.859454]\n",
      "[Epoch 0/1] [Batch 318/3551] [D loss: 0.433053] [G loss: 0.838128]\n",
      "[Epoch 0/1] [Batch 319/3551] [D loss: 0.519798] [G loss: 0.829105]\n",
      "[Epoch 0/1] [Batch 320/3551] [D loss: 0.383490] [G loss: 0.843597]\n",
      "[Epoch 0/1] [Batch 321/3551] [D loss: 0.746779] [G loss: 0.843332]\n",
      "[Epoch 0/1] [Batch 322/3551] [D loss: 0.283496] [G loss: 0.852818]\n",
      "[Epoch 0/1] [Batch 323/3551] [D loss: 0.468245] [G loss: 0.821286]\n",
      "[Epoch 0/1] [Batch 324/3551] [D loss: 0.617839] [G loss: 0.808592]\n",
      "[Epoch 0/1] [Batch 325/3551] [D loss: 0.399872] [G loss: 0.841851]\n",
      "[Epoch 0/1] [Batch 326/3551] [D loss: 0.441793] [G loss: 0.834796]\n",
      "[Epoch 0/1] [Batch 327/3551] [D loss: 0.506694] [G loss: 0.841072]\n",
      "[Epoch 0/1] [Batch 328/3551] [D loss: 0.316388] [G loss: 0.832841]\n",
      "[Epoch 0/1] [Batch 329/3551] [D loss: 0.500386] [G loss: 0.874670]\n",
      "[Epoch 0/1] [Batch 330/3551] [D loss: 0.532054] [G loss: 0.857760]\n",
      "[Epoch 0/1] [Batch 331/3551] [D loss: 0.539012] [G loss: 0.820204]\n",
      "[Epoch 0/1] [Batch 332/3551] [D loss: 0.356278] [G loss: 0.852029]\n",
      "[Epoch 0/1] [Batch 333/3551] [D loss: 0.289197] [G loss: 0.856729]\n",
      "[Epoch 0/1] [Batch 334/3551] [D loss: 0.376286] [G loss: 0.829704]\n",
      "[Epoch 0/1] [Batch 335/3551] [D loss: 0.234105] [G loss: 0.807693]\n",
      "[Epoch 0/1] [Batch 336/3551] [D loss: 0.413859] [G loss: 0.831774]\n",
      "[Epoch 0/1] [Batch 337/3551] [D loss: 0.405341] [G loss: 0.856011]\n",
      "[Epoch 0/1] [Batch 338/3551] [D loss: 0.434414] [G loss: 0.854203]\n",
      "[Epoch 0/1] [Batch 339/3551] [D loss: 0.447488] [G loss: 0.848434]\n",
      "[Epoch 0/1] [Batch 340/3551] [D loss: 0.314454] [G loss: 0.821716]\n",
      "[Epoch 0/1] [Batch 341/3551] [D loss: 0.573629] [G loss: 0.809208]\n",
      "[Epoch 0/1] [Batch 342/3551] [D loss: 0.369403] [G loss: 0.887139]\n",
      "[Epoch 0/1] [Batch 343/3551] [D loss: 0.185884] [G loss: 0.806551]\n",
      "[Epoch 0/1] [Batch 344/3551] [D loss: 0.365516] [G loss: 0.881918]\n",
      "[Epoch 0/1] [Batch 345/3551] [D loss: 0.396142] [G loss: 0.852049]\n",
      "[Epoch 0/1] [Batch 346/3551] [D loss: 0.498917] [G loss: 0.849700]\n",
      "[Epoch 0/1] [Batch 347/3551] [D loss: 0.333206] [G loss: 0.862384]\n",
      "[Epoch 0/1] [Batch 348/3551] [D loss: 0.490275] [G loss: 0.855835]\n",
      "[Epoch 0/1] [Batch 349/3551] [D loss: 0.372339] [G loss: 0.851591]\n",
      "[Epoch 0/1] [Batch 350/3551] [D loss: 0.462206] [G loss: 0.869729]\n",
      "[Epoch 0/1] [Batch 351/3551] [D loss: 0.321840] [G loss: 0.845939]\n",
      "[Epoch 0/1] [Batch 352/3551] [D loss: 0.298859] [G loss: 0.858865]\n",
      "[Epoch 0/1] [Batch 353/3551] [D loss: 0.376094] [G loss: 0.827683]\n",
      "[Epoch 0/1] [Batch 354/3551] [D loss: 0.607984] [G loss: 0.876981]\n",
      "[Epoch 0/1] [Batch 355/3551] [D loss: 0.371744] [G loss: 0.848300]\n",
      "[Epoch 0/1] [Batch 356/3551] [D loss: 0.330904] [G loss: 0.891994]\n",
      "[Epoch 0/1] [Batch 357/3551] [D loss: 0.386360] [G loss: 0.830910]\n",
      "[Epoch 0/1] [Batch 358/3551] [D loss: 0.384333] [G loss: 0.869870]\n",
      "[Epoch 0/1] [Batch 359/3551] [D loss: 0.668127] [G loss: 0.852656]\n",
      "[Epoch 0/1] [Batch 360/3551] [D loss: 0.393898] [G loss: 0.831351]\n",
      "[Epoch 0/1] [Batch 361/3551] [D loss: 0.301708] [G loss: 0.865945]\n",
      "[Epoch 0/1] [Batch 362/3551] [D loss: 0.579933] [G loss: 0.832095]\n",
      "[Epoch 0/1] [Batch 363/3551] [D loss: 0.415792] [G loss: 0.878679]\n",
      "[Epoch 0/1] [Batch 364/3551] [D loss: 0.155840] [G loss: 0.884672]\n",
      "[Epoch 0/1] [Batch 365/3551] [D loss: 0.484819] [G loss: 0.845332]\n",
      "[Epoch 0/1] [Batch 366/3551] [D loss: 0.595996] [G loss: 0.859904]\n",
      "[Epoch 0/1] [Batch 367/3551] [D loss: 0.450074] [G loss: 0.862737]\n",
      "[Epoch 0/1] [Batch 368/3551] [D loss: 0.326622] [G loss: 0.856211]\n",
      "[Epoch 0/1] [Batch 369/3551] [D loss: 0.456919] [G loss: 0.831415]\n",
      "[Epoch 0/1] [Batch 370/3551] [D loss: 0.462766] [G loss: 0.811233]\n",
      "[Epoch 0/1] [Batch 371/3551] [D loss: 0.367644] [G loss: 0.895013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 372/3551] [D loss: 0.414024] [G loss: 0.915581]\n",
      "[Epoch 0/1] [Batch 373/3551] [D loss: 0.375620] [G loss: 0.894849]\n",
      "[Epoch 0/1] [Batch 374/3551] [D loss: 0.523633] [G loss: 0.858353]\n",
      "[Epoch 0/1] [Batch 375/3551] [D loss: 0.329586] [G loss: 0.838696]\n",
      "[Epoch 0/1] [Batch 376/3551] [D loss: 0.562373] [G loss: 0.865649]\n",
      "[Epoch 0/1] [Batch 377/3551] [D loss: 0.477555] [G loss: 0.885907]\n",
      "[Epoch 0/1] [Batch 378/3551] [D loss: 0.492359] [G loss: 0.836455]\n",
      "[Epoch 0/1] [Batch 379/3551] [D loss: 0.513388] [G loss: 0.872218]\n",
      "[Epoch 0/1] [Batch 380/3551] [D loss: 0.437003] [G loss: 0.870367]\n",
      "[Epoch 0/1] [Batch 381/3551] [D loss: 0.285485] [G loss: 0.873066]\n",
      "[Epoch 0/1] [Batch 382/3551] [D loss: 0.366669] [G loss: 0.889467]\n",
      "[Epoch 0/1] [Batch 383/3551] [D loss: 0.460201] [G loss: 0.857388]\n",
      "[Epoch 0/1] [Batch 384/3551] [D loss: 0.467596] [G loss: 0.860646]\n",
      "[Epoch 0/1] [Batch 385/3551] [D loss: 0.495941] [G loss: 0.881912]\n",
      "[Epoch 0/1] [Batch 386/3551] [D loss: 0.319133] [G loss: 0.890647]\n",
      "[Epoch 0/1] [Batch 387/3551] [D loss: 0.464258] [G loss: 0.827428]\n",
      "[Epoch 0/1] [Batch 388/3551] [D loss: 0.548062] [G loss: 0.868755]\n",
      "[Epoch 0/1] [Batch 389/3551] [D loss: 0.319242] [G loss: 0.839081]\n",
      "[Epoch 0/1] [Batch 390/3551] [D loss: 0.253702] [G loss: 0.832747]\n",
      "[Epoch 0/1] [Batch 391/3551] [D loss: 0.498530] [G loss: 0.856893]\n",
      "[Epoch 0/1] [Batch 392/3551] [D loss: 0.326759] [G loss: 0.864333]\n",
      "[Epoch 0/1] [Batch 393/3551] [D loss: 0.231830] [G loss: 0.838679]\n",
      "[Epoch 0/1] [Batch 394/3551] [D loss: 0.277025] [G loss: 0.840265]\n",
      "[Epoch 0/1] [Batch 395/3551] [D loss: 0.228129] [G loss: 0.854595]\n",
      "[Epoch 0/1] [Batch 396/3551] [D loss: 0.364570] [G loss: 0.844855]\n",
      "[Epoch 0/1] [Batch 397/3551] [D loss: 0.476708] [G loss: 0.882806]\n",
      "[Epoch 0/1] [Batch 398/3551] [D loss: 0.315530] [G loss: 0.897129]\n",
      "[Epoch 0/1] [Batch 399/3551] [D loss: 0.269905] [G loss: 0.859533]\n",
      "[Epoch 0/1] [Batch 400/3551] [D loss: 0.318225] [G loss: 0.885935]\n",
      "[Epoch 0/1] [Batch 401/3551] [D loss: 0.466975] [G loss: 0.880098]\n",
      "[Epoch 0/1] [Batch 402/3551] [D loss: 0.242744] [G loss: 0.898999]\n",
      "[Epoch 0/1] [Batch 403/3551] [D loss: 0.358518] [G loss: 0.862105]\n",
      "[Epoch 0/1] [Batch 404/3551] [D loss: 0.379650] [G loss: 0.852039]\n",
      "[Epoch 0/1] [Batch 405/3551] [D loss: 0.328742] [G loss: 0.862662]\n",
      "[Epoch 0/1] [Batch 406/3551] [D loss: 0.264724] [G loss: 0.885106]\n",
      "[Epoch 0/1] [Batch 407/3551] [D loss: 0.292681] [G loss: 0.852166]\n",
      "[Epoch 0/1] [Batch 408/3551] [D loss: 0.378585] [G loss: 0.847468]\n",
      "[Epoch 0/1] [Batch 409/3551] [D loss: 0.402012] [G loss: 0.849220]\n",
      "[Epoch 0/1] [Batch 410/3551] [D loss: 0.469533] [G loss: 0.862467]\n",
      "[Epoch 0/1] [Batch 411/3551] [D loss: 0.396958] [G loss: 0.856671]\n",
      "[Epoch 0/1] [Batch 412/3551] [D loss: 0.412191] [G loss: 0.882355]\n",
      "[Epoch 0/1] [Batch 413/3551] [D loss: 0.342561] [G loss: 0.898799]\n",
      "[Epoch 0/1] [Batch 414/3551] [D loss: 0.327777] [G loss: 0.870735]\n",
      "[Epoch 0/1] [Batch 415/3551] [D loss: 0.312714] [G loss: 0.901846]\n",
      "[Epoch 0/1] [Batch 416/3551] [D loss: 0.315068] [G loss: 0.834635]\n",
      "[Epoch 0/1] [Batch 417/3551] [D loss: 0.270156] [G loss: 0.854456]\n",
      "[Epoch 0/1] [Batch 418/3551] [D loss: 0.381657] [G loss: 0.845137]\n",
      "[Epoch 0/1] [Batch 419/3551] [D loss: 0.274518] [G loss: 0.872803]\n",
      "[Epoch 0/1] [Batch 420/3551] [D loss: 0.360544] [G loss: 0.845118]\n",
      "[Epoch 0/1] [Batch 421/3551] [D loss: 0.279280] [G loss: 0.885226]\n",
      "[Epoch 0/1] [Batch 422/3551] [D loss: 0.450734] [G loss: 0.870394]\n",
      "[Epoch 0/1] [Batch 423/3551] [D loss: 0.246655] [G loss: 0.894417]\n",
      "[Epoch 0/1] [Batch 424/3551] [D loss: 0.465111] [G loss: 0.865341]\n",
      "[Epoch 0/1] [Batch 425/3551] [D loss: 0.289737] [G loss: 0.888412]\n",
      "[Epoch 0/1] [Batch 426/3551] [D loss: 0.263048] [G loss: 0.885987]\n",
      "[Epoch 0/1] [Batch 427/3551] [D loss: 0.274743] [G loss: 0.889086]\n",
      "[Epoch 0/1] [Batch 428/3551] [D loss: 0.258587] [G loss: 0.861623]\n",
      "[Epoch 0/1] [Batch 429/3551] [D loss: 0.317828] [G loss: 0.898666]\n",
      "[Epoch 0/1] [Batch 430/3551] [D loss: 0.354383] [G loss: 0.863270]\n",
      "[Epoch 0/1] [Batch 431/3551] [D loss: 0.243139] [G loss: 0.950694]\n",
      "[Epoch 0/1] [Batch 432/3551] [D loss: 0.248197] [G loss: 0.891333]\n",
      "[Epoch 0/1] [Batch 433/3551] [D loss: 0.281684] [G loss: 0.899340]\n",
      "[Epoch 0/1] [Batch 434/3551] [D loss: 0.481023] [G loss: 0.872781]\n",
      "[Epoch 0/1] [Batch 435/3551] [D loss: 0.326891] [G loss: 0.907061]\n",
      "[Epoch 0/1] [Batch 436/3551] [D loss: 0.242770] [G loss: 0.866123]\n",
      "[Epoch 0/1] [Batch 437/3551] [D loss: 0.245653] [G loss: 0.857825]\n",
      "[Epoch 0/1] [Batch 438/3551] [D loss: 0.324609] [G loss: 0.927298]\n",
      "[Epoch 0/1] [Batch 439/3551] [D loss: 0.323061] [G loss: 0.905544]\n",
      "[Epoch 0/1] [Batch 440/3551] [D loss: 0.467077] [G loss: 0.885021]\n",
      "[Epoch 0/1] [Batch 441/3551] [D loss: 0.199066] [G loss: 0.868871]\n",
      "[Epoch 0/1] [Batch 442/3551] [D loss: 0.323401] [G loss: 0.924473]\n",
      "[Epoch 0/1] [Batch 443/3551] [D loss: 0.452931] [G loss: 0.903814]\n",
      "[Epoch 0/1] [Batch 444/3551] [D loss: 0.447294] [G loss: 0.873871]\n",
      "[Epoch 0/1] [Batch 445/3551] [D loss: 0.229707] [G loss: 0.878935]\n",
      "[Epoch 0/1] [Batch 446/3551] [D loss: 0.278572] [G loss: 0.855804]\n",
      "[Epoch 0/1] [Batch 447/3551] [D loss: 0.414770] [G loss: 0.870380]\n",
      "[Epoch 0/1] [Batch 448/3551] [D loss: 0.328662] [G loss: 0.866402]\n",
      "[Epoch 0/1] [Batch 449/3551] [D loss: 0.364489] [G loss: 0.892285]\n",
      "[Epoch 0/1] [Batch 450/3551] [D loss: 0.266633] [G loss: 0.890103]\n",
      "[Epoch 0/1] [Batch 451/3551] [D loss: 0.407329] [G loss: 0.887407]\n",
      "[Epoch 0/1] [Batch 452/3551] [D loss: 0.274888] [G loss: 0.883860]\n",
      "[Epoch 0/1] [Batch 453/3551] [D loss: 0.288645] [G loss: 0.905883]\n",
      "[Epoch 0/1] [Batch 454/3551] [D loss: 0.396480] [G loss: 0.890638]\n",
      "[Epoch 0/1] [Batch 455/3551] [D loss: 0.280239] [G loss: 0.888679]\n",
      "[Epoch 0/1] [Batch 456/3551] [D loss: 0.146678] [G loss: 0.880032]\n",
      "[Epoch 0/1] [Batch 457/3551] [D loss: 0.392247] [G loss: 0.937916]\n",
      "[Epoch 0/1] [Batch 458/3551] [D loss: 0.164636] [G loss: 0.870791]\n",
      "[Epoch 0/1] [Batch 459/3551] [D loss: 0.313755] [G loss: 0.862940]\n",
      "[Epoch 0/1] [Batch 460/3551] [D loss: 0.323253] [G loss: 0.865593]\n",
      "[Epoch 0/1] [Batch 461/3551] [D loss: 0.213696] [G loss: 0.848619]\n",
      "[Epoch 0/1] [Batch 462/3551] [D loss: 0.370807] [G loss: 0.884527]\n",
      "[Epoch 0/1] [Batch 463/3551] [D loss: 0.378719] [G loss: 0.882373]\n",
      "[Epoch 0/1] [Batch 464/3551] [D loss: 0.321758] [G loss: 0.870935]\n",
      "[Epoch 0/1] [Batch 465/3551] [D loss: 0.382141] [G loss: 0.874246]\n",
      "[Epoch 0/1] [Batch 466/3551] [D loss: 0.433167] [G loss: 0.896608]\n",
      "[Epoch 0/1] [Batch 467/3551] [D loss: 0.212142] [G loss: 0.874224]\n",
      "[Epoch 0/1] [Batch 468/3551] [D loss: 0.525627] [G loss: 0.862223]\n",
      "[Epoch 0/1] [Batch 469/3551] [D loss: 0.247670] [G loss: 0.885167]\n",
      "[Epoch 0/1] [Batch 470/3551] [D loss: 0.353779] [G loss: 0.887201]\n",
      "[Epoch 0/1] [Batch 471/3551] [D loss: 0.307281] [G loss: 0.918814]\n",
      "[Epoch 0/1] [Batch 472/3551] [D loss: 0.284721] [G loss: 0.890729]\n",
      "[Epoch 0/1] [Batch 473/3551] [D loss: 0.286256] [G loss: 0.917659]\n",
      "[Epoch 0/1] [Batch 474/3551] [D loss: 0.331692] [G loss: 0.901949]\n",
      "[Epoch 0/1] [Batch 475/3551] [D loss: 0.308996] [G loss: 0.877923]\n",
      "[Epoch 0/1] [Batch 476/3551] [D loss: 0.233576] [G loss: 0.868986]\n",
      "[Epoch 0/1] [Batch 477/3551] [D loss: 0.185424] [G loss: 0.886293]\n",
      "[Epoch 0/1] [Batch 478/3551] [D loss: 0.431903] [G loss: 0.887531]\n",
      "[Epoch 0/1] [Batch 479/3551] [D loss: 0.328063] [G loss: 0.912525]\n",
      "[Epoch 0/1] [Batch 480/3551] [D loss: 0.228609] [G loss: 0.885264]\n",
      "[Epoch 0/1] [Batch 481/3551] [D loss: 0.314199] [G loss: 0.868084]\n",
      "[Epoch 0/1] [Batch 482/3551] [D loss: 0.174239] [G loss: 0.870344]\n",
      "[Epoch 0/1] [Batch 483/3551] [D loss: 0.363498] [G loss: 0.914265]\n",
      "[Epoch 0/1] [Batch 484/3551] [D loss: 0.377923] [G loss: 0.883258]\n",
      "[Epoch 0/1] [Batch 485/3551] [D loss: 0.228455] [G loss: 0.911665]\n",
      "[Epoch 0/1] [Batch 486/3551] [D loss: 0.292479] [G loss: 0.901954]\n",
      "[Epoch 0/1] [Batch 487/3551] [D loss: 0.294428] [G loss: 0.870879]\n",
      "[Epoch 0/1] [Batch 488/3551] [D loss: 0.187251] [G loss: 0.937647]\n",
      "[Epoch 0/1] [Batch 489/3551] [D loss: 0.376406] [G loss: 0.932242]\n",
      "[Epoch 0/1] [Batch 490/3551] [D loss: 0.389062] [G loss: 0.901581]\n",
      "[Epoch 0/1] [Batch 491/3551] [D loss: 0.233743] [G loss: 0.892558]\n",
      "[Epoch 0/1] [Batch 492/3551] [D loss: 0.320397] [G loss: 0.888237]\n",
      "[Epoch 0/1] [Batch 493/3551] [D loss: 0.264984] [G loss: 0.897875]\n",
      "[Epoch 0/1] [Batch 494/3551] [D loss: 0.371254] [G loss: 0.882265]\n",
      "[Epoch 0/1] [Batch 495/3551] [D loss: 0.237507] [G loss: 0.867188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 496/3551] [D loss: 0.207098] [G loss: 0.869167]\n",
      "[Epoch 0/1] [Batch 497/3551] [D loss: 0.191944] [G loss: 0.918323]\n",
      "[Epoch 0/1] [Batch 498/3551] [D loss: 0.308196] [G loss: 0.887639]\n",
      "[Epoch 0/1] [Batch 499/3551] [D loss: 0.367328] [G loss: 0.886140]\n",
      "[Epoch 0/1] [Batch 500/3551] [D loss: 0.447948] [G loss: 0.878551]\n",
      "[Epoch 0/1] [Batch 501/3551] [D loss: 0.245521] [G loss: 0.925116]\n",
      "[Epoch 0/1] [Batch 502/3551] [D loss: 0.375402] [G loss: 0.865255]\n",
      "[Epoch 0/1] [Batch 503/3551] [D loss: 0.335586] [G loss: 0.915842]\n",
      "[Epoch 0/1] [Batch 504/3551] [D loss: 0.359277] [G loss: 0.876409]\n",
      "[Epoch 0/1] [Batch 505/3551] [D loss: 0.338081] [G loss: 0.894884]\n",
      "[Epoch 0/1] [Batch 506/3551] [D loss: 0.317892] [G loss: 0.856275]\n",
      "[Epoch 0/1] [Batch 507/3551] [D loss: 0.240193] [G loss: 0.892523]\n",
      "[Epoch 0/1] [Batch 508/3551] [D loss: 0.231654] [G loss: 0.926954]\n",
      "[Epoch 0/1] [Batch 509/3551] [D loss: 0.243545] [G loss: 0.879392]\n",
      "[Epoch 0/1] [Batch 510/3551] [D loss: 0.275789] [G loss: 0.893016]\n",
      "[Epoch 0/1] [Batch 511/3551] [D loss: 0.271380] [G loss: 0.904508]\n",
      "[Epoch 0/1] [Batch 512/3551] [D loss: 0.215215] [G loss: 0.892526]\n",
      "[Epoch 0/1] [Batch 513/3551] [D loss: 0.271000] [G loss: 0.903619]\n",
      "[Epoch 0/1] [Batch 514/3551] [D loss: 0.233482] [G loss: 0.892558]\n",
      "[Epoch 0/1] [Batch 515/3551] [D loss: 0.221961] [G loss: 0.882308]\n",
      "[Epoch 0/1] [Batch 516/3551] [D loss: 0.219745] [G loss: 0.924882]\n",
      "[Epoch 0/1] [Batch 517/3551] [D loss: 0.172751] [G loss: 0.932520]\n",
      "[Epoch 0/1] [Batch 518/3551] [D loss: 0.238032] [G loss: 0.926004]\n",
      "[Epoch 0/1] [Batch 519/3551] [D loss: 0.367479] [G loss: 0.877631]\n",
      "[Epoch 0/1] [Batch 520/3551] [D loss: 0.248295] [G loss: 0.904307]\n",
      "[Epoch 0/1] [Batch 521/3551] [D loss: 0.288157] [G loss: 0.918146]\n",
      "[Epoch 0/1] [Batch 522/3551] [D loss: 0.165340] [G loss: 0.906912]\n",
      "[Epoch 0/1] [Batch 523/3551] [D loss: 0.184015] [G loss: 0.887102]\n",
      "[Epoch 0/1] [Batch 524/3551] [D loss: 0.256511] [G loss: 0.908660]\n",
      "[Epoch 0/1] [Batch 525/3551] [D loss: 0.295108] [G loss: 0.917282]\n",
      "[Epoch 0/1] [Batch 526/3551] [D loss: 0.364523] [G loss: 0.869104]\n",
      "[Epoch 0/1] [Batch 527/3551] [D loss: 0.463063] [G loss: 0.895212]\n",
      "[Epoch 0/1] [Batch 528/3551] [D loss: 0.319620] [G loss: 0.914640]\n",
      "[Epoch 0/1] [Batch 529/3551] [D loss: 0.195938] [G loss: 0.911145]\n",
      "[Epoch 0/1] [Batch 530/3551] [D loss: 0.341305] [G loss: 0.899628]\n",
      "[Epoch 0/1] [Batch 531/3551] [D loss: 0.237615] [G loss: 0.899758]\n",
      "[Epoch 0/1] [Batch 532/3551] [D loss: 0.355569] [G loss: 0.912400]\n",
      "[Epoch 0/1] [Batch 533/3551] [D loss: 0.273858] [G loss: 0.897447]\n",
      "[Epoch 0/1] [Batch 534/3551] [D loss: 0.295776] [G loss: 0.934653]\n",
      "[Epoch 0/1] [Batch 535/3551] [D loss: 0.272373] [G loss: 0.917147]\n",
      "[Epoch 0/1] [Batch 536/3551] [D loss: 0.454093] [G loss: 0.887404]\n",
      "[Epoch 0/1] [Batch 537/3551] [D loss: 0.248381] [G loss: 0.893683]\n",
      "[Epoch 0/1] [Batch 538/3551] [D loss: 0.282048] [G loss: 0.899216]\n",
      "[Epoch 0/1] [Batch 539/3551] [D loss: 0.236146] [G loss: 0.896865]\n",
      "[Epoch 0/1] [Batch 540/3551] [D loss: 0.287325] [G loss: 0.898004]\n",
      "[Epoch 0/1] [Batch 541/3551] [D loss: 0.290540] [G loss: 0.900875]\n",
      "[Epoch 0/1] [Batch 542/3551] [D loss: 0.371602] [G loss: 0.880720]\n",
      "[Epoch 0/1] [Batch 543/3551] [D loss: 0.331429] [G loss: 0.900011]\n",
      "[Epoch 0/1] [Batch 544/3551] [D loss: 0.205071] [G loss: 0.922383]\n",
      "[Epoch 0/1] [Batch 545/3551] [D loss: 0.231586] [G loss: 0.915379]\n",
      "[Epoch 0/1] [Batch 546/3551] [D loss: 0.240759] [G loss: 0.886728]\n",
      "[Epoch 0/1] [Batch 547/3551] [D loss: 0.276683] [G loss: 0.925104]\n",
      "[Epoch 0/1] [Batch 548/3551] [D loss: 0.276396] [G loss: 0.882924]\n",
      "[Epoch 0/1] [Batch 549/3551] [D loss: 0.194572] [G loss: 0.907196]\n",
      "[Epoch 0/1] [Batch 550/3551] [D loss: 0.142784] [G loss: 0.896486]\n",
      "[Epoch 0/1] [Batch 551/3551] [D loss: 0.208051] [G loss: 0.846052]\n",
      "[Epoch 0/1] [Batch 552/3551] [D loss: 0.314454] [G loss: 0.886082]\n",
      "[Epoch 0/1] [Batch 553/3551] [D loss: 0.254841] [G loss: 0.926377]\n",
      "[Epoch 0/1] [Batch 554/3551] [D loss: 0.275882] [G loss: 0.926206]\n",
      "[Epoch 0/1] [Batch 555/3551] [D loss: 0.247725] [G loss: 0.914730]\n",
      "[Epoch 0/1] [Batch 556/3551] [D loss: 0.201526] [G loss: 0.860028]\n",
      "[Epoch 0/1] [Batch 557/3551] [D loss: 0.276641] [G loss: 0.904453]\n",
      "[Epoch 0/1] [Batch 558/3551] [D loss: 0.350924] [G loss: 0.895971]\n",
      "[Epoch 0/1] [Batch 559/3551] [D loss: 0.250213] [G loss: 0.883116]\n",
      "[Epoch 0/1] [Batch 560/3551] [D loss: 0.236616] [G loss: 0.871808]\n",
      "[Epoch 0/1] [Batch 561/3551] [D loss: 0.250847] [G loss: 0.892352]\n",
      "[Epoch 0/1] [Batch 562/3551] [D loss: 0.226742] [G loss: 0.894472]\n",
      "[Epoch 0/1] [Batch 563/3551] [D loss: 0.217621] [G loss: 0.914663]\n",
      "[Epoch 0/1] [Batch 564/3551] [D loss: 0.205906] [G loss: 0.873598]\n",
      "[Epoch 0/1] [Batch 565/3551] [D loss: 0.251562] [G loss: 0.898585]\n",
      "[Epoch 0/1] [Batch 566/3551] [D loss: 0.275897] [G loss: 0.886876]\n",
      "[Epoch 0/1] [Batch 567/3551] [D loss: 0.210920] [G loss: 0.897092]\n",
      "[Epoch 0/1] [Batch 568/3551] [D loss: 0.213040] [G loss: 0.904772]\n",
      "[Epoch 0/1] [Batch 569/3551] [D loss: 0.238878] [G loss: 0.915392]\n",
      "[Epoch 0/1] [Batch 570/3551] [D loss: 0.161867] [G loss: 0.887638]\n",
      "[Epoch 0/1] [Batch 571/3551] [D loss: 0.328965] [G loss: 0.896953]\n",
      "[Epoch 0/1] [Batch 572/3551] [D loss: 0.337611] [G loss: 0.882341]\n",
      "[Epoch 0/1] [Batch 573/3551] [D loss: 0.116907] [G loss: 0.893637]\n",
      "[Epoch 0/1] [Batch 574/3551] [D loss: 0.299477] [G loss: 0.907131]\n",
      "[Epoch 0/1] [Batch 575/3551] [D loss: 0.195293] [G loss: 0.888445]\n",
      "[Epoch 0/1] [Batch 576/3551] [D loss: 0.293985] [G loss: 0.880379]\n",
      "[Epoch 0/1] [Batch 577/3551] [D loss: 0.327506] [G loss: 0.872011]\n",
      "[Epoch 0/1] [Batch 578/3551] [D loss: 0.215263] [G loss: 0.862925]\n",
      "[Epoch 0/1] [Batch 579/3551] [D loss: 0.256879] [G loss: 0.851190]\n",
      "[Epoch 0/1] [Batch 580/3551] [D loss: 0.196601] [G loss: 0.874647]\n",
      "[Epoch 0/1] [Batch 581/3551] [D loss: 0.210511] [G loss: 0.886959]\n",
      "[Epoch 0/1] [Batch 582/3551] [D loss: 0.266941] [G loss: 0.883994]\n",
      "[Epoch 0/1] [Batch 583/3551] [D loss: 0.230528] [G loss: 0.884533]\n",
      "[Epoch 0/1] [Batch 584/3551] [D loss: 0.155027] [G loss: 0.886657]\n",
      "[Epoch 0/1] [Batch 585/3551] [D loss: 0.196633] [G loss: 0.884201]\n",
      "[Epoch 0/1] [Batch 586/3551] [D loss: 0.262931] [G loss: 0.891168]\n",
      "[Epoch 0/1] [Batch 587/3551] [D loss: 0.188016] [G loss: 0.917877]\n",
      "[Epoch 0/1] [Batch 588/3551] [D loss: 0.275682] [G loss: 0.904027]\n",
      "[Epoch 0/1] [Batch 589/3551] [D loss: 0.223019] [G loss: 0.875385]\n",
      "[Epoch 0/1] [Batch 590/3551] [D loss: 0.238271] [G loss: 0.883391]\n",
      "[Epoch 0/1] [Batch 591/3551] [D loss: 0.200166] [G loss: 0.909401]\n",
      "[Epoch 0/1] [Batch 592/3551] [D loss: 0.300908] [G loss: 0.932501]\n",
      "[Epoch 0/1] [Batch 593/3551] [D loss: 0.262343] [G loss: 0.913065]\n",
      "[Epoch 0/1] [Batch 594/3551] [D loss: 0.284747] [G loss: 0.917098]\n",
      "[Epoch 0/1] [Batch 595/3551] [D loss: 0.409741] [G loss: 0.922876]\n",
      "[Epoch 0/1] [Batch 596/3551] [D loss: 0.165985] [G loss: 0.911840]\n",
      "[Epoch 0/1] [Batch 597/3551] [D loss: 0.168991] [G loss: 0.917585]\n",
      "[Epoch 0/1] [Batch 598/3551] [D loss: 0.162933] [G loss: 0.904225]\n",
      "[Epoch 0/1] [Batch 599/3551] [D loss: 0.270851] [G loss: 0.858279]\n",
      "[Epoch 0/1] [Batch 600/3551] [D loss: 0.180910] [G loss: 0.898723]\n",
      "[Epoch 0/1] [Batch 601/3551] [D loss: 0.246938] [G loss: 0.920541]\n",
      "[Epoch 0/1] [Batch 602/3551] [D loss: 0.137882] [G loss: 0.916354]\n",
      "[Epoch 0/1] [Batch 603/3551] [D loss: 0.170758] [G loss: 0.894640]\n",
      "[Epoch 0/1] [Batch 604/3551] [D loss: 0.247564] [G loss: 0.906939]\n",
      "[Epoch 0/1] [Batch 605/3551] [D loss: 0.243124] [G loss: 0.848659]\n",
      "[Epoch 0/1] [Batch 606/3551] [D loss: 0.246271] [G loss: 0.891063]\n",
      "[Epoch 0/1] [Batch 607/3551] [D loss: 0.181933] [G loss: 0.887410]\n",
      "[Epoch 0/1] [Batch 608/3551] [D loss: 0.282375] [G loss: 0.904545]\n",
      "[Epoch 0/1] [Batch 609/3551] [D loss: 0.206903] [G loss: 0.883327]\n",
      "[Epoch 0/1] [Batch 610/3551] [D loss: 0.107360] [G loss: 0.922659]\n",
      "[Epoch 0/1] [Batch 611/3551] [D loss: 0.193124] [G loss: 0.949236]\n",
      "[Epoch 0/1] [Batch 612/3551] [D loss: 0.214415] [G loss: 0.931462]\n",
      "[Epoch 0/1] [Batch 613/3551] [D loss: 0.272939] [G loss: 0.886529]\n",
      "[Epoch 0/1] [Batch 614/3551] [D loss: 0.289638] [G loss: 0.925816]\n",
      "[Epoch 0/1] [Batch 615/3551] [D loss: 0.277948] [G loss: 0.893971]\n",
      "[Epoch 0/1] [Batch 616/3551] [D loss: 0.210434] [G loss: 0.908790]\n",
      "[Epoch 0/1] [Batch 617/3551] [D loss: 0.393400] [G loss: 0.894422]\n",
      "[Epoch 0/1] [Batch 618/3551] [D loss: 0.215068] [G loss: 0.901094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 619/3551] [D loss: 0.237595] [G loss: 0.895797]\n",
      "[Epoch 0/1] [Batch 620/3551] [D loss: 0.202024] [G loss: 0.932387]\n",
      "[Epoch 0/1] [Batch 621/3551] [D loss: 0.170732] [G loss: 0.907764]\n",
      "[Epoch 0/1] [Batch 622/3551] [D loss: 0.291243] [G loss: 0.903899]\n",
      "[Epoch 0/1] [Batch 623/3551] [D loss: 0.307266] [G loss: 0.907411]\n",
      "[Epoch 0/1] [Batch 624/3551] [D loss: 0.349018] [G loss: 0.897483]\n",
      "[Epoch 0/1] [Batch 625/3551] [D loss: 0.258575] [G loss: 0.895086]\n",
      "[Epoch 0/1] [Batch 626/3551] [D loss: 0.265250] [G loss: 0.921113]\n",
      "[Epoch 0/1] [Batch 627/3551] [D loss: 0.194076] [G loss: 0.909857]\n",
      "[Epoch 0/1] [Batch 628/3551] [D loss: 0.303223] [G loss: 0.919798]\n",
      "[Epoch 0/1] [Batch 629/3551] [D loss: 0.182647] [G loss: 0.903635]\n",
      "[Epoch 0/1] [Batch 630/3551] [D loss: 0.259668] [G loss: 0.896781]\n",
      "[Epoch 0/1] [Batch 631/3551] [D loss: 0.194972] [G loss: 0.909122]\n",
      "[Epoch 0/1] [Batch 632/3551] [D loss: 0.265991] [G loss: 0.887104]\n",
      "[Epoch 0/1] [Batch 633/3551] [D loss: 0.106140] [G loss: 0.903955]\n",
      "[Epoch 0/1] [Batch 634/3551] [D loss: 0.196035] [G loss: 0.914634]\n",
      "[Epoch 0/1] [Batch 635/3551] [D loss: 0.249552] [G loss: 0.897886]\n",
      "[Epoch 0/1] [Batch 636/3551] [D loss: 0.214428] [G loss: 0.917789]\n",
      "[Epoch 0/1] [Batch 637/3551] [D loss: 0.138445] [G loss: 0.928920]\n",
      "[Epoch 0/1] [Batch 638/3551] [D loss: 0.287296] [G loss: 0.920197]\n",
      "[Epoch 0/1] [Batch 639/3551] [D loss: 0.291295] [G loss: 0.910228]\n",
      "[Epoch 0/1] [Batch 640/3551] [D loss: 0.231192] [G loss: 0.932371]\n",
      "[Epoch 0/1] [Batch 641/3551] [D loss: 0.180894] [G loss: 0.946191]\n",
      "[Epoch 0/1] [Batch 642/3551] [D loss: 0.119404] [G loss: 0.919052]\n",
      "[Epoch 0/1] [Batch 643/3551] [D loss: 0.171709] [G loss: 0.911565]\n",
      "[Epoch 0/1] [Batch 644/3551] [D loss: 0.211258] [G loss: 0.934452]\n",
      "[Epoch 0/1] [Batch 645/3551] [D loss: 0.254618] [G loss: 0.901062]\n",
      "[Epoch 0/1] [Batch 646/3551] [D loss: 0.175081] [G loss: 0.880591]\n",
      "[Epoch 0/1] [Batch 647/3551] [D loss: 0.215507] [G loss: 0.912143]\n",
      "[Epoch 0/1] [Batch 648/3551] [D loss: 0.330799] [G loss: 0.909855]\n",
      "[Epoch 0/1] [Batch 649/3551] [D loss: 0.192074] [G loss: 0.916702]\n",
      "[Epoch 0/1] [Batch 650/3551] [D loss: 0.187146] [G loss: 0.916929]\n",
      "[Epoch 0/1] [Batch 651/3551] [D loss: 0.158485] [G loss: 0.887231]\n",
      "[Epoch 0/1] [Batch 652/3551] [D loss: 0.213453] [G loss: 0.886470]\n",
      "[Epoch 0/1] [Batch 653/3551] [D loss: 0.191587] [G loss: 0.913426]\n",
      "[Epoch 0/1] [Batch 654/3551] [D loss: 0.179012] [G loss: 0.885025]\n",
      "[Epoch 0/1] [Batch 655/3551] [D loss: 0.211100] [G loss: 0.927174]\n",
      "[Epoch 0/1] [Batch 656/3551] [D loss: 0.167203] [G loss: 0.926201]\n",
      "[Epoch 0/1] [Batch 657/3551] [D loss: 0.201040] [G loss: 0.921310]\n",
      "[Epoch 0/1] [Batch 658/3551] [D loss: 0.206040] [G loss: 0.906092]\n",
      "[Epoch 0/1] [Batch 659/3551] [D loss: 0.188895] [G loss: 0.900473]\n",
      "[Epoch 0/1] [Batch 660/3551] [D loss: 0.162209] [G loss: 0.885084]\n",
      "[Epoch 0/1] [Batch 661/3551] [D loss: 0.282330] [G loss: 0.921618]\n",
      "[Epoch 0/1] [Batch 662/3551] [D loss: 0.263227] [G loss: 0.888299]\n",
      "[Epoch 0/1] [Batch 663/3551] [D loss: 0.153927] [G loss: 0.906839]\n",
      "[Epoch 0/1] [Batch 664/3551] [D loss: 0.282599] [G loss: 0.867956]\n",
      "[Epoch 0/1] [Batch 665/3551] [D loss: 0.128310] [G loss: 0.881529]\n",
      "[Epoch 0/1] [Batch 666/3551] [D loss: 0.201138] [G loss: 0.877694]\n",
      "[Epoch 0/1] [Batch 667/3551] [D loss: 0.162520] [G loss: 0.927532]\n",
      "[Epoch 0/1] [Batch 668/3551] [D loss: 0.148365] [G loss: 0.927276]\n",
      "[Epoch 0/1] [Batch 669/3551] [D loss: 0.155457] [G loss: 0.896032]\n",
      "[Epoch 0/1] [Batch 670/3551] [D loss: 0.210261] [G loss: 0.914295]\n",
      "[Epoch 0/1] [Batch 671/3551] [D loss: 0.157225] [G loss: 0.919435]\n",
      "[Epoch 0/1] [Batch 672/3551] [D loss: 0.188191] [G loss: 0.910587]\n",
      "[Epoch 0/1] [Batch 673/3551] [D loss: 0.232591] [G loss: 0.903059]\n",
      "[Epoch 0/1] [Batch 674/3551] [D loss: 0.198908] [G loss: 0.924084]\n",
      "[Epoch 0/1] [Batch 675/3551] [D loss: 0.152085] [G loss: 0.932218]\n",
      "[Epoch 0/1] [Batch 676/3551] [D loss: 0.229570] [G loss: 0.898619]\n",
      "[Epoch 0/1] [Batch 677/3551] [D loss: 0.193117] [G loss: 0.905557]\n",
      "[Epoch 0/1] [Batch 678/3551] [D loss: 0.159266] [G loss: 0.896320]\n",
      "[Epoch 0/1] [Batch 679/3551] [D loss: 0.164738] [G loss: 0.904789]\n",
      "[Epoch 0/1] [Batch 680/3551] [D loss: 0.250929] [G loss: 0.916308]\n",
      "[Epoch 0/1] [Batch 681/3551] [D loss: 0.133242] [G loss: 0.897199]\n",
      "[Epoch 0/1] [Batch 682/3551] [D loss: 0.231548] [G loss: 0.877561]\n",
      "[Epoch 0/1] [Batch 683/3551] [D loss: 0.193567] [G loss: 0.893431]\n",
      "[Epoch 0/1] [Batch 684/3551] [D loss: 0.249272] [G loss: 0.912930]\n",
      "[Epoch 0/1] [Batch 685/3551] [D loss: 0.103127] [G loss: 0.925457]\n",
      "[Epoch 0/1] [Batch 686/3551] [D loss: 0.185088] [G loss: 0.907733]\n",
      "[Epoch 0/1] [Batch 687/3551] [D loss: 0.150824] [G loss: 0.909962]\n",
      "[Epoch 0/1] [Batch 688/3551] [D loss: 0.082793] [G loss: 0.936988]\n",
      "[Epoch 0/1] [Batch 689/3551] [D loss: 0.135422] [G loss: 0.949959]\n",
      "[Epoch 0/1] [Batch 690/3551] [D loss: 0.092527] [G loss: 0.911458]\n",
      "[Epoch 0/1] [Batch 691/3551] [D loss: 0.185301] [G loss: 0.924193]\n",
      "[Epoch 0/1] [Batch 692/3551] [D loss: 0.117070] [G loss: 0.943563]\n",
      "[Epoch 0/1] [Batch 693/3551] [D loss: 0.182151] [G loss: 0.907619]\n",
      "[Epoch 0/1] [Batch 694/3551] [D loss: 0.215394] [G loss: 0.910665]\n",
      "[Epoch 0/1] [Batch 695/3551] [D loss: 0.292264] [G loss: 0.916305]\n",
      "[Epoch 0/1] [Batch 696/3551] [D loss: 0.171199] [G loss: 0.910702]\n",
      "[Epoch 0/1] [Batch 697/3551] [D loss: 0.142912] [G loss: 0.908430]\n",
      "[Epoch 0/1] [Batch 698/3551] [D loss: 0.170479] [G loss: 0.926675]\n",
      "[Epoch 0/1] [Batch 699/3551] [D loss: 0.238669] [G loss: 0.948077]\n",
      "[Epoch 0/1] [Batch 700/3551] [D loss: 0.138475] [G loss: 0.927236]\n",
      "[Epoch 0/1] [Batch 701/3551] [D loss: 0.213949] [G loss: 0.943805]\n",
      "[Epoch 0/1] [Batch 702/3551] [D loss: 0.288534] [G loss: 0.941512]\n",
      "[Epoch 0/1] [Batch 703/3551] [D loss: 0.280976] [G loss: 0.928709]\n",
      "[Epoch 0/1] [Batch 704/3551] [D loss: 0.154004] [G loss: 0.922785]\n",
      "[Epoch 0/1] [Batch 705/3551] [D loss: 0.252503] [G loss: 0.946211]\n",
      "[Epoch 0/1] [Batch 706/3551] [D loss: 0.148774] [G loss: 0.913620]\n",
      "[Epoch 0/1] [Batch 707/3551] [D loss: 0.103454] [G loss: 0.908509]\n",
      "[Epoch 0/1] [Batch 708/3551] [D loss: 0.167990] [G loss: 0.967093]\n",
      "[Epoch 0/1] [Batch 709/3551] [D loss: 0.181754] [G loss: 0.918577]\n",
      "[Epoch 0/1] [Batch 710/3551] [D loss: 0.197346] [G loss: 0.899612]\n",
      "[Epoch 0/1] [Batch 711/3551] [D loss: 0.155241] [G loss: 0.905906]\n",
      "[Epoch 0/1] [Batch 712/3551] [D loss: 0.300284] [G loss: 0.915411]\n",
      "[Epoch 0/1] [Batch 713/3551] [D loss: 0.215847] [G loss: 0.934634]\n",
      "[Epoch 0/1] [Batch 714/3551] [D loss: 0.205773] [G loss: 0.917007]\n",
      "[Epoch 0/1] [Batch 715/3551] [D loss: 0.204876] [G loss: 0.935963]\n",
      "[Epoch 0/1] [Batch 716/3551] [D loss: 0.209174] [G loss: 0.914138]\n",
      "[Epoch 0/1] [Batch 717/3551] [D loss: 0.104720] [G loss: 0.944568]\n",
      "[Epoch 0/1] [Batch 718/3551] [D loss: 0.139813] [G loss: 0.955833]\n",
      "[Epoch 0/1] [Batch 719/3551] [D loss: 0.156028] [G loss: 0.939943]\n",
      "[Epoch 0/1] [Batch 720/3551] [D loss: 0.212606] [G loss: 0.945622]\n",
      "[Epoch 0/1] [Batch 721/3551] [D loss: 0.126677] [G loss: 0.965035]\n",
      "[Epoch 0/1] [Batch 722/3551] [D loss: 0.170947] [G loss: 0.932935]\n",
      "[Epoch 0/1] [Batch 723/3551] [D loss: 0.136749] [G loss: 0.931179]\n",
      "[Epoch 0/1] [Batch 724/3551] [D loss: 0.212205] [G loss: 0.934098]\n",
      "[Epoch 0/1] [Batch 725/3551] [D loss: 0.193503] [G loss: 0.954613]\n",
      "[Epoch 0/1] [Batch 726/3551] [D loss: 0.113064] [G loss: 0.945715]\n",
      "[Epoch 0/1] [Batch 727/3551] [D loss: 0.166459] [G loss: 0.917862]\n",
      "[Epoch 0/1] [Batch 728/3551] [D loss: 0.200784] [G loss: 0.946841]\n",
      "[Epoch 0/1] [Batch 729/3551] [D loss: 0.161739] [G loss: 0.933391]\n",
      "[Epoch 0/1] [Batch 730/3551] [D loss: 0.211672] [G loss: 0.929336]\n",
      "[Epoch 0/1] [Batch 731/3551] [D loss: 0.184666] [G loss: 0.944248]\n",
      "[Epoch 0/1] [Batch 732/3551] [D loss: 0.188966] [G loss: 0.911987]\n",
      "[Epoch 0/1] [Batch 733/3551] [D loss: 0.141911] [G loss: 0.958859]\n",
      "[Epoch 0/1] [Batch 734/3551] [D loss: 0.213797] [G loss: 0.899863]\n",
      "[Epoch 0/1] [Batch 735/3551] [D loss: 0.161887] [G loss: 0.954526]\n",
      "[Epoch 0/1] [Batch 736/3551] [D loss: 0.249739] [G loss: 0.945311]\n",
      "[Epoch 0/1] [Batch 737/3551] [D loss: 0.141320] [G loss: 0.932862]\n",
      "[Epoch 0/1] [Batch 738/3551] [D loss: 0.105694] [G loss: 0.945530]\n",
      "[Epoch 0/1] [Batch 739/3551] [D loss: 0.115340] [G loss: 0.937663]\n",
      "[Epoch 0/1] [Batch 740/3551] [D loss: 0.288919] [G loss: 0.966618]\n",
      "[Epoch 0/1] [Batch 741/3551] [D loss: 0.218769] [G loss: 0.890746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 742/3551] [D loss: 0.211688] [G loss: 0.924516]\n",
      "[Epoch 0/1] [Batch 743/3551] [D loss: 0.190832] [G loss: 0.888563]\n",
      "[Epoch 0/1] [Batch 744/3551] [D loss: 0.159663] [G loss: 0.928016]\n",
      "[Epoch 0/1] [Batch 745/3551] [D loss: 0.169901] [G loss: 0.930744]\n",
      "[Epoch 0/1] [Batch 746/3551] [D loss: 0.151381] [G loss: 0.926366]\n",
      "[Epoch 0/1] [Batch 747/3551] [D loss: 0.168840] [G loss: 0.928240]\n",
      "[Epoch 0/1] [Batch 748/3551] [D loss: 0.161973] [G loss: 0.908661]\n",
      "[Epoch 0/1] [Batch 749/3551] [D loss: 0.203783] [G loss: 0.917829]\n",
      "[Epoch 0/1] [Batch 750/3551] [D loss: 0.173071] [G loss: 0.949109]\n",
      "[Epoch 0/1] [Batch 751/3551] [D loss: 0.107146] [G loss: 0.941901]\n",
      "[Epoch 0/1] [Batch 752/3551] [D loss: 0.168121] [G loss: 0.920966]\n",
      "[Epoch 0/1] [Batch 753/3551] [D loss: 0.136460] [G loss: 0.940504]\n",
      "[Epoch 0/1] [Batch 754/3551] [D loss: 0.161680] [G loss: 0.931010]\n",
      "[Epoch 0/1] [Batch 755/3551] [D loss: 0.205552] [G loss: 0.944054]\n",
      "[Epoch 0/1] [Batch 756/3551] [D loss: 0.230678] [G loss: 0.918933]\n",
      "[Epoch 0/1] [Batch 757/3551] [D loss: 0.188734] [G loss: 0.897462]\n",
      "[Epoch 0/1] [Batch 758/3551] [D loss: 0.186225] [G loss: 0.928944]\n",
      "[Epoch 0/1] [Batch 759/3551] [D loss: 0.108391] [G loss: 0.913990]\n",
      "[Epoch 0/1] [Batch 760/3551] [D loss: 0.166250] [G loss: 0.932344]\n",
      "[Epoch 0/1] [Batch 761/3551] [D loss: 0.177041] [G loss: 0.944131]\n",
      "[Epoch 0/1] [Batch 762/3551] [D loss: 0.153467] [G loss: 0.906016]\n",
      "[Epoch 0/1] [Batch 763/3551] [D loss: 0.180195] [G loss: 0.927237]\n",
      "[Epoch 0/1] [Batch 764/3551] [D loss: 0.148990] [G loss: 0.925467]\n",
      "[Epoch 0/1] [Batch 765/3551] [D loss: 0.135758] [G loss: 0.916547]\n",
      "[Epoch 0/1] [Batch 766/3551] [D loss: 0.186289] [G loss: 0.928028]\n",
      "[Epoch 0/1] [Batch 767/3551] [D loss: 0.145742] [G loss: 0.935472]\n",
      "[Epoch 0/1] [Batch 768/3551] [D loss: 0.143305] [G loss: 0.919327]\n",
      "[Epoch 0/1] [Batch 769/3551] [D loss: 0.154721] [G loss: 0.905692]\n",
      "[Epoch 0/1] [Batch 770/3551] [D loss: 0.131462] [G loss: 0.916369]\n",
      "[Epoch 0/1] [Batch 771/3551] [D loss: 0.147076] [G loss: 0.929500]\n",
      "[Epoch 0/1] [Batch 772/3551] [D loss: 0.170698] [G loss: 0.937182]\n",
      "[Epoch 0/1] [Batch 773/3551] [D loss: 0.136562] [G loss: 0.949975]\n",
      "[Epoch 0/1] [Batch 774/3551] [D loss: 0.182478] [G loss: 0.950677]\n",
      "[Epoch 0/1] [Batch 775/3551] [D loss: 0.139813] [G loss: 0.936023]\n",
      "[Epoch 0/1] [Batch 776/3551] [D loss: 0.109829] [G loss: 0.917830]\n",
      "[Epoch 0/1] [Batch 777/3551] [D loss: 0.238212] [G loss: 0.914692]\n",
      "[Epoch 0/1] [Batch 778/3551] [D loss: 0.132336] [G loss: 0.917118]\n",
      "[Epoch 0/1] [Batch 779/3551] [D loss: 0.204184] [G loss: 0.945370]\n",
      "[Epoch 0/1] [Batch 780/3551] [D loss: 0.215251] [G loss: 0.938024]\n",
      "[Epoch 0/1] [Batch 781/3551] [D loss: 0.201500] [G loss: 0.930593]\n",
      "[Epoch 0/1] [Batch 782/3551] [D loss: 0.118419] [G loss: 0.966844]\n",
      "[Epoch 0/1] [Batch 783/3551] [D loss: 0.221339] [G loss: 0.914127]\n",
      "[Epoch 0/1] [Batch 784/3551] [D loss: 0.139212] [G loss: 0.913877]\n",
      "[Epoch 0/1] [Batch 785/3551] [D loss: 0.153991] [G loss: 0.956532]\n",
      "[Epoch 0/1] [Batch 786/3551] [D loss: 0.124260] [G loss: 0.948010]\n",
      "[Epoch 0/1] [Batch 787/3551] [D loss: 0.140581] [G loss: 0.917095]\n",
      "[Epoch 0/1] [Batch 788/3551] [D loss: 0.119659] [G loss: 0.932023]\n",
      "[Epoch 0/1] [Batch 789/3551] [D loss: 0.174615] [G loss: 0.960689]\n",
      "[Epoch 0/1] [Batch 790/3551] [D loss: 0.192001] [G loss: 0.938478]\n",
      "[Epoch 0/1] [Batch 791/3551] [D loss: 0.144585] [G loss: 0.893384]\n",
      "[Epoch 0/1] [Batch 792/3551] [D loss: 0.130360] [G loss: 0.916788]\n",
      "[Epoch 0/1] [Batch 793/3551] [D loss: 0.126172] [G loss: 0.939207]\n",
      "[Epoch 0/1] [Batch 794/3551] [D loss: 0.124905] [G loss: 0.919489]\n",
      "[Epoch 0/1] [Batch 795/3551] [D loss: 0.175185] [G loss: 0.905670]\n",
      "[Epoch 0/1] [Batch 796/3551] [D loss: 0.241680] [G loss: 0.923375]\n",
      "[Epoch 0/1] [Batch 797/3551] [D loss: 0.215666] [G loss: 0.901255]\n",
      "[Epoch 0/1] [Batch 798/3551] [D loss: 0.109428] [G loss: 0.928819]\n",
      "[Epoch 0/1] [Batch 799/3551] [D loss: 0.123807] [G loss: 0.913255]\n",
      "[Epoch 0/1] [Batch 800/3551] [D loss: 0.186225] [G loss: 0.919354]\n",
      "[Epoch 0/1] [Batch 801/3551] [D loss: 0.132981] [G loss: 0.967171]\n",
      "[Epoch 0/1] [Batch 802/3551] [D loss: 0.189493] [G loss: 0.942822]\n",
      "[Epoch 0/1] [Batch 803/3551] [D loss: 0.156712] [G loss: 0.919226]\n",
      "[Epoch 0/1] [Batch 804/3551] [D loss: 0.128814] [G loss: 0.918472]\n",
      "[Epoch 0/1] [Batch 805/3551] [D loss: 0.230638] [G loss: 0.936379]\n",
      "[Epoch 0/1] [Batch 806/3551] [D loss: 0.188249] [G loss: 0.958002]\n",
      "[Epoch 0/1] [Batch 807/3551] [D loss: 0.143630] [G loss: 0.938418]\n",
      "[Epoch 0/1] [Batch 808/3551] [D loss: 0.199071] [G loss: 0.939395]\n",
      "[Epoch 0/1] [Batch 809/3551] [D loss: 0.152096] [G loss: 0.918870]\n",
      "[Epoch 0/1] [Batch 810/3551] [D loss: 0.155945] [G loss: 0.954207]\n",
      "[Epoch 0/1] [Batch 811/3551] [D loss: 0.104672] [G loss: 0.953609]\n",
      "[Epoch 0/1] [Batch 812/3551] [D loss: 0.220886] [G loss: 0.955523]\n",
      "[Epoch 0/1] [Batch 813/3551] [D loss: 0.116492] [G loss: 0.942520]\n",
      "[Epoch 0/1] [Batch 814/3551] [D loss: 0.181600] [G loss: 0.931287]\n",
      "[Epoch 0/1] [Batch 815/3551] [D loss: 0.159939] [G loss: 0.947480]\n",
      "[Epoch 0/1] [Batch 816/3551] [D loss: 0.175571] [G loss: 0.943918]\n",
      "[Epoch 0/1] [Batch 817/3551] [D loss: 0.125862] [G loss: 0.957222]\n",
      "[Epoch 0/1] [Batch 818/3551] [D loss: 0.148487] [G loss: 0.934890]\n",
      "[Epoch 0/1] [Batch 819/3551] [D loss: 0.114277] [G loss: 0.931848]\n",
      "[Epoch 0/1] [Batch 820/3551] [D loss: 0.138966] [G loss: 0.949168]\n",
      "[Epoch 0/1] [Batch 821/3551] [D loss: 0.136524] [G loss: 0.959322]\n",
      "[Epoch 0/1] [Batch 822/3551] [D loss: 0.136994] [G loss: 0.940761]\n",
      "[Epoch 0/1] [Batch 823/3551] [D loss: 0.108626] [G loss: 0.938741]\n",
      "[Epoch 0/1] [Batch 824/3551] [D loss: 0.157565] [G loss: 0.929458]\n",
      "[Epoch 0/1] [Batch 825/3551] [D loss: 0.094777] [G loss: 0.965636]\n",
      "[Epoch 0/1] [Batch 826/3551] [D loss: 0.201998] [G loss: 0.931818]\n",
      "[Epoch 0/1] [Batch 827/3551] [D loss: 0.116524] [G loss: 0.944779]\n",
      "[Epoch 0/1] [Batch 828/3551] [D loss: 0.138241] [G loss: 0.947099]\n",
      "[Epoch 0/1] [Batch 829/3551] [D loss: 0.185396] [G loss: 0.968587]\n",
      "[Epoch 0/1] [Batch 830/3551] [D loss: 0.200755] [G loss: 0.945614]\n",
      "[Epoch 0/1] [Batch 831/3551] [D loss: 0.164673] [G loss: 0.924343]\n",
      "[Epoch 0/1] [Batch 832/3551] [D loss: 0.116151] [G loss: 0.922438]\n",
      "[Epoch 0/1] [Batch 833/3551] [D loss: 0.150797] [G loss: 0.921583]\n",
      "[Epoch 0/1] [Batch 834/3551] [D loss: 0.158901] [G loss: 0.954171]\n",
      "[Epoch 0/1] [Batch 835/3551] [D loss: 0.195523] [G loss: 0.969033]\n",
      "[Epoch 0/1] [Batch 836/3551] [D loss: 0.125548] [G loss: 0.956961]\n",
      "[Epoch 0/1] [Batch 837/3551] [D loss: 0.214591] [G loss: 0.907404]\n",
      "[Epoch 0/1] [Batch 838/3551] [D loss: 0.141151] [G loss: 0.927472]\n",
      "[Epoch 0/1] [Batch 839/3551] [D loss: 0.117804] [G loss: 0.957387]\n",
      "[Epoch 0/1] [Batch 840/3551] [D loss: 0.054625] [G loss: 0.962892]\n",
      "[Epoch 0/1] [Batch 841/3551] [D loss: 0.190230] [G loss: 0.945338]\n",
      "[Epoch 0/1] [Batch 842/3551] [D loss: 0.144858] [G loss: 0.956177]\n",
      "[Epoch 0/1] [Batch 843/3551] [D loss: 0.133399] [G loss: 0.932635]\n",
      "[Epoch 0/1] [Batch 844/3551] [D loss: 0.187168] [G loss: 0.932848]\n",
      "[Epoch 0/1] [Batch 845/3551] [D loss: 0.166344] [G loss: 0.948528]\n",
      "[Epoch 0/1] [Batch 846/3551] [D loss: 0.152841] [G loss: 0.930527]\n",
      "[Epoch 0/1] [Batch 847/3551] [D loss: 0.186802] [G loss: 0.941157]\n",
      "[Epoch 0/1] [Batch 848/3551] [D loss: 0.124408] [G loss: 0.928719]\n",
      "[Epoch 0/1] [Batch 849/3551] [D loss: 0.117578] [G loss: 0.937829]\n",
      "[Epoch 0/1] [Batch 850/3551] [D loss: 0.123752] [G loss: 0.914776]\n",
      "[Epoch 0/1] [Batch 851/3551] [D loss: 0.095227] [G loss: 0.948954]\n",
      "[Epoch 0/1] [Batch 852/3551] [D loss: 0.103726] [G loss: 0.930082]\n",
      "[Epoch 0/1] [Batch 853/3551] [D loss: 0.212920] [G loss: 0.967182]\n",
      "[Epoch 0/1] [Batch 854/3551] [D loss: 0.117042] [G loss: 0.926549]\n",
      "[Epoch 0/1] [Batch 855/3551] [D loss: 0.175798] [G loss: 0.938331]\n",
      "[Epoch 0/1] [Batch 856/3551] [D loss: 0.180050] [G loss: 0.950911]\n",
      "[Epoch 0/1] [Batch 857/3551] [D loss: 0.138979] [G loss: 0.936452]\n",
      "[Epoch 0/1] [Batch 858/3551] [D loss: 0.199928] [G loss: 0.922769]\n",
      "[Epoch 0/1] [Batch 859/3551] [D loss: 0.137963] [G loss: 0.925948]\n",
      "[Epoch 0/1] [Batch 860/3551] [D loss: 0.169418] [G loss: 0.943169]\n",
      "[Epoch 0/1] [Batch 861/3551] [D loss: 0.243183] [G loss: 0.916471]\n",
      "[Epoch 0/1] [Batch 862/3551] [D loss: 0.139217] [G loss: 0.923805]\n",
      "[Epoch 0/1] [Batch 863/3551] [D loss: 0.226399] [G loss: 0.927150]\n",
      "[Epoch 0/1] [Batch 864/3551] [D loss: 0.158732] [G loss: 0.937377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 865/3551] [D loss: 0.135054] [G loss: 0.960089]\n",
      "[Epoch 0/1] [Batch 866/3551] [D loss: 0.208188] [G loss: 0.960960]\n",
      "[Epoch 0/1] [Batch 867/3551] [D loss: 0.155685] [G loss: 0.966934]\n",
      "[Epoch 0/1] [Batch 868/3551] [D loss: 0.100845] [G loss: 0.930077]\n",
      "[Epoch 0/1] [Batch 869/3551] [D loss: 0.138328] [G loss: 0.925592]\n",
      "[Epoch 0/1] [Batch 870/3551] [D loss: 0.190038] [G loss: 0.935753]\n",
      "[Epoch 0/1] [Batch 871/3551] [D loss: 0.221114] [G loss: 0.898101]\n",
      "[Epoch 0/1] [Batch 872/3551] [D loss: 0.108790] [G loss: 0.946805]\n",
      "[Epoch 0/1] [Batch 873/3551] [D loss: 0.150401] [G loss: 0.930551]\n",
      "[Epoch 0/1] [Batch 874/3551] [D loss: 0.100062] [G loss: 0.923183]\n",
      "[Epoch 0/1] [Batch 875/3551] [D loss: 0.164917] [G loss: 0.957462]\n",
      "[Epoch 0/1] [Batch 876/3551] [D loss: 0.190207] [G loss: 0.932839]\n",
      "[Epoch 0/1] [Batch 877/3551] [D loss: 0.131289] [G loss: 0.931174]\n",
      "[Epoch 0/1] [Batch 878/3551] [D loss: 0.154131] [G loss: 0.950042]\n",
      "[Epoch 0/1] [Batch 879/3551] [D loss: 0.093633] [G loss: 0.982130]\n",
      "[Epoch 0/1] [Batch 880/3551] [D loss: 0.145866] [G loss: 0.922999]\n",
      "[Epoch 0/1] [Batch 881/3551] [D loss: 0.106594] [G loss: 0.932619]\n",
      "[Epoch 0/1] [Batch 882/3551] [D loss: 0.142008] [G loss: 0.959970]\n",
      "[Epoch 0/1] [Batch 883/3551] [D loss: 0.163812] [G loss: 0.934231]\n",
      "[Epoch 0/1] [Batch 884/3551] [D loss: 0.134993] [G loss: 0.939000]\n",
      "[Epoch 0/1] [Batch 885/3551] [D loss: 0.156130] [G loss: 0.947286]\n",
      "[Epoch 0/1] [Batch 886/3551] [D loss: 0.172005] [G loss: 0.937581]\n",
      "[Epoch 0/1] [Batch 887/3551] [D loss: 0.136154] [G loss: 0.953075]\n",
      "[Epoch 0/1] [Batch 888/3551] [D loss: 0.214410] [G loss: 0.940511]\n",
      "[Epoch 0/1] [Batch 889/3551] [D loss: 0.144934] [G loss: 0.956046]\n",
      "[Epoch 0/1] [Batch 890/3551] [D loss: 0.168635] [G loss: 0.958362]\n",
      "[Epoch 0/1] [Batch 891/3551] [D loss: 0.105640] [G loss: 0.955485]\n",
      "[Epoch 0/1] [Batch 892/3551] [D loss: 0.190893] [G loss: 0.938909]\n",
      "[Epoch 0/1] [Batch 893/3551] [D loss: 0.146127] [G loss: 0.946850]\n",
      "[Epoch 0/1] [Batch 894/3551] [D loss: 0.134406] [G loss: 0.930834]\n",
      "[Epoch 0/1] [Batch 895/3551] [D loss: 0.146270] [G loss: 0.956672]\n",
      "[Epoch 0/1] [Batch 896/3551] [D loss: 0.110900] [G loss: 0.938121]\n",
      "[Epoch 0/1] [Batch 897/3551] [D loss: 0.118842] [G loss: 0.941039]\n",
      "[Epoch 0/1] [Batch 898/3551] [D loss: 0.146554] [G loss: 0.958000]\n",
      "[Epoch 0/1] [Batch 899/3551] [D loss: 0.100713] [G loss: 0.951445]\n",
      "[Epoch 0/1] [Batch 900/3551] [D loss: 0.099225] [G loss: 0.953829]\n",
      "[Epoch 0/1] [Batch 901/3551] [D loss: 0.098461] [G loss: 0.938755]\n",
      "[Epoch 0/1] [Batch 902/3551] [D loss: 0.111456] [G loss: 0.946692]\n",
      "[Epoch 0/1] [Batch 903/3551] [D loss: 0.126005] [G loss: 0.949174]\n",
      "[Epoch 0/1] [Batch 904/3551] [D loss: 0.246075] [G loss: 0.929243]\n",
      "[Epoch 0/1] [Batch 905/3551] [D loss: 0.138213] [G loss: 0.941032]\n",
      "[Epoch 0/1] [Batch 906/3551] [D loss: 0.128247] [G loss: 0.949514]\n",
      "[Epoch 0/1] [Batch 907/3551] [D loss: 0.110106] [G loss: 0.931768]\n",
      "[Epoch 0/1] [Batch 908/3551] [D loss: 0.189557] [G loss: 0.939838]\n",
      "[Epoch 0/1] [Batch 909/3551] [D loss: 0.178679] [G loss: 0.932290]\n",
      "[Epoch 0/1] [Batch 910/3551] [D loss: 0.159090] [G loss: 0.926588]\n",
      "[Epoch 0/1] [Batch 911/3551] [D loss: 0.154140] [G loss: 0.938408]\n",
      "[Epoch 0/1] [Batch 912/3551] [D loss: 0.128537] [G loss: 0.949391]\n",
      "[Epoch 0/1] [Batch 913/3551] [D loss: 0.171952] [G loss: 0.947647]\n",
      "[Epoch 0/1] [Batch 914/3551] [D loss: 0.156377] [G loss: 0.935696]\n",
      "[Epoch 0/1] [Batch 915/3551] [D loss: 0.156166] [G loss: 0.946906]\n",
      "[Epoch 0/1] [Batch 916/3551] [D loss: 0.124696] [G loss: 0.936035]\n",
      "[Epoch 0/1] [Batch 917/3551] [D loss: 0.096975] [G loss: 0.945517]\n",
      "[Epoch 0/1] [Batch 918/3551] [D loss: 0.133584] [G loss: 0.965504]\n",
      "[Epoch 0/1] [Batch 919/3551] [D loss: 0.149784] [G loss: 0.938697]\n",
      "[Epoch 0/1] [Batch 920/3551] [D loss: 0.126287] [G loss: 0.973108]\n",
      "[Epoch 0/1] [Batch 921/3551] [D loss: 0.200694] [G loss: 0.928443]\n",
      "[Epoch 0/1] [Batch 922/3551] [D loss: 0.151869] [G loss: 0.940814]\n",
      "[Epoch 0/1] [Batch 923/3551] [D loss: 0.115652] [G loss: 0.957513]\n",
      "[Epoch 0/1] [Batch 924/3551] [D loss: 0.138754] [G loss: 0.949970]\n",
      "[Epoch 0/1] [Batch 925/3551] [D loss: 0.158667] [G loss: 0.940416]\n",
      "[Epoch 0/1] [Batch 926/3551] [D loss: 0.171791] [G loss: 0.942778]\n",
      "[Epoch 0/1] [Batch 927/3551] [D loss: 0.130121] [G loss: 0.944185]\n",
      "[Epoch 0/1] [Batch 928/3551] [D loss: 0.169731] [G loss: 0.941442]\n",
      "[Epoch 0/1] [Batch 929/3551] [D loss: 0.131948] [G loss: 0.967461]\n",
      "[Epoch 0/1] [Batch 930/3551] [D loss: 0.136096] [G loss: 0.931266]\n",
      "[Epoch 0/1] [Batch 931/3551] [D loss: 0.195103] [G loss: 0.929442]\n",
      "[Epoch 0/1] [Batch 932/3551] [D loss: 0.212196] [G loss: 0.953243]\n",
      "[Epoch 0/1] [Batch 933/3551] [D loss: 0.087975] [G loss: 0.945827]\n",
      "[Epoch 0/1] [Batch 934/3551] [D loss: 0.136017] [G loss: 0.943301]\n",
      "[Epoch 0/1] [Batch 935/3551] [D loss: 0.114002] [G loss: 0.965182]\n",
      "[Epoch 0/1] [Batch 936/3551] [D loss: 0.125876] [G loss: 0.942124]\n",
      "[Epoch 0/1] [Batch 937/3551] [D loss: 0.145292] [G loss: 0.955250]\n",
      "[Epoch 0/1] [Batch 938/3551] [D loss: 0.161456] [G loss: 0.930764]\n",
      "[Epoch 0/1] [Batch 939/3551] [D loss: 0.154523] [G loss: 0.939900]\n",
      "[Epoch 0/1] [Batch 940/3551] [D loss: 0.114880] [G loss: 0.952760]\n",
      "[Epoch 0/1] [Batch 941/3551] [D loss: 0.125609] [G loss: 0.953686]\n",
      "[Epoch 0/1] [Batch 942/3551] [D loss: 0.084604] [G loss: 0.941466]\n",
      "[Epoch 0/1] [Batch 943/3551] [D loss: 0.114178] [G loss: 0.934376]\n",
      "[Epoch 0/1] [Batch 944/3551] [D loss: 0.103779] [G loss: 0.979213]\n",
      "[Epoch 0/1] [Batch 945/3551] [D loss: 0.168066] [G loss: 0.960081]\n",
      "[Epoch 0/1] [Batch 946/3551] [D loss: 0.141631] [G loss: 0.915467]\n",
      "[Epoch 0/1] [Batch 947/3551] [D loss: 0.148412] [G loss: 0.938597]\n",
      "[Epoch 0/1] [Batch 948/3551] [D loss: 0.100625] [G loss: 0.920150]\n",
      "[Epoch 0/1] [Batch 949/3551] [D loss: 0.096103] [G loss: 0.933509]\n",
      "[Epoch 0/1] [Batch 950/3551] [D loss: 0.162313] [G loss: 0.927132]\n",
      "[Epoch 0/1] [Batch 951/3551] [D loss: 0.104323] [G loss: 0.977882]\n",
      "[Epoch 0/1] [Batch 952/3551] [D loss: 0.086152] [G loss: 0.958281]\n",
      "[Epoch 0/1] [Batch 953/3551] [D loss: 0.092778] [G loss: 0.937236]\n",
      "[Epoch 0/1] [Batch 954/3551] [D loss: 0.163516] [G loss: 0.950857]\n",
      "[Epoch 0/1] [Batch 955/3551] [D loss: 0.095474] [G loss: 0.939898]\n",
      "[Epoch 0/1] [Batch 956/3551] [D loss: 0.109586] [G loss: 0.916761]\n",
      "[Epoch 0/1] [Batch 957/3551] [D loss: 0.152821] [G loss: 0.916182]\n",
      "[Epoch 0/1] [Batch 958/3551] [D loss: 0.127967] [G loss: 0.977804]\n",
      "[Epoch 0/1] [Batch 959/3551] [D loss: 0.162825] [G loss: 0.966890]\n",
      "[Epoch 0/1] [Batch 960/3551] [D loss: 0.080779] [G loss: 0.966491]\n",
      "[Epoch 0/1] [Batch 961/3551] [D loss: 0.085780] [G loss: 0.953437]\n",
      "[Epoch 0/1] [Batch 962/3551] [D loss: 0.104665] [G loss: 0.966255]\n",
      "[Epoch 0/1] [Batch 963/3551] [D loss: 0.171065] [G loss: 0.937830]\n",
      "[Epoch 0/1] [Batch 964/3551] [D loss: 0.059815] [G loss: 0.982326]\n",
      "[Epoch 0/1] [Batch 965/3551] [D loss: 0.141965] [G loss: 0.956458]\n",
      "[Epoch 0/1] [Batch 966/3551] [D loss: 0.075700] [G loss: 0.952065]\n",
      "[Epoch 0/1] [Batch 967/3551] [D loss: 0.149281] [G loss: 0.937915]\n",
      "[Epoch 0/1] [Batch 968/3551] [D loss: 0.115902] [G loss: 0.951767]\n",
      "[Epoch 0/1] [Batch 969/3551] [D loss: 0.090050] [G loss: 0.976372]\n",
      "[Epoch 0/1] [Batch 970/3551] [D loss: 0.103080] [G loss: 0.926221]\n",
      "[Epoch 0/1] [Batch 971/3551] [D loss: 0.143936] [G loss: 0.941318]\n",
      "[Epoch 0/1] [Batch 972/3551] [D loss: 0.082932] [G loss: 0.951258]\n",
      "[Epoch 0/1] [Batch 973/3551] [D loss: 0.094882] [G loss: 0.930923]\n",
      "[Epoch 0/1] [Batch 974/3551] [D loss: 0.140914] [G loss: 0.974940]\n",
      "[Epoch 0/1] [Batch 975/3551] [D loss: 0.093578] [G loss: 0.963816]\n",
      "[Epoch 0/1] [Batch 976/3551] [D loss: 0.091195] [G loss: 0.949026]\n",
      "[Epoch 0/1] [Batch 977/3551] [D loss: 0.133933] [G loss: 0.954543]\n",
      "[Epoch 0/1] [Batch 978/3551] [D loss: 0.107002] [G loss: 0.953611]\n",
      "[Epoch 0/1] [Batch 979/3551] [D loss: 0.152977] [G loss: 0.961860]\n",
      "[Epoch 0/1] [Batch 980/3551] [D loss: 0.178867] [G loss: 0.952389]\n",
      "[Epoch 0/1] [Batch 981/3551] [D loss: 0.117940] [G loss: 0.946985]\n",
      "[Epoch 0/1] [Batch 982/3551] [D loss: 0.148038] [G loss: 0.966830]\n",
      "[Epoch 0/1] [Batch 983/3551] [D loss: 0.228118] [G loss: 0.973569]\n",
      "[Epoch 0/1] [Batch 984/3551] [D loss: 0.084139] [G loss: 0.961548]\n",
      "[Epoch 0/1] [Batch 985/3551] [D loss: 0.093492] [G loss: 0.970179]\n",
      "[Epoch 0/1] [Batch 986/3551] [D loss: 0.129976] [G loss: 0.944022]\n",
      "[Epoch 0/1] [Batch 987/3551] [D loss: 0.217883] [G loss: 0.943782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 988/3551] [D loss: 0.102279] [G loss: 0.952717]\n",
      "[Epoch 0/1] [Batch 989/3551] [D loss: 0.130141] [G loss: 0.970806]\n",
      "[Epoch 0/1] [Batch 990/3551] [D loss: 0.128085] [G loss: 0.959341]\n",
      "[Epoch 0/1] [Batch 991/3551] [D loss: 0.137593] [G loss: 0.964295]\n",
      "[Epoch 0/1] [Batch 992/3551] [D loss: 0.117137] [G loss: 0.954493]\n",
      "[Epoch 0/1] [Batch 993/3551] [D loss: 0.138727] [G loss: 0.955898]\n",
      "[Epoch 0/1] [Batch 994/3551] [D loss: 0.130396] [G loss: 0.965458]\n",
      "[Epoch 0/1] [Batch 995/3551] [D loss: 0.121608] [G loss: 0.959799]\n",
      "[Epoch 0/1] [Batch 996/3551] [D loss: 0.123874] [G loss: 0.921201]\n",
      "[Epoch 0/1] [Batch 997/3551] [D loss: 0.123029] [G loss: 0.952280]\n",
      "[Epoch 0/1] [Batch 998/3551] [D loss: 0.113679] [G loss: 0.966531]\n",
      "[Epoch 0/1] [Batch 999/3551] [D loss: 0.115119] [G loss: 0.953669]\n",
      "[Epoch 0/1] [Batch 1000/3551] [D loss: 0.134056] [G loss: 0.964014]\n",
      "[Epoch 0/1] [Batch 1001/3551] [D loss: 0.069471] [G loss: 0.954786]\n",
      "[Epoch 0/1] [Batch 1002/3551] [D loss: 0.172377] [G loss: 0.930380]\n",
      "[Epoch 0/1] [Batch 1003/3551] [D loss: 0.106395] [G loss: 0.967046]\n",
      "[Epoch 0/1] [Batch 1004/3551] [D loss: 0.163090] [G loss: 0.941892]\n",
      "[Epoch 0/1] [Batch 1005/3551] [D loss: 0.098581] [G loss: 0.950454]\n",
      "[Epoch 0/1] [Batch 1006/3551] [D loss: 0.100067] [G loss: 0.958843]\n",
      "[Epoch 0/1] [Batch 1007/3551] [D loss: 0.075090] [G loss: 0.963117]\n",
      "[Epoch 0/1] [Batch 1008/3551] [D loss: 0.095195] [G loss: 0.933301]\n",
      "[Epoch 0/1] [Batch 1009/3551] [D loss: 0.175865] [G loss: 0.957243]\n",
      "[Epoch 0/1] [Batch 1010/3551] [D loss: 0.069864] [G loss: 0.952678]\n",
      "[Epoch 0/1] [Batch 1011/3551] [D loss: 0.143399] [G loss: 0.972072]\n",
      "[Epoch 0/1] [Batch 1012/3551] [D loss: 0.123081] [G loss: 0.958570]\n",
      "[Epoch 0/1] [Batch 1013/3551] [D loss: 0.146363] [G loss: 0.964745]\n",
      "[Epoch 0/1] [Batch 1014/3551] [D loss: 0.136265] [G loss: 0.956114]\n",
      "[Epoch 0/1] [Batch 1015/3551] [D loss: 0.143919] [G loss: 0.944156]\n",
      "[Epoch 0/1] [Batch 1016/3551] [D loss: 0.111372] [G loss: 0.964771]\n",
      "[Epoch 0/1] [Batch 1017/3551] [D loss: 0.125726] [G loss: 0.958730]\n",
      "[Epoch 0/1] [Batch 1018/3551] [D loss: 0.147912] [G loss: 0.962124]\n",
      "[Epoch 0/1] [Batch 1019/3551] [D loss: 0.164458] [G loss: 0.961031]\n",
      "[Epoch 0/1] [Batch 1020/3551] [D loss: 0.117853] [G loss: 0.959676]\n",
      "[Epoch 0/1] [Batch 1021/3551] [D loss: 0.143953] [G loss: 0.944031]\n",
      "[Epoch 0/1] [Batch 1022/3551] [D loss: 0.188137] [G loss: 0.945108]\n",
      "[Epoch 0/1] [Batch 1023/3551] [D loss: 0.127905] [G loss: 0.974692]\n",
      "[Epoch 0/1] [Batch 1024/3551] [D loss: 0.052011] [G loss: 0.926687]\n",
      "[Epoch 0/1] [Batch 1025/3551] [D loss: 0.125028] [G loss: 0.944079]\n",
      "[Epoch 0/1] [Batch 1026/3551] [D loss: 0.102062] [G loss: 0.944353]\n",
      "[Epoch 0/1] [Batch 1027/3551] [D loss: 0.178236] [G loss: 0.965604]\n",
      "[Epoch 0/1] [Batch 1028/3551] [D loss: 0.123902] [G loss: 0.952901]\n",
      "[Epoch 0/1] [Batch 1029/3551] [D loss: 0.134153] [G loss: 0.957844]\n",
      "[Epoch 0/1] [Batch 1030/3551] [D loss: 0.135803] [G loss: 0.951461]\n",
      "[Epoch 0/1] [Batch 1031/3551] [D loss: 0.122148] [G loss: 0.965351]\n",
      "[Epoch 0/1] [Batch 1032/3551] [D loss: 0.181383] [G loss: 0.938453]\n",
      "[Epoch 0/1] [Batch 1033/3551] [D loss: 0.095993] [G loss: 0.947398]\n",
      "[Epoch 0/1] [Batch 1034/3551] [D loss: 0.079153] [G loss: 0.971032]\n",
      "[Epoch 0/1] [Batch 1035/3551] [D loss: 0.158494] [G loss: 0.948831]\n",
      "[Epoch 0/1] [Batch 1036/3551] [D loss: 0.116456] [G loss: 0.958257]\n",
      "[Epoch 0/1] [Batch 1037/3551] [D loss: 0.097932] [G loss: 0.916381]\n",
      "[Epoch 0/1] [Batch 1038/3551] [D loss: 0.084147] [G loss: 0.947611]\n",
      "[Epoch 0/1] [Batch 1039/3551] [D loss: 0.074698] [G loss: 0.944612]\n",
      "[Epoch 0/1] [Batch 1040/3551] [D loss: 0.101570] [G loss: 0.943197]\n",
      "[Epoch 0/1] [Batch 1041/3551] [D loss: 0.156167] [G loss: 0.944868]\n",
      "[Epoch 0/1] [Batch 1042/3551] [D loss: 0.119149] [G loss: 0.973367]\n",
      "[Epoch 0/1] [Batch 1043/3551] [D loss: 0.132014] [G loss: 0.959579]\n",
      "[Epoch 0/1] [Batch 1044/3551] [D loss: 0.097904] [G loss: 0.979293]\n",
      "[Epoch 0/1] [Batch 1045/3551] [D loss: 0.119075] [G loss: 0.969504]\n",
      "[Epoch 0/1] [Batch 1046/3551] [D loss: 0.131622] [G loss: 0.946918]\n",
      "[Epoch 0/1] [Batch 1047/3551] [D loss: 0.124463] [G loss: 0.936391]\n",
      "[Epoch 0/1] [Batch 1048/3551] [D loss: 0.123669] [G loss: 0.965518]\n",
      "[Epoch 0/1] [Batch 1049/3551] [D loss: 0.112094] [G loss: 0.962260]\n",
      "[Epoch 0/1] [Batch 1050/3551] [D loss: 0.162025] [G loss: 0.947114]\n",
      "[Epoch 0/1] [Batch 1051/3551] [D loss: 0.151640] [G loss: 0.939615]\n",
      "[Epoch 0/1] [Batch 1052/3551] [D loss: 0.109192] [G loss: 0.959185]\n",
      "[Epoch 0/1] [Batch 1053/3551] [D loss: 0.143246] [G loss: 0.957864]\n",
      "[Epoch 0/1] [Batch 1054/3551] [D loss: 0.109459] [G loss: 0.950128]\n",
      "[Epoch 0/1] [Batch 1055/3551] [D loss: 0.122930] [G loss: 0.976074]\n",
      "[Epoch 0/1] [Batch 1056/3551] [D loss: 0.104039] [G loss: 0.965549]\n",
      "[Epoch 0/1] [Batch 1057/3551] [D loss: 0.116993] [G loss: 0.971652]\n",
      "[Epoch 0/1] [Batch 1058/3551] [D loss: 0.157034] [G loss: 0.967666]\n",
      "[Epoch 0/1] [Batch 1059/3551] [D loss: 0.106848] [G loss: 0.949397]\n",
      "[Epoch 0/1] [Batch 1060/3551] [D loss: 0.123629] [G loss: 0.972535]\n",
      "[Epoch 0/1] [Batch 1061/3551] [D loss: 0.131037] [G loss: 0.970338]\n",
      "[Epoch 0/1] [Batch 1062/3551] [D loss: 0.089579] [G loss: 0.946639]\n",
      "[Epoch 0/1] [Batch 1063/3551] [D loss: 0.110490] [G loss: 0.980680]\n",
      "[Epoch 0/1] [Batch 1064/3551] [D loss: 0.080937] [G loss: 0.954002]\n",
      "[Epoch 0/1] [Batch 1065/3551] [D loss: 0.115686] [G loss: 0.940943]\n",
      "[Epoch 0/1] [Batch 1066/3551] [D loss: 0.085368] [G loss: 0.979453]\n",
      "[Epoch 0/1] [Batch 1067/3551] [D loss: 0.103427] [G loss: 0.955086]\n",
      "[Epoch 0/1] [Batch 1068/3551] [D loss: 0.119513] [G loss: 0.952048]\n",
      "[Epoch 0/1] [Batch 1069/3551] [D loss: 0.146355] [G loss: 0.968383]\n",
      "[Epoch 0/1] [Batch 1070/3551] [D loss: 0.103707] [G loss: 0.955103]\n",
      "[Epoch 0/1] [Batch 1071/3551] [D loss: 0.126407] [G loss: 0.977807]\n",
      "[Epoch 0/1] [Batch 1072/3551] [D loss: 0.092664] [G loss: 0.953732]\n",
      "[Epoch 0/1] [Batch 1073/3551] [D loss: 0.135175] [G loss: 0.956322]\n",
      "[Epoch 0/1] [Batch 1074/3551] [D loss: 0.160801] [G loss: 0.923785]\n",
      "[Epoch 0/1] [Batch 1075/3551] [D loss: 0.125417] [G loss: 0.975503]\n",
      "[Epoch 0/1] [Batch 1076/3551] [D loss: 0.078339] [G loss: 0.954524]\n",
      "[Epoch 0/1] [Batch 1077/3551] [D loss: 0.151395] [G loss: 0.976593]\n",
      "[Epoch 0/1] [Batch 1078/3551] [D loss: 0.116210] [G loss: 0.959144]\n",
      "[Epoch 0/1] [Batch 1079/3551] [D loss: 0.177534] [G loss: 0.937874]\n",
      "[Epoch 0/1] [Batch 1080/3551] [D loss: 0.094826] [G loss: 0.978909]\n",
      "[Epoch 0/1] [Batch 1081/3551] [D loss: 0.106607] [G loss: 0.950480]\n",
      "[Epoch 0/1] [Batch 1082/3551] [D loss: 0.083399] [G loss: 0.966866]\n",
      "[Epoch 0/1] [Batch 1083/3551] [D loss: 0.123417] [G loss: 0.943943]\n",
      "[Epoch 0/1] [Batch 1084/3551] [D loss: 0.105386] [G loss: 0.937918]\n",
      "[Epoch 0/1] [Batch 1085/3551] [D loss: 0.117210] [G loss: 0.940199]\n",
      "[Epoch 0/1] [Batch 1086/3551] [D loss: 0.163434] [G loss: 0.948866]\n",
      "[Epoch 0/1] [Batch 1087/3551] [D loss: 0.156620] [G loss: 0.975895]\n",
      "[Epoch 0/1] [Batch 1088/3551] [D loss: 0.117632] [G loss: 0.967132]\n",
      "[Epoch 0/1] [Batch 1089/3551] [D loss: 0.083892] [G loss: 0.931520]\n",
      "[Epoch 0/1] [Batch 1090/3551] [D loss: 0.114089] [G loss: 0.964142]\n",
      "[Epoch 0/1] [Batch 1091/3551] [D loss: 0.137537] [G loss: 0.958295]\n",
      "[Epoch 0/1] [Batch 1092/3551] [D loss: 0.075086] [G loss: 0.961625]\n",
      "[Epoch 0/1] [Batch 1093/3551] [D loss: 0.162744] [G loss: 0.993751]\n",
      "[Epoch 0/1] [Batch 1094/3551] [D loss: 0.113552] [G loss: 0.987094]\n",
      "[Epoch 0/1] [Batch 1095/3551] [D loss: 0.142096] [G loss: 0.963975]\n",
      "[Epoch 0/1] [Batch 1096/3551] [D loss: 0.091756] [G loss: 0.935198]\n",
      "[Epoch 0/1] [Batch 1097/3551] [D loss: 0.117912] [G loss: 0.969652]\n",
      "[Epoch 0/1] [Batch 1098/3551] [D loss: 0.118536] [G loss: 0.960019]\n",
      "[Epoch 0/1] [Batch 1099/3551] [D loss: 0.096677] [G loss: 0.960028]\n",
      "[Epoch 0/1] [Batch 1100/3551] [D loss: 0.110258] [G loss: 0.956882]\n",
      "[Epoch 0/1] [Batch 1101/3551] [D loss: 0.057569] [G loss: 0.960344]\n",
      "[Epoch 0/1] [Batch 1102/3551] [D loss: 0.145926] [G loss: 0.944811]\n",
      "[Epoch 0/1] [Batch 1103/3551] [D loss: 0.108179] [G loss: 0.955070]\n",
      "[Epoch 0/1] [Batch 1104/3551] [D loss: 0.142579] [G loss: 0.948084]\n",
      "[Epoch 0/1] [Batch 1105/3551] [D loss: 0.108409] [G loss: 0.944046]\n",
      "[Epoch 0/1] [Batch 1106/3551] [D loss: 0.112037] [G loss: 0.949255]\n",
      "[Epoch 0/1] [Batch 1107/3551] [D loss: 0.158904] [G loss: 0.955764]\n",
      "[Epoch 0/1] [Batch 1108/3551] [D loss: 0.056303] [G loss: 0.964858]\n",
      "[Epoch 0/1] [Batch 1109/3551] [D loss: 0.086297] [G loss: 0.937252]\n",
      "[Epoch 0/1] [Batch 1110/3551] [D loss: 0.101291] [G loss: 0.970210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1111/3551] [D loss: 0.135991] [G loss: 0.947699]\n",
      "[Epoch 0/1] [Batch 1112/3551] [D loss: 0.136251] [G loss: 0.946922]\n",
      "[Epoch 0/1] [Batch 1113/3551] [D loss: 0.116933] [G loss: 0.955201]\n",
      "[Epoch 0/1] [Batch 1114/3551] [D loss: 0.076789] [G loss: 0.962751]\n",
      "[Epoch 0/1] [Batch 1115/3551] [D loss: 0.142800] [G loss: 0.950864]\n",
      "[Epoch 0/1] [Batch 1116/3551] [D loss: 0.151478] [G loss: 0.936988]\n",
      "[Epoch 0/1] [Batch 1117/3551] [D loss: 0.081768] [G loss: 0.953328]\n",
      "[Epoch 0/1] [Batch 1118/3551] [D loss: 0.125970] [G loss: 0.927585]\n",
      "[Epoch 0/1] [Batch 1119/3551] [D loss: 0.097988] [G loss: 0.938705]\n",
      "[Epoch 0/1] [Batch 1120/3551] [D loss: 0.140450] [G loss: 0.959982]\n",
      "[Epoch 0/1] [Batch 1121/3551] [D loss: 0.102579] [G loss: 0.947155]\n",
      "[Epoch 0/1] [Batch 1122/3551] [D loss: 0.111804] [G loss: 0.971318]\n",
      "[Epoch 0/1] [Batch 1123/3551] [D loss: 0.169203] [G loss: 0.950745]\n",
      "[Epoch 0/1] [Batch 1124/3551] [D loss: 0.100956] [G loss: 0.950098]\n",
      "[Epoch 0/1] [Batch 1125/3551] [D loss: 0.152455] [G loss: 0.946071]\n",
      "[Epoch 0/1] [Batch 1126/3551] [D loss: 0.126852] [G loss: 0.967773]\n",
      "[Epoch 0/1] [Batch 1127/3551] [D loss: 0.082964] [G loss: 0.973321]\n",
      "[Epoch 0/1] [Batch 1128/3551] [D loss: 0.072473] [G loss: 0.950002]\n",
      "[Epoch 0/1] [Batch 1129/3551] [D loss: 0.146367] [G loss: 0.967968]\n",
      "[Epoch 0/1] [Batch 1130/3551] [D loss: 0.128422] [G loss: 0.952456]\n",
      "[Epoch 0/1] [Batch 1131/3551] [D loss: 0.125664] [G loss: 0.970261]\n",
      "[Epoch 0/1] [Batch 1132/3551] [D loss: 0.083649] [G loss: 0.947264]\n",
      "[Epoch 0/1] [Batch 1133/3551] [D loss: 0.123959] [G loss: 0.953659]\n",
      "[Epoch 0/1] [Batch 1134/3551] [D loss: 0.106557] [G loss: 0.965860]\n",
      "[Epoch 0/1] [Batch 1135/3551] [D loss: 0.119663] [G loss: 0.948317]\n",
      "[Epoch 0/1] [Batch 1136/3551] [D loss: 0.081645] [G loss: 0.957900]\n",
      "[Epoch 0/1] [Batch 1137/3551] [D loss: 0.111613] [G loss: 0.961249]\n",
      "[Epoch 0/1] [Batch 1138/3551] [D loss: 0.108371] [G loss: 0.974471]\n",
      "[Epoch 0/1] [Batch 1139/3551] [D loss: 0.156647] [G loss: 0.934527]\n",
      "[Epoch 0/1] [Batch 1140/3551] [D loss: 0.048566] [G loss: 0.979846]\n",
      "[Epoch 0/1] [Batch 1141/3551] [D loss: 0.105875] [G loss: 0.947932]\n",
      "[Epoch 0/1] [Batch 1142/3551] [D loss: 0.158595] [G loss: 0.965663]\n",
      "[Epoch 0/1] [Batch 1143/3551] [D loss: 0.085126] [G loss: 0.958165]\n",
      "[Epoch 0/1] [Batch 1144/3551] [D loss: 0.105468] [G loss: 0.958719]\n",
      "[Epoch 0/1] [Batch 1145/3551] [D loss: 0.088970] [G loss: 0.959490]\n",
      "[Epoch 0/1] [Batch 1146/3551] [D loss: 0.120239] [G loss: 0.959072]\n",
      "[Epoch 0/1] [Batch 1147/3551] [D loss: 0.112163] [G loss: 0.966375]\n",
      "[Epoch 0/1] [Batch 1148/3551] [D loss: 0.160157] [G loss: 0.979611]\n",
      "[Epoch 0/1] [Batch 1149/3551] [D loss: 0.105048] [G loss: 0.958669]\n",
      "[Epoch 0/1] [Batch 1150/3551] [D loss: 0.121073] [G loss: 0.960351]\n",
      "[Epoch 0/1] [Batch 1151/3551] [D loss: 0.105186] [G loss: 0.974514]\n",
      "[Epoch 0/1] [Batch 1152/3551] [D loss: 0.110424] [G loss: 0.971629]\n",
      "[Epoch 0/1] [Batch 1153/3551] [D loss: 0.140177] [G loss: 0.936263]\n",
      "[Epoch 0/1] [Batch 1154/3551] [D loss: 0.107916] [G loss: 0.928317]\n",
      "[Epoch 0/1] [Batch 1155/3551] [D loss: 0.129623] [G loss: 0.959527]\n",
      "[Epoch 0/1] [Batch 1156/3551] [D loss: 0.107200] [G loss: 0.966594]\n",
      "[Epoch 0/1] [Batch 1157/3551] [D loss: 0.113515] [G loss: 0.965058]\n",
      "[Epoch 0/1] [Batch 1158/3551] [D loss: 0.080016] [G loss: 0.945811]\n",
      "[Epoch 0/1] [Batch 1159/3551] [D loss: 0.134673] [G loss: 0.980225]\n",
      "[Epoch 0/1] [Batch 1160/3551] [D loss: 0.145627] [G loss: 0.949147]\n",
      "[Epoch 0/1] [Batch 1161/3551] [D loss: 0.097946] [G loss: 0.929727]\n",
      "[Epoch 0/1] [Batch 1162/3551] [D loss: 0.105174] [G loss: 0.968132]\n",
      "[Epoch 0/1] [Batch 1163/3551] [D loss: 0.091780] [G loss: 0.945632]\n",
      "[Epoch 0/1] [Batch 1164/3551] [D loss: 0.070057] [G loss: 0.948284]\n",
      "[Epoch 0/1] [Batch 1165/3551] [D loss: 0.073787] [G loss: 0.972583]\n",
      "[Epoch 0/1] [Batch 1166/3551] [D loss: 0.082330] [G loss: 0.944856]\n",
      "[Epoch 0/1] [Batch 1167/3551] [D loss: 0.147484] [G loss: 0.965445]\n",
      "[Epoch 0/1] [Batch 1168/3551] [D loss: 0.112448] [G loss: 0.979895]\n",
      "[Epoch 0/1] [Batch 1169/3551] [D loss: 0.121133] [G loss: 0.941383]\n",
      "[Epoch 0/1] [Batch 1170/3551] [D loss: 0.174068] [G loss: 0.931170]\n",
      "[Epoch 0/1] [Batch 1171/3551] [D loss: 0.117122] [G loss: 0.978547]\n",
      "[Epoch 0/1] [Batch 1172/3551] [D loss: 0.071804] [G loss: 0.942860]\n",
      "[Epoch 0/1] [Batch 1173/3551] [D loss: 0.089889] [G loss: 0.977967]\n",
      "[Epoch 0/1] [Batch 1174/3551] [D loss: 0.075497] [G loss: 0.969798]\n",
      "[Epoch 0/1] [Batch 1175/3551] [D loss: 0.076693] [G loss: 0.965845]\n",
      "[Epoch 0/1] [Batch 1176/3551] [D loss: 0.106303] [G loss: 0.948728]\n",
      "[Epoch 0/1] [Batch 1177/3551] [D loss: 0.111431] [G loss: 0.947495]\n",
      "[Epoch 0/1] [Batch 1178/3551] [D loss: 0.089614] [G loss: 0.946230]\n",
      "[Epoch 0/1] [Batch 1179/3551] [D loss: 0.076669] [G loss: 0.942463]\n",
      "[Epoch 0/1] [Batch 1180/3551] [D loss: 0.083373] [G loss: 0.951412]\n",
      "[Epoch 0/1] [Batch 1181/3551] [D loss: 0.097870] [G loss: 0.957520]\n",
      "[Epoch 0/1] [Batch 1182/3551] [D loss: 0.097426] [G loss: 0.921976]\n",
      "[Epoch 0/1] [Batch 1183/3551] [D loss: 0.092599] [G loss: 0.951292]\n",
      "[Epoch 0/1] [Batch 1184/3551] [D loss: 0.135227] [G loss: 0.968562]\n",
      "[Epoch 0/1] [Batch 1185/3551] [D loss: 0.063705] [G loss: 0.929439]\n",
      "[Epoch 0/1] [Batch 1186/3551] [D loss: 0.053044] [G loss: 0.968893]\n",
      "[Epoch 0/1] [Batch 1187/3551] [D loss: 0.090287] [G loss: 0.960493]\n",
      "[Epoch 0/1] [Batch 1188/3551] [D loss: 0.074027] [G loss: 0.983641]\n",
      "[Epoch 0/1] [Batch 1189/3551] [D loss: 0.094079] [G loss: 0.964375]\n",
      "[Epoch 0/1] [Batch 1190/3551] [D loss: 0.058637] [G loss: 0.974313]\n",
      "[Epoch 0/1] [Batch 1191/3551] [D loss: 0.099597] [G loss: 0.951568]\n",
      "[Epoch 0/1] [Batch 1192/3551] [D loss: 0.082279] [G loss: 0.973334]\n",
      "[Epoch 0/1] [Batch 1193/3551] [D loss: 0.058554] [G loss: 0.941191]\n",
      "[Epoch 0/1] [Batch 1194/3551] [D loss: 0.112099] [G loss: 0.947824]\n",
      "[Epoch 0/1] [Batch 1195/3551] [D loss: 0.135460] [G loss: 0.979704]\n",
      "[Epoch 0/1] [Batch 1196/3551] [D loss: 0.052301] [G loss: 0.971622]\n",
      "[Epoch 0/1] [Batch 1197/3551] [D loss: 0.092999] [G loss: 0.952596]\n",
      "[Epoch 0/1] [Batch 1198/3551] [D loss: 0.124319] [G loss: 0.961733]\n",
      "[Epoch 0/1] [Batch 1199/3551] [D loss: 0.079895] [G loss: 0.971174]\n",
      "[Epoch 0/1] [Batch 1200/3551] [D loss: 0.098389] [G loss: 0.940260]\n",
      "[Epoch 0/1] [Batch 1201/3551] [D loss: 0.088459] [G loss: 0.972928]\n",
      "[Epoch 0/1] [Batch 1202/3551] [D loss: 0.122740] [G loss: 0.960451]\n",
      "[Epoch 0/1] [Batch 1203/3551] [D loss: 0.107470] [G loss: 0.985644]\n",
      "[Epoch 0/1] [Batch 1204/3551] [D loss: 0.063844] [G loss: 0.966045]\n",
      "[Epoch 0/1] [Batch 1205/3551] [D loss: 0.122359] [G loss: 0.973054]\n",
      "[Epoch 0/1] [Batch 1206/3551] [D loss: 0.062095] [G loss: 0.956345]\n",
      "[Epoch 0/1] [Batch 1207/3551] [D loss: 0.084353] [G loss: 0.983104]\n",
      "[Epoch 0/1] [Batch 1208/3551] [D loss: 0.097620] [G loss: 0.955112]\n",
      "[Epoch 0/1] [Batch 1209/3551] [D loss: 0.141459] [G loss: 0.940295]\n",
      "[Epoch 0/1] [Batch 1210/3551] [D loss: 0.071044] [G loss: 0.965458]\n",
      "[Epoch 0/1] [Batch 1211/3551] [D loss: 0.104102] [G loss: 0.972797]\n",
      "[Epoch 0/1] [Batch 1212/3551] [D loss: 0.076398] [G loss: 0.941791]\n",
      "[Epoch 0/1] [Batch 1213/3551] [D loss: 0.123391] [G loss: 0.956097]\n",
      "[Epoch 0/1] [Batch 1214/3551] [D loss: 0.098027] [G loss: 0.958861]\n",
      "[Epoch 0/1] [Batch 1215/3551] [D loss: 0.111555] [G loss: 0.988904]\n",
      "[Epoch 0/1] [Batch 1216/3551] [D loss: 0.064536] [G loss: 0.955668]\n",
      "[Epoch 0/1] [Batch 1217/3551] [D loss: 0.099523] [G loss: 0.961558]\n",
      "[Epoch 0/1] [Batch 1218/3551] [D loss: 0.105920] [G loss: 0.948924]\n",
      "[Epoch 0/1] [Batch 1219/3551] [D loss: 0.107691] [G loss: 0.942989]\n",
      "[Epoch 0/1] [Batch 1220/3551] [D loss: 0.086535] [G loss: 0.946345]\n",
      "[Epoch 0/1] [Batch 1221/3551] [D loss: 0.062573] [G loss: 0.975097]\n",
      "[Epoch 0/1] [Batch 1222/3551] [D loss: 0.079436] [G loss: 0.944772]\n",
      "[Epoch 0/1] [Batch 1223/3551] [D loss: 0.107903] [G loss: 0.940059]\n",
      "[Epoch 0/1] [Batch 1224/3551] [D loss: 0.081383] [G loss: 0.982003]\n",
      "[Epoch 0/1] [Batch 1225/3551] [D loss: 0.118332] [G loss: 0.961329]\n",
      "[Epoch 0/1] [Batch 1226/3551] [D loss: 0.109095] [G loss: 0.958159]\n",
      "[Epoch 0/1] [Batch 1227/3551] [D loss: 0.097141] [G loss: 0.953872]\n",
      "[Epoch 0/1] [Batch 1228/3551] [D loss: 0.094996] [G loss: 0.984984]\n",
      "[Epoch 0/1] [Batch 1229/3551] [D loss: 0.114340] [G loss: 0.966566]\n",
      "[Epoch 0/1] [Batch 1230/3551] [D loss: 0.084652] [G loss: 0.962091]\n",
      "[Epoch 0/1] [Batch 1231/3551] [D loss: 0.113547] [G loss: 0.930799]\n",
      "[Epoch 0/1] [Batch 1232/3551] [D loss: 0.099054] [G loss: 0.940690]\n",
      "[Epoch 0/1] [Batch 1233/3551] [D loss: 0.155540] [G loss: 0.934061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1234/3551] [D loss: 0.078760] [G loss: 0.954093]\n",
      "[Epoch 0/1] [Batch 1235/3551] [D loss: 0.111811] [G loss: 0.958530]\n",
      "[Epoch 0/1] [Batch 1236/3551] [D loss: 0.120849] [G loss: 0.963602]\n",
      "[Epoch 0/1] [Batch 1237/3551] [D loss: 0.111970] [G loss: 0.948740]\n",
      "[Epoch 0/1] [Batch 1238/3551] [D loss: 0.172555] [G loss: 0.932154]\n",
      "[Epoch 0/1] [Batch 1239/3551] [D loss: 0.055727] [G loss: 0.967808]\n",
      "[Epoch 0/1] [Batch 1240/3551] [D loss: 0.157786] [G loss: 0.956657]\n",
      "[Epoch 0/1] [Batch 1241/3551] [D loss: 0.056602] [G loss: 0.956233]\n",
      "[Epoch 0/1] [Batch 1242/3551] [D loss: 0.100565] [G loss: 0.957508]\n",
      "[Epoch 0/1] [Batch 1243/3551] [D loss: 0.087733] [G loss: 0.979511]\n",
      "[Epoch 0/1] [Batch 1244/3551] [D loss: 0.052029] [G loss: 0.970941]\n",
      "[Epoch 0/1] [Batch 1245/3551] [D loss: 0.092296] [G loss: 0.927526]\n",
      "[Epoch 0/1] [Batch 1246/3551] [D loss: 0.100404] [G loss: 0.953817]\n",
      "[Epoch 0/1] [Batch 1247/3551] [D loss: 0.058798] [G loss: 0.941431]\n",
      "[Epoch 0/1] [Batch 1248/3551] [D loss: 0.105724] [G loss: 0.954063]\n",
      "[Epoch 0/1] [Batch 1249/3551] [D loss: 0.080445] [G loss: 0.924047]\n",
      "[Epoch 0/1] [Batch 1250/3551] [D loss: 0.119035] [G loss: 0.961095]\n",
      "[Epoch 0/1] [Batch 1251/3551] [D loss: 0.052188] [G loss: 0.952848]\n",
      "[Epoch 0/1] [Batch 1252/3551] [D loss: 0.081267] [G loss: 0.965483]\n",
      "[Epoch 0/1] [Batch 1253/3551] [D loss: 0.107377] [G loss: 0.967494]\n",
      "[Epoch 0/1] [Batch 1254/3551] [D loss: 0.095205] [G loss: 0.972913]\n",
      "[Epoch 0/1] [Batch 1255/3551] [D loss: 0.133965] [G loss: 0.969958]\n",
      "[Epoch 0/1] [Batch 1256/3551] [D loss: 0.101041] [G loss: 0.961054]\n",
      "[Epoch 0/1] [Batch 1257/3551] [D loss: 0.052323] [G loss: 0.977583]\n",
      "[Epoch 0/1] [Batch 1258/3551] [D loss: 0.133295] [G loss: 0.966829]\n",
      "[Epoch 0/1] [Batch 1259/3551] [D loss: 0.117889] [G loss: 0.966325]\n",
      "[Epoch 0/1] [Batch 1260/3551] [D loss: 0.053203] [G loss: 0.961251]\n",
      "[Epoch 0/1] [Batch 1261/3551] [D loss: 0.052851] [G loss: 0.934965]\n",
      "[Epoch 0/1] [Batch 1262/3551] [D loss: 0.085059] [G loss: 0.947357]\n",
      "[Epoch 0/1] [Batch 1263/3551] [D loss: 0.094545] [G loss: 0.999092]\n",
      "[Epoch 0/1] [Batch 1264/3551] [D loss: 0.086985] [G loss: 0.953131]\n",
      "[Epoch 0/1] [Batch 1265/3551] [D loss: 0.090979] [G loss: 0.981242]\n",
      "[Epoch 0/1] [Batch 1266/3551] [D loss: 0.065388] [G loss: 0.952833]\n",
      "[Epoch 0/1] [Batch 1267/3551] [D loss: 0.114573] [G loss: 0.943073]\n",
      "[Epoch 0/1] [Batch 1268/3551] [D loss: 0.090046] [G loss: 0.964876]\n",
      "[Epoch 0/1] [Batch 1269/3551] [D loss: 0.044925] [G loss: 0.968994]\n",
      "[Epoch 0/1] [Batch 1270/3551] [D loss: 0.061777] [G loss: 0.981176]\n",
      "[Epoch 0/1] [Batch 1271/3551] [D loss: 0.084376] [G loss: 0.962461]\n",
      "[Epoch 0/1] [Batch 1272/3551] [D loss: 0.090456] [G loss: 0.986434]\n",
      "[Epoch 0/1] [Batch 1273/3551] [D loss: 0.073550] [G loss: 0.962361]\n",
      "[Epoch 0/1] [Batch 1274/3551] [D loss: 0.129945] [G loss: 0.978876]\n",
      "[Epoch 0/1] [Batch 1275/3551] [D loss: 0.076478] [G loss: 0.945303]\n",
      "[Epoch 0/1] [Batch 1276/3551] [D loss: 0.050576] [G loss: 0.952289]\n",
      "[Epoch 0/1] [Batch 1277/3551] [D loss: 0.174282] [G loss: 0.961028]\n",
      "[Epoch 0/1] [Batch 1278/3551] [D loss: 0.107915] [G loss: 0.952727]\n",
      "[Epoch 0/1] [Batch 1279/3551] [D loss: 0.151317] [G loss: 0.976802]\n",
      "[Epoch 0/1] [Batch 1280/3551] [D loss: 0.060825] [G loss: 0.990382]\n",
      "[Epoch 0/1] [Batch 1281/3551] [D loss: 0.057407] [G loss: 0.972822]\n",
      "[Epoch 0/1] [Batch 1282/3551] [D loss: 0.113616] [G loss: 0.990640]\n",
      "[Epoch 0/1] [Batch 1283/3551] [D loss: 0.094778] [G loss: 0.984637]\n",
      "[Epoch 0/1] [Batch 1284/3551] [D loss: 0.057376] [G loss: 0.951310]\n",
      "[Epoch 0/1] [Batch 1285/3551] [D loss: 0.092825] [G loss: 0.963221]\n",
      "[Epoch 0/1] [Batch 1286/3551] [D loss: 0.088640] [G loss: 0.969398]\n",
      "[Epoch 0/1] [Batch 1287/3551] [D loss: 0.108632] [G loss: 0.947305]\n",
      "[Epoch 0/1] [Batch 1288/3551] [D loss: 0.064742] [G loss: 0.953275]\n",
      "[Epoch 0/1] [Batch 1289/3551] [D loss: 0.079101] [G loss: 0.958383]\n",
      "[Epoch 0/1] [Batch 1290/3551] [D loss: 0.088152] [G loss: 0.962758]\n",
      "[Epoch 0/1] [Batch 1291/3551] [D loss: 0.075000] [G loss: 0.963744]\n",
      "[Epoch 0/1] [Batch 1292/3551] [D loss: 0.116250] [G loss: 0.993783]\n",
      "[Epoch 0/1] [Batch 1293/3551] [D loss: 0.072004] [G loss: 0.982723]\n",
      "[Epoch 0/1] [Batch 1294/3551] [D loss: 0.066223] [G loss: 0.955346]\n",
      "[Epoch 0/1] [Batch 1295/3551] [D loss: 0.097634] [G loss: 0.963001]\n",
      "[Epoch 0/1] [Batch 1296/3551] [D loss: 0.108129] [G loss: 0.959092]\n",
      "[Epoch 0/1] [Batch 1297/3551] [D loss: 0.052249] [G loss: 0.955506]\n",
      "[Epoch 0/1] [Batch 1298/3551] [D loss: 0.125553] [G loss: 0.981183]\n",
      "[Epoch 0/1] [Batch 1299/3551] [D loss: 0.082513] [G loss: 0.967774]\n",
      "[Epoch 0/1] [Batch 1300/3551] [D loss: 0.129388] [G loss: 0.965999]\n",
      "[Epoch 0/1] [Batch 1301/3551] [D loss: 0.079609] [G loss: 0.972003]\n",
      "[Epoch 0/1] [Batch 1302/3551] [D loss: 0.083407] [G loss: 0.944656]\n",
      "[Epoch 0/1] [Batch 1303/3551] [D loss: 0.078012] [G loss: 0.955476]\n",
      "[Epoch 0/1] [Batch 1304/3551] [D loss: 0.106076] [G loss: 0.949945]\n",
      "[Epoch 0/1] [Batch 1305/3551] [D loss: 0.114141] [G loss: 0.960743]\n",
      "[Epoch 0/1] [Batch 1306/3551] [D loss: 0.108275] [G loss: 0.971202]\n",
      "[Epoch 0/1] [Batch 1307/3551] [D loss: 0.138564] [G loss: 0.943887]\n",
      "[Epoch 0/1] [Batch 1308/3551] [D loss: 0.110445] [G loss: 0.968796]\n",
      "[Epoch 0/1] [Batch 1309/3551] [D loss: 0.090371] [G loss: 0.959988]\n",
      "[Epoch 0/1] [Batch 1310/3551] [D loss: 0.113185] [G loss: 0.952091]\n",
      "[Epoch 0/1] [Batch 1311/3551] [D loss: 0.087239] [G loss: 0.958008]\n",
      "[Epoch 0/1] [Batch 1312/3551] [D loss: 0.087214] [G loss: 0.935316]\n",
      "[Epoch 0/1] [Batch 1313/3551] [D loss: 0.065411] [G loss: 0.943615]\n",
      "[Epoch 0/1] [Batch 1314/3551] [D loss: 0.082293] [G loss: 0.956214]\n",
      "[Epoch 0/1] [Batch 1315/3551] [D loss: 0.079133] [G loss: 0.944634]\n",
      "[Epoch 0/1] [Batch 1316/3551] [D loss: 0.094421] [G loss: 0.984276]\n",
      "[Epoch 0/1] [Batch 1317/3551] [D loss: 0.084027] [G loss: 0.940677]\n",
      "[Epoch 0/1] [Batch 1318/3551] [D loss: 0.056018] [G loss: 0.977200]\n",
      "[Epoch 0/1] [Batch 1319/3551] [D loss: 0.064527] [G loss: 0.948985]\n",
      "[Epoch 0/1] [Batch 1320/3551] [D loss: 0.140050] [G loss: 0.970096]\n",
      "[Epoch 0/1] [Batch 1321/3551] [D loss: 0.098022] [G loss: 0.994482]\n",
      "[Epoch 0/1] [Batch 1322/3551] [D loss: 0.108183] [G loss: 0.987144]\n",
      "[Epoch 0/1] [Batch 1323/3551] [D loss: 0.076663] [G loss: 0.940357]\n",
      "[Epoch 0/1] [Batch 1324/3551] [D loss: 0.084308] [G loss: 0.946457]\n",
      "[Epoch 0/1] [Batch 1325/3551] [D loss: 0.050415] [G loss: 0.959809]\n",
      "[Epoch 0/1] [Batch 1326/3551] [D loss: 0.070747] [G loss: 0.959714]\n",
      "[Epoch 0/1] [Batch 1327/3551] [D loss: 0.059545] [G loss: 0.946186]\n",
      "[Epoch 0/1] [Batch 1328/3551] [D loss: 0.062480] [G loss: 0.958139]\n",
      "[Epoch 0/1] [Batch 1329/3551] [D loss: 0.091086] [G loss: 0.947104]\n",
      "[Epoch 0/1] [Batch 1330/3551] [D loss: 0.086319] [G loss: 0.952209]\n",
      "[Epoch 0/1] [Batch 1331/3551] [D loss: 0.111385] [G loss: 0.945800]\n",
      "[Epoch 0/1] [Batch 1332/3551] [D loss: 0.097872] [G loss: 0.945438]\n",
      "[Epoch 0/1] [Batch 1333/3551] [D loss: 0.103465] [G loss: 0.980611]\n",
      "[Epoch 0/1] [Batch 1334/3551] [D loss: 0.092351] [G loss: 0.984999]\n",
      "[Epoch 0/1] [Batch 1335/3551] [D loss: 0.091191] [G loss: 0.987316]\n",
      "[Epoch 0/1] [Batch 1336/3551] [D loss: 0.105162] [G loss: 0.969230]\n",
      "[Epoch 0/1] [Batch 1337/3551] [D loss: 0.087965] [G loss: 0.979178]\n",
      "[Epoch 0/1] [Batch 1338/3551] [D loss: 0.076018] [G loss: 0.929010]\n",
      "[Epoch 0/1] [Batch 1339/3551] [D loss: 0.113881] [G loss: 0.963340]\n",
      "[Epoch 0/1] [Batch 1340/3551] [D loss: 0.074486] [G loss: 0.964383]\n",
      "[Epoch 0/1] [Batch 1341/3551] [D loss: 0.090973] [G loss: 0.998413]\n",
      "[Epoch 0/1] [Batch 1342/3551] [D loss: 0.113623] [G loss: 0.999308]\n",
      "[Epoch 0/1] [Batch 1343/3551] [D loss: 0.071481] [G loss: 0.980900]\n",
      "[Epoch 0/1] [Batch 1344/3551] [D loss: 0.082529] [G loss: 0.965132]\n",
      "[Epoch 0/1] [Batch 1345/3551] [D loss: 0.101013] [G loss: 0.956446]\n",
      "[Epoch 0/1] [Batch 1346/3551] [D loss: 0.076030] [G loss: 0.960699]\n",
      "[Epoch 0/1] [Batch 1347/3551] [D loss: 0.094895] [G loss: 0.972975]\n",
      "[Epoch 0/1] [Batch 1348/3551] [D loss: 0.099245] [G loss: 0.982213]\n",
      "[Epoch 0/1] [Batch 1349/3551] [D loss: 0.068682] [G loss: 0.956716]\n",
      "[Epoch 0/1] [Batch 1350/3551] [D loss: 0.122236] [G loss: 0.980839]\n",
      "[Epoch 0/1] [Batch 1351/3551] [D loss: 0.104502] [G loss: 0.987366]\n",
      "[Epoch 0/1] [Batch 1352/3551] [D loss: 0.100384] [G loss: 0.998016]\n",
      "[Epoch 0/1] [Batch 1353/3551] [D loss: 0.095016] [G loss: 0.964198]\n",
      "[Epoch 0/1] [Batch 1354/3551] [D loss: 0.059672] [G loss: 0.972814]\n",
      "[Epoch 0/1] [Batch 1355/3551] [D loss: 0.116442] [G loss: 0.986654]\n",
      "[Epoch 0/1] [Batch 1356/3551] [D loss: 0.138549] [G loss: 0.938928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1357/3551] [D loss: 0.082638] [G loss: 0.964863]\n",
      "[Epoch 0/1] [Batch 1358/3551] [D loss: 0.080930] [G loss: 0.946707]\n",
      "[Epoch 0/1] [Batch 1359/3551] [D loss: 0.069096] [G loss: 0.990152]\n",
      "[Epoch 0/1] [Batch 1360/3551] [D loss: 0.068959] [G loss: 0.963789]\n",
      "[Epoch 0/1] [Batch 1361/3551] [D loss: 0.118543] [G loss: 0.978384]\n",
      "[Epoch 0/1] [Batch 1362/3551] [D loss: 0.049744] [G loss: 0.968647]\n",
      "[Epoch 0/1] [Batch 1363/3551] [D loss: 0.071475] [G loss: 0.940299]\n",
      "[Epoch 0/1] [Batch 1364/3551] [D loss: 0.085532] [G loss: 0.929760]\n",
      "[Epoch 0/1] [Batch 1365/3551] [D loss: 0.084718] [G loss: 0.959424]\n",
      "[Epoch 0/1] [Batch 1366/3551] [D loss: 0.147304] [G loss: 0.979642]\n",
      "[Epoch 0/1] [Batch 1367/3551] [D loss: 0.074043] [G loss: 0.965766]\n",
      "[Epoch 0/1] [Batch 1368/3551] [D loss: 0.105875] [G loss: 1.002916]\n",
      "[Epoch 0/1] [Batch 1369/3551] [D loss: 0.098714] [G loss: 1.005532]\n",
      "[Epoch 0/1] [Batch 1370/3551] [D loss: 0.086783] [G loss: 0.962608]\n",
      "[Epoch 0/1] [Batch 1371/3551] [D loss: 0.069682] [G loss: 0.966973]\n",
      "[Epoch 0/1] [Batch 1372/3551] [D loss: 0.075151] [G loss: 0.996503]\n",
      "[Epoch 0/1] [Batch 1373/3551] [D loss: 0.112101] [G loss: 0.986534]\n",
      "[Epoch 0/1] [Batch 1374/3551] [D loss: 0.074096] [G loss: 0.970386]\n",
      "[Epoch 0/1] [Batch 1375/3551] [D loss: 0.072710] [G loss: 0.980550]\n",
      "[Epoch 0/1] [Batch 1376/3551] [D loss: 0.071749] [G loss: 0.970095]\n",
      "[Epoch 0/1] [Batch 1377/3551] [D loss: 0.079736] [G loss: 0.985181]\n",
      "[Epoch 0/1] [Batch 1378/3551] [D loss: 0.113779] [G loss: 0.958468]\n",
      "[Epoch 0/1] [Batch 1379/3551] [D loss: 0.111884] [G loss: 0.993468]\n",
      "[Epoch 0/1] [Batch 1380/3551] [D loss: 0.101402] [G loss: 0.942048]\n",
      "[Epoch 0/1] [Batch 1381/3551] [D loss: 0.152873] [G loss: 0.965406]\n",
      "[Epoch 0/1] [Batch 1382/3551] [D loss: 0.094663] [G loss: 0.967185]\n",
      "[Epoch 0/1] [Batch 1383/3551] [D loss: 0.099068] [G loss: 0.948129]\n",
      "[Epoch 0/1] [Batch 1384/3551] [D loss: 0.089411] [G loss: 0.951649]\n",
      "[Epoch 0/1] [Batch 1385/3551] [D loss: 0.034876] [G loss: 0.986332]\n",
      "[Epoch 0/1] [Batch 1386/3551] [D loss: 0.078589] [G loss: 0.959287]\n",
      "[Epoch 0/1] [Batch 1387/3551] [D loss: 0.085974] [G loss: 0.950721]\n",
      "[Epoch 0/1] [Batch 1388/3551] [D loss: 0.133566] [G loss: 0.974032]\n",
      "[Epoch 0/1] [Batch 1389/3551] [D loss: 0.051386] [G loss: 0.976096]\n",
      "[Epoch 0/1] [Batch 1390/3551] [D loss: 0.104539] [G loss: 0.964861]\n",
      "[Epoch 0/1] [Batch 1391/3551] [D loss: 0.077760] [G loss: 0.956287]\n",
      "[Epoch 0/1] [Batch 1392/3551] [D loss: 0.093435] [G loss: 0.939795]\n",
      "[Epoch 0/1] [Batch 1393/3551] [D loss: 0.098062] [G loss: 0.952395]\n",
      "[Epoch 0/1] [Batch 1394/3551] [D loss: 0.104842] [G loss: 0.966101]\n",
      "[Epoch 0/1] [Batch 1395/3551] [D loss: 0.078435] [G loss: 0.994585]\n",
      "[Epoch 0/1] [Batch 1396/3551] [D loss: 0.092556] [G loss: 0.973036]\n",
      "[Epoch 0/1] [Batch 1397/3551] [D loss: 0.093699] [G loss: 0.957118]\n",
      "[Epoch 0/1] [Batch 1398/3551] [D loss: 0.070709] [G loss: 0.958326]\n",
      "[Epoch 0/1] [Batch 1399/3551] [D loss: 0.053222] [G loss: 0.976737]\n",
      "[Epoch 0/1] [Batch 1400/3551] [D loss: 0.094691] [G loss: 0.948084]\n",
      "[Epoch 0/1] [Batch 1401/3551] [D loss: 0.105075] [G loss: 0.938916]\n",
      "[Epoch 0/1] [Batch 1402/3551] [D loss: 0.082308] [G loss: 0.978400]\n",
      "[Epoch 0/1] [Batch 1403/3551] [D loss: 0.083433] [G loss: 0.993937]\n",
      "[Epoch 0/1] [Batch 1404/3551] [D loss: 0.083794] [G loss: 0.962003]\n",
      "[Epoch 0/1] [Batch 1405/3551] [D loss: 0.066478] [G loss: 0.968986]\n",
      "[Epoch 0/1] [Batch 1406/3551] [D loss: 0.058647] [G loss: 0.983036]\n",
      "[Epoch 0/1] [Batch 1407/3551] [D loss: 0.080810] [G loss: 0.976866]\n",
      "[Epoch 0/1] [Batch 1408/3551] [D loss: 0.143440] [G loss: 0.965622]\n",
      "[Epoch 0/1] [Batch 1409/3551] [D loss: 0.072594] [G loss: 0.993984]\n",
      "[Epoch 0/1] [Batch 1410/3551] [D loss: 0.070502] [G loss: 0.981491]\n",
      "[Epoch 0/1] [Batch 1411/3551] [D loss: 0.057425] [G loss: 0.952174]\n",
      "[Epoch 0/1] [Batch 1412/3551] [D loss: 0.098795] [G loss: 0.985191]\n",
      "[Epoch 0/1] [Batch 1413/3551] [D loss: 0.059324] [G loss: 0.979992]\n",
      "[Epoch 0/1] [Batch 1414/3551] [D loss: 0.083860] [G loss: 0.993187]\n",
      "[Epoch 0/1] [Batch 1415/3551] [D loss: 0.078751] [G loss: 0.956522]\n",
      "[Epoch 0/1] [Batch 1416/3551] [D loss: 0.098523] [G loss: 0.961518]\n",
      "[Epoch 0/1] [Batch 1417/3551] [D loss: 0.070856] [G loss: 0.974866]\n",
      "[Epoch 0/1] [Batch 1418/3551] [D loss: 0.115328] [G loss: 0.979926]\n",
      "[Epoch 0/1] [Batch 1419/3551] [D loss: 0.077590] [G loss: 0.975907]\n",
      "[Epoch 0/1] [Batch 1420/3551] [D loss: 0.083046] [G loss: 0.959190]\n",
      "[Epoch 0/1] [Batch 1421/3551] [D loss: 0.107416] [G loss: 0.985250]\n",
      "[Epoch 0/1] [Batch 1422/3551] [D loss: 0.111132] [G loss: 0.966125]\n",
      "[Epoch 0/1] [Batch 1423/3551] [D loss: 0.042151] [G loss: 0.986576]\n",
      "[Epoch 0/1] [Batch 1424/3551] [D loss: 0.072451] [G loss: 0.973341]\n",
      "[Epoch 0/1] [Batch 1425/3551] [D loss: 0.085529] [G loss: 0.965807]\n",
      "[Epoch 0/1] [Batch 1426/3551] [D loss: 0.067921] [G loss: 0.977786]\n",
      "[Epoch 0/1] [Batch 1427/3551] [D loss: 0.081360] [G loss: 0.978903]\n",
      "[Epoch 0/1] [Batch 1428/3551] [D loss: 0.112676] [G loss: 0.960435]\n",
      "[Epoch 0/1] [Batch 1429/3551] [D loss: 0.044471] [G loss: 0.963615]\n",
      "[Epoch 0/1] [Batch 1430/3551] [D loss: 0.066090] [G loss: 0.962354]\n",
      "[Epoch 0/1] [Batch 1431/3551] [D loss: 0.068117] [G loss: 0.977073]\n",
      "[Epoch 0/1] [Batch 1432/3551] [D loss: 0.077491] [G loss: 0.983117]\n",
      "[Epoch 0/1] [Batch 1433/3551] [D loss: 0.075161] [G loss: 0.975429]\n",
      "[Epoch 0/1] [Batch 1434/3551] [D loss: 0.084409] [G loss: 0.990883]\n",
      "[Epoch 0/1] [Batch 1435/3551] [D loss: 0.057136] [G loss: 0.938417]\n",
      "[Epoch 0/1] [Batch 1436/3551] [D loss: 0.080814] [G loss: 0.974994]\n",
      "[Epoch 0/1] [Batch 1437/3551] [D loss: 0.069104] [G loss: 0.930291]\n",
      "[Epoch 0/1] [Batch 1438/3551] [D loss: 0.094588] [G loss: 0.980647]\n",
      "[Epoch 0/1] [Batch 1439/3551] [D loss: 0.093932] [G loss: 1.007559]\n",
      "[Epoch 0/1] [Batch 1440/3551] [D loss: 0.046029] [G loss: 0.987211]\n",
      "[Epoch 0/1] [Batch 1441/3551] [D loss: 0.096931] [G loss: 0.986366]\n",
      "[Epoch 0/1] [Batch 1442/3551] [D loss: 0.078099] [G loss: 0.964802]\n",
      "[Epoch 0/1] [Batch 1443/3551] [D loss: 0.113920] [G loss: 0.992371]\n",
      "[Epoch 0/1] [Batch 1444/3551] [D loss: 0.049203] [G loss: 0.974900]\n",
      "[Epoch 0/1] [Batch 1445/3551] [D loss: 0.093805] [G loss: 0.973791]\n",
      "[Epoch 0/1] [Batch 1446/3551] [D loss: 0.066980] [G loss: 0.979709]\n",
      "[Epoch 0/1] [Batch 1447/3551] [D loss: 0.066768] [G loss: 0.976051]\n",
      "[Epoch 0/1] [Batch 1448/3551] [D loss: 0.068210] [G loss: 0.974993]\n",
      "[Epoch 0/1] [Batch 1449/3551] [D loss: 0.132899] [G loss: 0.973821]\n",
      "[Epoch 0/1] [Batch 1450/3551] [D loss: 0.090718] [G loss: 0.970494]\n",
      "[Epoch 0/1] [Batch 1451/3551] [D loss: 0.112576] [G loss: 0.989703]\n",
      "[Epoch 0/1] [Batch 1452/3551] [D loss: 0.068138] [G loss: 0.977599]\n",
      "[Epoch 0/1] [Batch 1453/3551] [D loss: 0.056704] [G loss: 0.970028]\n",
      "[Epoch 0/1] [Batch 1454/3551] [D loss: 0.070756] [G loss: 0.972564]\n",
      "[Epoch 0/1] [Batch 1455/3551] [D loss: 0.076978] [G loss: 0.962705]\n",
      "[Epoch 0/1] [Batch 1456/3551] [D loss: 0.085272] [G loss: 0.965014]\n",
      "[Epoch 0/1] [Batch 1457/3551] [D loss: 0.065096] [G loss: 0.970633]\n",
      "[Epoch 0/1] [Batch 1458/3551] [D loss: 0.097368] [G loss: 0.971629]\n",
      "[Epoch 0/1] [Batch 1459/3551] [D loss: 0.079506] [G loss: 0.965722]\n",
      "[Epoch 0/1] [Batch 1460/3551] [D loss: 0.071625] [G loss: 0.972845]\n",
      "[Epoch 0/1] [Batch 1461/3551] [D loss: 0.073167] [G loss: 0.995613]\n",
      "[Epoch 0/1] [Batch 1462/3551] [D loss: 0.106353] [G loss: 0.962351]\n",
      "[Epoch 0/1] [Batch 1463/3551] [D loss: 0.055135] [G loss: 0.928915]\n",
      "[Epoch 0/1] [Batch 1464/3551] [D loss: 0.057900] [G loss: 0.976918]\n",
      "[Epoch 0/1] [Batch 1465/3551] [D loss: 0.053195] [G loss: 0.972758]\n",
      "[Epoch 0/1] [Batch 1466/3551] [D loss: 0.064974] [G loss: 0.967826]\n",
      "[Epoch 0/1] [Batch 1467/3551] [D loss: 0.072352] [G loss: 0.985033]\n",
      "[Epoch 0/1] [Batch 1468/3551] [D loss: 0.051532] [G loss: 0.989483]\n",
      "[Epoch 0/1] [Batch 1469/3551] [D loss: 0.102669] [G loss: 0.972423]\n",
      "[Epoch 0/1] [Batch 1470/3551] [D loss: 0.063751] [G loss: 0.957871]\n",
      "[Epoch 0/1] [Batch 1471/3551] [D loss: 0.086845] [G loss: 0.951716]\n",
      "[Epoch 0/1] [Batch 1472/3551] [D loss: 0.086459] [G loss: 0.980684]\n",
      "[Epoch 0/1] [Batch 1473/3551] [D loss: 0.054677] [G loss: 0.975095]\n",
      "[Epoch 0/1] [Batch 1474/3551] [D loss: 0.048500] [G loss: 0.963830]\n",
      "[Epoch 0/1] [Batch 1475/3551] [D loss: 0.084461] [G loss: 0.986778]\n",
      "[Epoch 0/1] [Batch 1476/3551] [D loss: 0.043634] [G loss: 0.984382]\n",
      "[Epoch 0/1] [Batch 1477/3551] [D loss: 0.094442] [G loss: 0.969889]\n",
      "[Epoch 0/1] [Batch 1478/3551] [D loss: 0.103872] [G loss: 0.975353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1479/3551] [D loss: 0.046865] [G loss: 0.990468]\n",
      "[Epoch 0/1] [Batch 1480/3551] [D loss: 0.065613] [G loss: 0.992662]\n",
      "[Epoch 0/1] [Batch 1481/3551] [D loss: 0.078987] [G loss: 0.948373]\n",
      "[Epoch 0/1] [Batch 1482/3551] [D loss: 0.082222] [G loss: 0.993658]\n",
      "[Epoch 0/1] [Batch 1483/3551] [D loss: 0.044812] [G loss: 0.968289]\n",
      "[Epoch 0/1] [Batch 1484/3551] [D loss: 0.060980] [G loss: 0.974451]\n",
      "[Epoch 0/1] [Batch 1485/3551] [D loss: 0.089417] [G loss: 0.973529]\n",
      "[Epoch 0/1] [Batch 1486/3551] [D loss: 0.071558] [G loss: 0.962376]\n",
      "[Epoch 0/1] [Batch 1487/3551] [D loss: 0.072877] [G loss: 0.946216]\n",
      "[Epoch 0/1] [Batch 1488/3551] [D loss: 0.073495] [G loss: 0.969355]\n",
      "[Epoch 0/1] [Batch 1489/3551] [D loss: 0.065853] [G loss: 0.951076]\n",
      "[Epoch 0/1] [Batch 1490/3551] [D loss: 0.049774] [G loss: 0.971223]\n",
      "[Epoch 0/1] [Batch 1491/3551] [D loss: 0.108807] [G loss: 0.960432]\n",
      "[Epoch 0/1] [Batch 1492/3551] [D loss: 0.089346] [G loss: 0.978831]\n",
      "[Epoch 0/1] [Batch 1493/3551] [D loss: 0.095011] [G loss: 0.979200]\n",
      "[Epoch 0/1] [Batch 1494/3551] [D loss: 0.063095] [G loss: 0.989075]\n",
      "[Epoch 0/1] [Batch 1495/3551] [D loss: 0.054077] [G loss: 0.979306]\n",
      "[Epoch 0/1] [Batch 1496/3551] [D loss: 0.064312] [G loss: 0.973949]\n",
      "[Epoch 0/1] [Batch 1497/3551] [D loss: 0.068429] [G loss: 0.968899]\n",
      "[Epoch 0/1] [Batch 1498/3551] [D loss: 0.098212] [G loss: 0.962522]\n",
      "[Epoch 0/1] [Batch 1499/3551] [D loss: 0.069469] [G loss: 0.982088]\n",
      "[Epoch 0/1] [Batch 1500/3551] [D loss: 0.070529] [G loss: 0.960734]\n",
      "[Epoch 0/1] [Batch 1501/3551] [D loss: 0.099096] [G loss: 0.969253]\n",
      "[Epoch 0/1] [Batch 1502/3551] [D loss: 0.082040] [G loss: 0.964158]\n",
      "[Epoch 0/1] [Batch 1503/3551] [D loss: 0.071913] [G loss: 0.969310]\n",
      "[Epoch 0/1] [Batch 1504/3551] [D loss: 0.078289] [G loss: 0.973523]\n",
      "[Epoch 0/1] [Batch 1505/3551] [D loss: 0.078266] [G loss: 0.973221]\n",
      "[Epoch 0/1] [Batch 1506/3551] [D loss: 0.065866] [G loss: 0.985224]\n",
      "[Epoch 0/1] [Batch 1507/3551] [D loss: 0.120159] [G loss: 0.965893]\n",
      "[Epoch 0/1] [Batch 1508/3551] [D loss: 0.077428] [G loss: 0.985299]\n",
      "[Epoch 0/1] [Batch 1509/3551] [D loss: 0.056878] [G loss: 0.974651]\n",
      "[Epoch 0/1] [Batch 1510/3551] [D loss: 0.097123] [G loss: 0.948821]\n",
      "[Epoch 0/1] [Batch 1511/3551] [D loss: 0.110575] [G loss: 0.972828]\n",
      "[Epoch 0/1] [Batch 1512/3551] [D loss: 0.079899] [G loss: 0.973868]\n",
      "[Epoch 0/1] [Batch 1513/3551] [D loss: 0.057137] [G loss: 0.953983]\n",
      "[Epoch 0/1] [Batch 1514/3551] [D loss: 0.050681] [G loss: 0.977792]\n",
      "[Epoch 0/1] [Batch 1515/3551] [D loss: 0.059419] [G loss: 0.942950]\n",
      "[Epoch 0/1] [Batch 1516/3551] [D loss: 0.053266] [G loss: 0.980228]\n",
      "[Epoch 0/1] [Batch 1517/3551] [D loss: 0.107154] [G loss: 0.973240]\n",
      "[Epoch 0/1] [Batch 1518/3551] [D loss: 0.088024] [G loss: 0.978592]\n",
      "[Epoch 0/1] [Batch 1519/3551] [D loss: 0.094260] [G loss: 0.976846]\n",
      "[Epoch 0/1] [Batch 1520/3551] [D loss: 0.087636] [G loss: 0.973404]\n",
      "[Epoch 0/1] [Batch 1521/3551] [D loss: 0.051626] [G loss: 0.972995]\n",
      "[Epoch 0/1] [Batch 1522/3551] [D loss: 0.086056] [G loss: 0.969765]\n",
      "[Epoch 0/1] [Batch 1523/3551] [D loss: 0.039229] [G loss: 0.958886]\n",
      "[Epoch 0/1] [Batch 1524/3551] [D loss: 0.057048] [G loss: 0.960935]\n",
      "[Epoch 0/1] [Batch 1525/3551] [D loss: 0.102598] [G loss: 1.001392]\n",
      "[Epoch 0/1] [Batch 1526/3551] [D loss: 0.091772] [G loss: 0.975323]\n",
      "[Epoch 0/1] [Batch 1527/3551] [D loss: 0.071826] [G loss: 0.944527]\n",
      "[Epoch 0/1] [Batch 1528/3551] [D loss: 0.063263] [G loss: 0.983840]\n",
      "[Epoch 0/1] [Batch 1529/3551] [D loss: 0.062674] [G loss: 0.992085]\n",
      "[Epoch 0/1] [Batch 1530/3551] [D loss: 0.062379] [G loss: 0.946934]\n",
      "[Epoch 0/1] [Batch 1531/3551] [D loss: 0.079349] [G loss: 0.952648]\n",
      "[Epoch 0/1] [Batch 1532/3551] [D loss: 0.065039] [G loss: 0.950323]\n",
      "[Epoch 0/1] [Batch 1533/3551] [D loss: 0.058046] [G loss: 0.964020]\n",
      "[Epoch 0/1] [Batch 1534/3551] [D loss: 0.074835] [G loss: 0.975773]\n",
      "[Epoch 0/1] [Batch 1535/3551] [D loss: 0.051790] [G loss: 0.951282]\n",
      "[Epoch 0/1] [Batch 1536/3551] [D loss: 0.114289] [G loss: 0.966243]\n",
      "[Epoch 0/1] [Batch 1537/3551] [D loss: 0.090589] [G loss: 0.960991]\n",
      "[Epoch 0/1] [Batch 1538/3551] [D loss: 0.103883] [G loss: 0.963431]\n",
      "[Epoch 0/1] [Batch 1539/3551] [D loss: 0.064833] [G loss: 0.962355]\n",
      "[Epoch 0/1] [Batch 1540/3551] [D loss: 0.086561] [G loss: 0.994288]\n",
      "[Epoch 0/1] [Batch 1541/3551] [D loss: 0.067596] [G loss: 0.951198]\n",
      "[Epoch 0/1] [Batch 1542/3551] [D loss: 0.073445] [G loss: 0.958828]\n",
      "[Epoch 0/1] [Batch 1543/3551] [D loss: 0.061510] [G loss: 0.968567]\n",
      "[Epoch 0/1] [Batch 1544/3551] [D loss: 0.099593] [G loss: 0.981295]\n",
      "[Epoch 0/1] [Batch 1545/3551] [D loss: 0.065065] [G loss: 0.967548]\n",
      "[Epoch 0/1] [Batch 1546/3551] [D loss: 0.085586] [G loss: 0.975852]\n",
      "[Epoch 0/1] [Batch 1547/3551] [D loss: 0.106804] [G loss: 0.968744]\n",
      "[Epoch 0/1] [Batch 1548/3551] [D loss: 0.076849] [G loss: 0.970492]\n",
      "[Epoch 0/1] [Batch 1549/3551] [D loss: 0.081181] [G loss: 0.954432]\n",
      "[Epoch 0/1] [Batch 1550/3551] [D loss: 0.063946] [G loss: 0.971757]\n",
      "[Epoch 0/1] [Batch 1551/3551] [D loss: 0.089427] [G loss: 0.966149]\n",
      "[Epoch 0/1] [Batch 1552/3551] [D loss: 0.043401] [G loss: 0.970737]\n",
      "[Epoch 0/1] [Batch 1553/3551] [D loss: 0.065999] [G loss: 0.982268]\n",
      "[Epoch 0/1] [Batch 1554/3551] [D loss: 0.067040] [G loss: 0.964315]\n",
      "[Epoch 0/1] [Batch 1555/3551] [D loss: 0.069070] [G loss: 0.972875]\n",
      "[Epoch 0/1] [Batch 1556/3551] [D loss: 0.057855] [G loss: 0.978683]\n",
      "[Epoch 0/1] [Batch 1557/3551] [D loss: 0.060643] [G loss: 0.962655]\n",
      "[Epoch 0/1] [Batch 1558/3551] [D loss: 0.134364] [G loss: 0.965024]\n",
      "[Epoch 0/1] [Batch 1559/3551] [D loss: 0.041920] [G loss: 0.977810]\n",
      "[Epoch 0/1] [Batch 1560/3551] [D loss: 0.118505] [G loss: 0.967220]\n",
      "[Epoch 0/1] [Batch 1561/3551] [D loss: 0.065932] [G loss: 0.974485]\n",
      "[Epoch 0/1] [Batch 1562/3551] [D loss: 0.096484] [G loss: 0.976818]\n",
      "[Epoch 0/1] [Batch 1563/3551] [D loss: 0.076262] [G loss: 0.977273]\n",
      "[Epoch 0/1] [Batch 1564/3551] [D loss: 0.091302] [G loss: 0.979103]\n",
      "[Epoch 0/1] [Batch 1565/3551] [D loss: 0.066429] [G loss: 0.983380]\n",
      "[Epoch 0/1] [Batch 1566/3551] [D loss: 0.045905] [G loss: 0.974061]\n",
      "[Epoch 0/1] [Batch 1567/3551] [D loss: 0.094002] [G loss: 0.979952]\n",
      "[Epoch 0/1] [Batch 1568/3551] [D loss: 0.054534] [G loss: 0.958125]\n",
      "[Epoch 0/1] [Batch 1569/3551] [D loss: 0.094329] [G loss: 0.964248]\n",
      "[Epoch 0/1] [Batch 1570/3551] [D loss: 0.080260] [G loss: 0.983733]\n",
      "[Epoch 0/1] [Batch 1571/3551] [D loss: 0.094074] [G loss: 0.974444]\n",
      "[Epoch 0/1] [Batch 1572/3551] [D loss: 0.059216] [G loss: 0.967138]\n",
      "[Epoch 0/1] [Batch 1573/3551] [D loss: 0.075157] [G loss: 0.949585]\n",
      "[Epoch 0/1] [Batch 1574/3551] [D loss: 0.049733] [G loss: 1.011036]\n",
      "[Epoch 0/1] [Batch 1575/3551] [D loss: 0.057761] [G loss: 0.955208]\n",
      "[Epoch 0/1] [Batch 1576/3551] [D loss: 0.062129] [G loss: 0.976444]\n",
      "[Epoch 0/1] [Batch 1577/3551] [D loss: 0.055217] [G loss: 0.967098]\n",
      "[Epoch 0/1] [Batch 1578/3551] [D loss: 0.069048] [G loss: 0.983554]\n",
      "[Epoch 0/1] [Batch 1579/3551] [D loss: 0.110253] [G loss: 1.000559]\n",
      "[Epoch 0/1] [Batch 1580/3551] [D loss: 0.075521] [G loss: 0.973202]\n",
      "[Epoch 0/1] [Batch 1581/3551] [D loss: 0.094578] [G loss: 0.968114]\n",
      "[Epoch 0/1] [Batch 1582/3551] [D loss: 0.068376] [G loss: 0.975852]\n",
      "[Epoch 0/1] [Batch 1583/3551] [D loss: 0.062520] [G loss: 0.971397]\n",
      "[Epoch 0/1] [Batch 1584/3551] [D loss: 0.055328] [G loss: 0.947059]\n",
      "[Epoch 0/1] [Batch 1585/3551] [D loss: 0.051763] [G loss: 0.979596]\n",
      "[Epoch 0/1] [Batch 1586/3551] [D loss: 0.066541] [G loss: 0.973267]\n",
      "[Epoch 0/1] [Batch 1587/3551] [D loss: 0.064000] [G loss: 0.980818]\n",
      "[Epoch 0/1] [Batch 1588/3551] [D loss: 0.093949] [G loss: 0.984925]\n",
      "[Epoch 0/1] [Batch 1589/3551] [D loss: 0.047944] [G loss: 0.959513]\n",
      "[Epoch 0/1] [Batch 1590/3551] [D loss: 0.122651] [G loss: 0.986966]\n",
      "[Epoch 0/1] [Batch 1591/3551] [D loss: 0.126186] [G loss: 0.966379]\n",
      "[Epoch 0/1] [Batch 1592/3551] [D loss: 0.060277] [G loss: 0.988562]\n",
      "[Epoch 0/1] [Batch 1593/3551] [D loss: 0.078758] [G loss: 0.993698]\n",
      "[Epoch 0/1] [Batch 1594/3551] [D loss: 0.092775] [G loss: 0.964164]\n",
      "[Epoch 0/1] [Batch 1595/3551] [D loss: 0.046617] [G loss: 0.955560]\n",
      "[Epoch 0/1] [Batch 1596/3551] [D loss: 0.040551] [G loss: 0.971981]\n",
      "[Epoch 0/1] [Batch 1597/3551] [D loss: 0.069924] [G loss: 0.948708]\n",
      "[Epoch 0/1] [Batch 1598/3551] [D loss: 0.057320] [G loss: 0.969172]\n",
      "[Epoch 0/1] [Batch 1599/3551] [D loss: 0.056550] [G loss: 0.954972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1600/3551] [D loss: 0.099865] [G loss: 0.972997]\n",
      "[Epoch 0/1] [Batch 1601/3551] [D loss: 0.074226] [G loss: 0.971807]\n",
      "[Epoch 0/1] [Batch 1602/3551] [D loss: 0.112613] [G loss: 0.959926]\n",
      "[Epoch 0/1] [Batch 1603/3551] [D loss: 0.085008] [G loss: 0.999650]\n",
      "[Epoch 0/1] [Batch 1604/3551] [D loss: 0.074501] [G loss: 0.976256]\n",
      "[Epoch 0/1] [Batch 1605/3551] [D loss: 0.052133] [G loss: 0.989962]\n",
      "[Epoch 0/1] [Batch 1606/3551] [D loss: 0.060604] [G loss: 0.957257]\n",
      "[Epoch 0/1] [Batch 1607/3551] [D loss: 0.088466] [G loss: 0.977149]\n",
      "[Epoch 0/1] [Batch 1608/3551] [D loss: 0.083020] [G loss: 0.958930]\n",
      "[Epoch 0/1] [Batch 1609/3551] [D loss: 0.056990] [G loss: 0.966479]\n",
      "[Epoch 0/1] [Batch 1610/3551] [D loss: 0.076723] [G loss: 0.956126]\n",
      "[Epoch 0/1] [Batch 1611/3551] [D loss: 0.088958] [G loss: 0.968641]\n",
      "[Epoch 0/1] [Batch 1612/3551] [D loss: 0.077223] [G loss: 0.958876]\n",
      "[Epoch 0/1] [Batch 1613/3551] [D loss: 0.041990] [G loss: 0.962391]\n",
      "[Epoch 0/1] [Batch 1614/3551] [D loss: 0.051388] [G loss: 0.982687]\n",
      "[Epoch 0/1] [Batch 1615/3551] [D loss: 0.069812] [G loss: 0.981332]\n",
      "[Epoch 0/1] [Batch 1616/3551] [D loss: 0.077011] [G loss: 0.970267]\n",
      "[Epoch 0/1] [Batch 1617/3551] [D loss: 0.066331] [G loss: 0.963877]\n",
      "[Epoch 0/1] [Batch 1618/3551] [D loss: 0.073027] [G loss: 0.950713]\n",
      "[Epoch 0/1] [Batch 1619/3551] [D loss: 0.052442] [G loss: 0.966164]\n",
      "[Epoch 0/1] [Batch 1620/3551] [D loss: 0.076731] [G loss: 0.974994]\n",
      "[Epoch 0/1] [Batch 1621/3551] [D loss: 0.050608] [G loss: 0.973311]\n",
      "[Epoch 0/1] [Batch 1622/3551] [D loss: 0.040793] [G loss: 0.981256]\n",
      "[Epoch 0/1] [Batch 1623/3551] [D loss: 0.073872] [G loss: 0.978038]\n",
      "[Epoch 0/1] [Batch 1624/3551] [D loss: 0.061326] [G loss: 0.961724]\n",
      "[Epoch 0/1] [Batch 1625/3551] [D loss: 0.053598] [G loss: 0.983101]\n",
      "[Epoch 0/1] [Batch 1626/3551] [D loss: 0.098651] [G loss: 0.984124]\n",
      "[Epoch 0/1] [Batch 1627/3551] [D loss: 0.073349] [G loss: 0.968263]\n",
      "[Epoch 0/1] [Batch 1628/3551] [D loss: 0.062659] [G loss: 0.959561]\n",
      "[Epoch 0/1] [Batch 1629/3551] [D loss: 0.120360] [G loss: 0.973728]\n",
      "[Epoch 0/1] [Batch 1630/3551] [D loss: 0.112832] [G loss: 0.967263]\n",
      "[Epoch 0/1] [Batch 1631/3551] [D loss: 0.057395] [G loss: 0.982751]\n",
      "[Epoch 0/1] [Batch 1632/3551] [D loss: 0.088084] [G loss: 0.959346]\n",
      "[Epoch 0/1] [Batch 1633/3551] [D loss: 0.069534] [G loss: 0.979178]\n",
      "[Epoch 0/1] [Batch 1634/3551] [D loss: 0.093414] [G loss: 0.970621]\n",
      "[Epoch 0/1] [Batch 1635/3551] [D loss: 0.065478] [G loss: 0.982241]\n",
      "[Epoch 0/1] [Batch 1636/3551] [D loss: 0.057630] [G loss: 0.983781]\n",
      "[Epoch 0/1] [Batch 1637/3551] [D loss: 0.061595] [G loss: 0.951526]\n",
      "[Epoch 0/1] [Batch 1638/3551] [D loss: 0.070199] [G loss: 0.988199]\n",
      "[Epoch 0/1] [Batch 1639/3551] [D loss: 0.092264] [G loss: 0.977920]\n",
      "[Epoch 0/1] [Batch 1640/3551] [D loss: 0.058930] [G loss: 0.982801]\n",
      "[Epoch 0/1] [Batch 1641/3551] [D loss: 0.071998] [G loss: 0.976248]\n",
      "[Epoch 0/1] [Batch 1642/3551] [D loss: 0.066482] [G loss: 0.981281]\n",
      "[Epoch 0/1] [Batch 1643/3551] [D loss: 0.102983] [G loss: 0.991624]\n",
      "[Epoch 0/1] [Batch 1644/3551] [D loss: 0.074423] [G loss: 0.957226]\n",
      "[Epoch 0/1] [Batch 1645/3551] [D loss: 0.069146] [G loss: 0.962618]\n",
      "[Epoch 0/1] [Batch 1646/3551] [D loss: 0.079179] [G loss: 0.971275]\n",
      "[Epoch 0/1] [Batch 1647/3551] [D loss: 0.039475] [G loss: 0.959293]\n",
      "[Epoch 0/1] [Batch 1648/3551] [D loss: 0.073220] [G loss: 0.984262]\n",
      "[Epoch 0/1] [Batch 1649/3551] [D loss: 0.076471] [G loss: 0.966639]\n",
      "[Epoch 0/1] [Batch 1650/3551] [D loss: 0.070676] [G loss: 0.974225]\n",
      "[Epoch 0/1] [Batch 1651/3551] [D loss: 0.060373] [G loss: 0.965984]\n",
      "[Epoch 0/1] [Batch 1652/3551] [D loss: 0.053916] [G loss: 0.974993]\n",
      "[Epoch 0/1] [Batch 1653/3551] [D loss: 0.070443] [G loss: 0.974141]\n",
      "[Epoch 0/1] [Batch 1654/3551] [D loss: 0.056045] [G loss: 0.972703]\n",
      "[Epoch 0/1] [Batch 1655/3551] [D loss: 0.056665] [G loss: 0.950126]\n",
      "[Epoch 0/1] [Batch 1656/3551] [D loss: 0.073640] [G loss: 0.986442]\n",
      "[Epoch 0/1] [Batch 1657/3551] [D loss: 0.058184] [G loss: 0.999327]\n",
      "[Epoch 0/1] [Batch 1658/3551] [D loss: 0.061268] [G loss: 0.953144]\n",
      "[Epoch 0/1] [Batch 1659/3551] [D loss: 0.071264] [G loss: 0.953781]\n",
      "[Epoch 0/1] [Batch 1660/3551] [D loss: 0.056543] [G loss: 0.990772]\n",
      "[Epoch 0/1] [Batch 1661/3551] [D loss: 0.050990] [G loss: 0.958588]\n",
      "[Epoch 0/1] [Batch 1662/3551] [D loss: 0.048993] [G loss: 0.958125]\n",
      "[Epoch 0/1] [Batch 1663/3551] [D loss: 0.058103] [G loss: 0.976596]\n",
      "[Epoch 0/1] [Batch 1664/3551] [D loss: 0.053141] [G loss: 0.992805]\n",
      "[Epoch 0/1] [Batch 1665/3551] [D loss: 0.046315] [G loss: 0.980836]\n",
      "[Epoch 0/1] [Batch 1666/3551] [D loss: 0.076566] [G loss: 0.972798]\n",
      "[Epoch 0/1] [Batch 1667/3551] [D loss: 0.065754] [G loss: 0.960251]\n",
      "[Epoch 0/1] [Batch 1668/3551] [D loss: 0.070932] [G loss: 0.976482]\n",
      "[Epoch 0/1] [Batch 1669/3551] [D loss: 0.080687] [G loss: 0.983206]\n",
      "[Epoch 0/1] [Batch 1670/3551] [D loss: 0.101744] [G loss: 0.979063]\n",
      "[Epoch 0/1] [Batch 1671/3551] [D loss: 0.051475] [G loss: 0.983529]\n",
      "[Epoch 0/1] [Batch 1672/3551] [D loss: 0.056120] [G loss: 0.961489]\n",
      "[Epoch 0/1] [Batch 1673/3551] [D loss: 0.101994] [G loss: 0.969634]\n",
      "[Epoch 0/1] [Batch 1674/3551] [D loss: 0.056467] [G loss: 0.962859]\n",
      "[Epoch 0/1] [Batch 1675/3551] [D loss: 0.128633] [G loss: 0.978819]\n",
      "[Epoch 0/1] [Batch 1676/3551] [D loss: 0.038053] [G loss: 0.975483]\n",
      "[Epoch 0/1] [Batch 1677/3551] [D loss: 0.061436] [G loss: 0.983545]\n",
      "[Epoch 0/1] [Batch 1678/3551] [D loss: 0.084079] [G loss: 0.958020]\n",
      "[Epoch 0/1] [Batch 1679/3551] [D loss: 0.056628] [G loss: 0.967736]\n",
      "[Epoch 0/1] [Batch 1680/3551] [D loss: 0.059040] [G loss: 0.954012]\n",
      "[Epoch 0/1] [Batch 1681/3551] [D loss: 0.050563] [G loss: 0.989804]\n",
      "[Epoch 0/1] [Batch 1682/3551] [D loss: 0.052983] [G loss: 0.957940]\n",
      "[Epoch 0/1] [Batch 1683/3551] [D loss: 0.059674] [G loss: 0.958757]\n",
      "[Epoch 0/1] [Batch 1684/3551] [D loss: 0.044513] [G loss: 0.974194]\n",
      "[Epoch 0/1] [Batch 1685/3551] [D loss: 0.039612] [G loss: 0.966100]\n",
      "[Epoch 0/1] [Batch 1686/3551] [D loss: 0.110611] [G loss: 0.942437]\n",
      "[Epoch 0/1] [Batch 1687/3551] [D loss: 0.047177] [G loss: 0.958427]\n",
      "[Epoch 0/1] [Batch 1688/3551] [D loss: 0.076165] [G loss: 0.957545]\n",
      "[Epoch 0/1] [Batch 1689/3551] [D loss: 0.109902] [G loss: 0.974510]\n",
      "[Epoch 0/1] [Batch 1690/3551] [D loss: 0.064060] [G loss: 0.983228]\n",
      "[Epoch 0/1] [Batch 1691/3551] [D loss: 0.047081] [G loss: 0.968915]\n",
      "[Epoch 0/1] [Batch 1692/3551] [D loss: 0.099829] [G loss: 0.961676]\n",
      "[Epoch 0/1] [Batch 1693/3551] [D loss: 0.084588] [G loss: 0.938755]\n",
      "[Epoch 0/1] [Batch 1694/3551] [D loss: 0.075423] [G loss: 0.992843]\n",
      "[Epoch 0/1] [Batch 1695/3551] [D loss: 0.063275] [G loss: 0.989155]\n",
      "[Epoch 0/1] [Batch 1696/3551] [D loss: 0.045398] [G loss: 0.957125]\n",
      "[Epoch 0/1] [Batch 1697/3551] [D loss: 0.062905] [G loss: 0.975058]\n",
      "[Epoch 0/1] [Batch 1698/3551] [D loss: 0.038539] [G loss: 0.983336]\n",
      "[Epoch 0/1] [Batch 1699/3551] [D loss: 0.079489] [G loss: 0.973141]\n",
      "[Epoch 0/1] [Batch 1700/3551] [D loss: 0.079059] [G loss: 0.973326]\n",
      "[Epoch 0/1] [Batch 1701/3551] [D loss: 0.087972] [G loss: 0.956510]\n",
      "[Epoch 0/1] [Batch 1702/3551] [D loss: 0.057709] [G loss: 0.979200]\n",
      "[Epoch 0/1] [Batch 1703/3551] [D loss: 0.066133] [G loss: 0.955793]\n",
      "[Epoch 0/1] [Batch 1704/3551] [D loss: 0.040163] [G loss: 0.956085]\n",
      "[Epoch 0/1] [Batch 1705/3551] [D loss: 0.059366] [G loss: 0.981573]\n",
      "[Epoch 0/1] [Batch 1706/3551] [D loss: 0.081743] [G loss: 0.980635]\n",
      "[Epoch 0/1] [Batch 1707/3551] [D loss: 0.082475] [G loss: 0.987305]\n",
      "[Epoch 0/1] [Batch 1708/3551] [D loss: 0.049819] [G loss: 0.961457]\n",
      "[Epoch 0/1] [Batch 1709/3551] [D loss: 0.080050] [G loss: 0.989294]\n",
      "[Epoch 0/1] [Batch 1710/3551] [D loss: 0.077291] [G loss: 0.967943]\n",
      "[Epoch 0/1] [Batch 1711/3551] [D loss: 0.073877] [G loss: 0.981549]\n",
      "[Epoch 0/1] [Batch 1712/3551] [D loss: 0.042556] [G loss: 0.969350]\n",
      "[Epoch 0/1] [Batch 1713/3551] [D loss: 0.060143] [G loss: 0.965887]\n",
      "[Epoch 0/1] [Batch 1714/3551] [D loss: 0.076389] [G loss: 0.955015]\n",
      "[Epoch 0/1] [Batch 1715/3551] [D loss: 0.040591] [G loss: 0.993951]\n",
      "[Epoch 0/1] [Batch 1716/3551] [D loss: 0.071373] [G loss: 0.981486]\n",
      "[Epoch 0/1] [Batch 1717/3551] [D loss: 0.061834] [G loss: 0.973244]\n",
      "[Epoch 0/1] [Batch 1718/3551] [D loss: 0.063894] [G loss: 0.972718]\n",
      "[Epoch 0/1] [Batch 1719/3551] [D loss: 0.062270] [G loss: 0.979004]\n",
      "[Epoch 0/1] [Batch 1720/3551] [D loss: 0.082655] [G loss: 0.990110]\n",
      "[Epoch 0/1] [Batch 1721/3551] [D loss: 0.054371] [G loss: 0.973833]\n",
      "[Epoch 0/1] [Batch 1722/3551] [D loss: 0.094099] [G loss: 0.986832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1723/3551] [D loss: 0.054604] [G loss: 0.995634]\n",
      "[Epoch 0/1] [Batch 1724/3551] [D loss: 0.083518] [G loss: 0.964031]\n",
      "[Epoch 0/1] [Batch 1725/3551] [D loss: 0.066735] [G loss: 0.980273]\n",
      "[Epoch 0/1] [Batch 1726/3551] [D loss: 0.069907] [G loss: 0.984982]\n",
      "[Epoch 0/1] [Batch 1727/3551] [D loss: 0.074924] [G loss: 0.990175]\n",
      "[Epoch 0/1] [Batch 1728/3551] [D loss: 0.059282] [G loss: 0.980658]\n",
      "[Epoch 0/1] [Batch 1729/3551] [D loss: 0.057176] [G loss: 0.981149]\n",
      "[Epoch 0/1] [Batch 1730/3551] [D loss: 0.051228] [G loss: 0.974411]\n",
      "[Epoch 0/1] [Batch 1731/3551] [D loss: 0.081669] [G loss: 0.984929]\n",
      "[Epoch 0/1] [Batch 1732/3551] [D loss: 0.106351] [G loss: 0.971175]\n",
      "[Epoch 0/1] [Batch 1733/3551] [D loss: 0.077214] [G loss: 0.972360]\n",
      "[Epoch 0/1] [Batch 1734/3551] [D loss: 0.055545] [G loss: 0.980602]\n",
      "[Epoch 0/1] [Batch 1735/3551] [D loss: 0.032412] [G loss: 0.971423]\n",
      "[Epoch 0/1] [Batch 1736/3551] [D loss: 0.037740] [G loss: 0.959026]\n",
      "[Epoch 0/1] [Batch 1737/3551] [D loss: 0.052995] [G loss: 0.979760]\n",
      "[Epoch 0/1] [Batch 1738/3551] [D loss: 0.045407] [G loss: 0.982122]\n",
      "[Epoch 0/1] [Batch 1739/3551] [D loss: 0.036364] [G loss: 0.974939]\n",
      "[Epoch 0/1] [Batch 1740/3551] [D loss: 0.075161] [G loss: 0.984564]\n",
      "[Epoch 0/1] [Batch 1741/3551] [D loss: 0.048613] [G loss: 0.981755]\n",
      "[Epoch 0/1] [Batch 1742/3551] [D loss: 0.082624] [G loss: 0.992096]\n",
      "[Epoch 0/1] [Batch 1743/3551] [D loss: 0.065129] [G loss: 0.964096]\n",
      "[Epoch 0/1] [Batch 1744/3551] [D loss: 0.067444] [G loss: 0.994127]\n",
      "[Epoch 0/1] [Batch 1745/3551] [D loss: 0.076114] [G loss: 0.971074]\n",
      "[Epoch 0/1] [Batch 1746/3551] [D loss: 0.063963] [G loss: 0.973099]\n",
      "[Epoch 0/1] [Batch 1747/3551] [D loss: 0.046088] [G loss: 0.987503]\n",
      "[Epoch 0/1] [Batch 1748/3551] [D loss: 0.059472] [G loss: 0.964544]\n",
      "[Epoch 0/1] [Batch 1749/3551] [D loss: 0.049063] [G loss: 0.986986]\n",
      "[Epoch 0/1] [Batch 1750/3551] [D loss: 0.036709] [G loss: 0.985366]\n",
      "[Epoch 0/1] [Batch 1751/3551] [D loss: 0.048304] [G loss: 0.957799]\n",
      "[Epoch 0/1] [Batch 1752/3551] [D loss: 0.065604] [G loss: 0.966934]\n",
      "[Epoch 0/1] [Batch 1753/3551] [D loss: 0.057008] [G loss: 0.977694]\n",
      "[Epoch 0/1] [Batch 1754/3551] [D loss: 0.075324] [G loss: 0.948040]\n",
      "[Epoch 0/1] [Batch 1755/3551] [D loss: 0.067537] [G loss: 0.977240]\n",
      "[Epoch 0/1] [Batch 1756/3551] [D loss: 0.066006] [G loss: 0.981070]\n",
      "[Epoch 0/1] [Batch 1757/3551] [D loss: 0.046899] [G loss: 0.981702]\n",
      "[Epoch 0/1] [Batch 1758/3551] [D loss: 0.058621] [G loss: 0.965168]\n",
      "[Epoch 0/1] [Batch 1759/3551] [D loss: 0.073163] [G loss: 0.983072]\n",
      "[Epoch 0/1] [Batch 1760/3551] [D loss: 0.075785] [G loss: 0.978953]\n",
      "[Epoch 0/1] [Batch 1761/3551] [D loss: 0.082248] [G loss: 0.979300]\n",
      "[Epoch 0/1] [Batch 1762/3551] [D loss: 0.054768] [G loss: 0.979113]\n",
      "[Epoch 0/1] [Batch 1763/3551] [D loss: 0.048863] [G loss: 0.965726]\n",
      "[Epoch 0/1] [Batch 1764/3551] [D loss: 0.047751] [G loss: 0.954825]\n",
      "[Epoch 0/1] [Batch 1765/3551] [D loss: 0.062753] [G loss: 0.973382]\n",
      "[Epoch 0/1] [Batch 1766/3551] [D loss: 0.040870] [G loss: 0.965366]\n",
      "[Epoch 0/1] [Batch 1767/3551] [D loss: 0.094378] [G loss: 0.949994]\n",
      "[Epoch 0/1] [Batch 1768/3551] [D loss: 0.064520] [G loss: 0.951273]\n",
      "[Epoch 0/1] [Batch 1769/3551] [D loss: 0.051534] [G loss: 0.981093]\n",
      "[Epoch 0/1] [Batch 1770/3551] [D loss: 0.066174] [G loss: 0.985406]\n",
      "[Epoch 0/1] [Batch 1771/3551] [D loss: 0.055163] [G loss: 0.960564]\n",
      "[Epoch 0/1] [Batch 1772/3551] [D loss: 0.079180] [G loss: 0.978590]\n",
      "[Epoch 0/1] [Batch 1773/3551] [D loss: 0.061343] [G loss: 0.981733]\n",
      "[Epoch 0/1] [Batch 1774/3551] [D loss: 0.059591] [G loss: 0.965118]\n",
      "[Epoch 0/1] [Batch 1775/3551] [D loss: 0.069428] [G loss: 0.976367]\n",
      "[Epoch 0/1] [Batch 1776/3551] [D loss: 0.090268] [G loss: 0.983013]\n",
      "[Epoch 0/1] [Batch 1777/3551] [D loss: 0.081021] [G loss: 0.986664]\n",
      "[Epoch 0/1] [Batch 1778/3551] [D loss: 0.037094] [G loss: 0.992389]\n",
      "[Epoch 0/1] [Batch 1779/3551] [D loss: 0.059222] [G loss: 0.998574]\n",
      "[Epoch 0/1] [Batch 1780/3551] [D loss: 0.073086] [G loss: 0.978044]\n",
      "[Epoch 0/1] [Batch 1781/3551] [D loss: 0.070214] [G loss: 0.961521]\n",
      "[Epoch 0/1] [Batch 1782/3551] [D loss: 0.037522] [G loss: 0.967551]\n",
      "[Epoch 0/1] [Batch 1783/3551] [D loss: 0.047262] [G loss: 0.958094]\n",
      "[Epoch 0/1] [Batch 1784/3551] [D loss: 0.094313] [G loss: 0.956120]\n",
      "[Epoch 0/1] [Batch 1785/3551] [D loss: 0.054867] [G loss: 0.966365]\n",
      "[Epoch 0/1] [Batch 1786/3551] [D loss: 0.053939] [G loss: 0.960173]\n",
      "[Epoch 0/1] [Batch 1787/3551] [D loss: 0.065893] [G loss: 0.974324]\n",
      "[Epoch 0/1] [Batch 1788/3551] [D loss: 0.054924] [G loss: 0.977254]\n",
      "[Epoch 0/1] [Batch 1789/3551] [D loss: 0.037253] [G loss: 0.970051]\n",
      "[Epoch 0/1] [Batch 1790/3551] [D loss: 0.047155] [G loss: 0.965991]\n",
      "[Epoch 0/1] [Batch 1791/3551] [D loss: 0.074519] [G loss: 0.975561]\n",
      "[Epoch 0/1] [Batch 1792/3551] [D loss: 0.061771] [G loss: 0.968138]\n",
      "[Epoch 0/1] [Batch 1793/3551] [D loss: 0.074300] [G loss: 0.962822]\n",
      "[Epoch 0/1] [Batch 1794/3551] [D loss: 0.042034] [G loss: 0.977849]\n",
      "[Epoch 0/1] [Batch 1795/3551] [D loss: 0.076192] [G loss: 0.972366]\n",
      "[Epoch 0/1] [Batch 1796/3551] [D loss: 0.054625] [G loss: 0.959865]\n",
      "[Epoch 0/1] [Batch 1797/3551] [D loss: 0.039830] [G loss: 0.974687]\n",
      "[Epoch 0/1] [Batch 1798/3551] [D loss: 0.084962] [G loss: 0.973979]\n",
      "[Epoch 0/1] [Batch 1799/3551] [D loss: 0.052146] [G loss: 0.970332]\n",
      "[Epoch 0/1] [Batch 1800/3551] [D loss: 0.110328] [G loss: 0.994558]\n",
      "[Epoch 0/1] [Batch 1801/3551] [D loss: 0.045363] [G loss: 0.966771]\n",
      "[Epoch 0/1] [Batch 1802/3551] [D loss: 0.059319] [G loss: 0.983342]\n",
      "[Epoch 0/1] [Batch 1803/3551] [D loss: 0.050141] [G loss: 0.984118]\n",
      "[Epoch 0/1] [Batch 1804/3551] [D loss: 0.020335] [G loss: 0.974817]\n",
      "[Epoch 0/1] [Batch 1805/3551] [D loss: 0.056678] [G loss: 0.980065]\n",
      "[Epoch 0/1] [Batch 1806/3551] [D loss: 0.046568] [G loss: 0.995166]\n",
      "[Epoch 0/1] [Batch 1807/3551] [D loss: 0.088760] [G loss: 0.971954]\n",
      "[Epoch 0/1] [Batch 1808/3551] [D loss: 0.061001] [G loss: 0.977024]\n",
      "[Epoch 0/1] [Batch 1809/3551] [D loss: 0.066663] [G loss: 0.971370]\n",
      "[Epoch 0/1] [Batch 1810/3551] [D loss: 0.035124] [G loss: 0.974704]\n",
      "[Epoch 0/1] [Batch 1811/3551] [D loss: 0.046942] [G loss: 0.973787]\n",
      "[Epoch 0/1] [Batch 1812/3551] [D loss: 0.056243] [G loss: 0.975395]\n",
      "[Epoch 0/1] [Batch 1813/3551] [D loss: 0.048902] [G loss: 0.987128]\n",
      "[Epoch 0/1] [Batch 1814/3551] [D loss: 0.043289] [G loss: 0.979942]\n",
      "[Epoch 0/1] [Batch 1815/3551] [D loss: 0.078908] [G loss: 0.975647]\n",
      "[Epoch 0/1] [Batch 1816/3551] [D loss: 0.053750] [G loss: 0.975237]\n",
      "[Epoch 0/1] [Batch 1817/3551] [D loss: 0.065933] [G loss: 0.977812]\n",
      "[Epoch 0/1] [Batch 1818/3551] [D loss: 0.052202] [G loss: 0.985234]\n",
      "[Epoch 0/1] [Batch 1819/3551] [D loss: 0.056109] [G loss: 0.978377]\n",
      "[Epoch 0/1] [Batch 1820/3551] [D loss: 0.071875] [G loss: 0.973735]\n",
      "[Epoch 0/1] [Batch 1821/3551] [D loss: 0.045782] [G loss: 0.968545]\n",
      "[Epoch 0/1] [Batch 1822/3551] [D loss: 0.048448] [G loss: 0.999061]\n",
      "[Epoch 0/1] [Batch 1823/3551] [D loss: 0.064144] [G loss: 0.973437]\n",
      "[Epoch 0/1] [Batch 1824/3551] [D loss: 0.067589] [G loss: 0.958271]\n",
      "[Epoch 0/1] [Batch 1825/3551] [D loss: 0.048682] [G loss: 0.975074]\n",
      "[Epoch 0/1] [Batch 1826/3551] [D loss: 0.054598] [G loss: 0.973971]\n",
      "[Epoch 0/1] [Batch 1827/3551] [D loss: 0.070744] [G loss: 0.998073]\n",
      "[Epoch 0/1] [Batch 1828/3551] [D loss: 0.023989] [G loss: 0.991547]\n",
      "[Epoch 0/1] [Batch 1829/3551] [D loss: 0.078859] [G loss: 0.985652]\n",
      "[Epoch 0/1] [Batch 1830/3551] [D loss: 0.061392] [G loss: 0.975487]\n",
      "[Epoch 0/1] [Batch 1831/3551] [D loss: 0.089722] [G loss: 0.987799]\n",
      "[Epoch 0/1] [Batch 1832/3551] [D loss: 0.068920] [G loss: 0.986366]\n",
      "[Epoch 0/1] [Batch 1833/3551] [D loss: 0.052807] [G loss: 0.979593]\n",
      "[Epoch 0/1] [Batch 1834/3551] [D loss: 0.047679] [G loss: 0.990497]\n",
      "[Epoch 0/1] [Batch 1835/3551] [D loss: 0.062006] [G loss: 0.951879]\n",
      "[Epoch 0/1] [Batch 1836/3551] [D loss: 0.043982] [G loss: 0.978047]\n",
      "[Epoch 0/1] [Batch 1837/3551] [D loss: 0.083563] [G loss: 0.977588]\n",
      "[Epoch 0/1] [Batch 1838/3551] [D loss: 0.071574] [G loss: 0.976567]\n",
      "[Epoch 0/1] [Batch 1839/3551] [D loss: 0.079615] [G loss: 0.968987]\n",
      "[Epoch 0/1] [Batch 1840/3551] [D loss: 0.036148] [G loss: 0.980303]\n",
      "[Epoch 0/1] [Batch 1841/3551] [D loss: 0.042139] [G loss: 0.944446]\n",
      "[Epoch 0/1] [Batch 1842/3551] [D loss: 0.067006] [G loss: 0.963679]\n",
      "[Epoch 0/1] [Batch 1843/3551] [D loss: 0.043266] [G loss: 0.986513]\n",
      "[Epoch 0/1] [Batch 1844/3551] [D loss: 0.039476] [G loss: 0.984020]\n",
      "[Epoch 0/1] [Batch 1845/3551] [D loss: 0.045351] [G loss: 0.972286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1846/3551] [D loss: 0.073889] [G loss: 0.997219]\n",
      "[Epoch 0/1] [Batch 1847/3551] [D loss: 0.064460] [G loss: 0.960671]\n",
      "[Epoch 0/1] [Batch 1848/3551] [D loss: 0.063076] [G loss: 0.970090]\n",
      "[Epoch 0/1] [Batch 1849/3551] [D loss: 0.055761] [G loss: 0.981102]\n",
      "[Epoch 0/1] [Batch 1850/3551] [D loss: 0.053523] [G loss: 0.965375]\n",
      "[Epoch 0/1] [Batch 1851/3551] [D loss: 0.058987] [G loss: 0.969083]\n",
      "[Epoch 0/1] [Batch 1852/3551] [D loss: 0.047646] [G loss: 0.976529]\n",
      "[Epoch 0/1] [Batch 1853/3551] [D loss: 0.063054] [G loss: 0.998774]\n",
      "[Epoch 0/1] [Batch 1854/3551] [D loss: 0.067321] [G loss: 0.964725]\n",
      "[Epoch 0/1] [Batch 1855/3551] [D loss: 0.052424] [G loss: 0.986895]\n",
      "[Epoch 0/1] [Batch 1856/3551] [D loss: 0.092095] [G loss: 0.972998]\n",
      "[Epoch 0/1] [Batch 1857/3551] [D loss: 0.059863] [G loss: 1.003170]\n",
      "[Epoch 0/1] [Batch 1858/3551] [D loss: 0.050217] [G loss: 0.986032]\n",
      "[Epoch 0/1] [Batch 1859/3551] [D loss: 0.036012] [G loss: 0.974545]\n",
      "[Epoch 0/1] [Batch 1860/3551] [D loss: 0.045301] [G loss: 0.979903]\n",
      "[Epoch 0/1] [Batch 1861/3551] [D loss: 0.063419] [G loss: 0.995926]\n",
      "[Epoch 0/1] [Batch 1862/3551] [D loss: 0.053094] [G loss: 0.979945]\n",
      "[Epoch 0/1] [Batch 1863/3551] [D loss: 0.043902] [G loss: 0.986387]\n",
      "[Epoch 0/1] [Batch 1864/3551] [D loss: 0.044264] [G loss: 0.974325]\n",
      "[Epoch 0/1] [Batch 1865/3551] [D loss: 0.083972] [G loss: 0.986691]\n",
      "[Epoch 0/1] [Batch 1866/3551] [D loss: 0.084113] [G loss: 0.991113]\n",
      "[Epoch 0/1] [Batch 1867/3551] [D loss: 0.045432] [G loss: 0.971207]\n",
      "[Epoch 0/1] [Batch 1868/3551] [D loss: 0.066131] [G loss: 0.979124]\n",
      "[Epoch 0/1] [Batch 1869/3551] [D loss: 0.049769] [G loss: 0.970151]\n",
      "[Epoch 0/1] [Batch 1870/3551] [D loss: 0.058322] [G loss: 0.981214]\n",
      "[Epoch 0/1] [Batch 1871/3551] [D loss: 0.068529] [G loss: 1.014649]\n",
      "[Epoch 0/1] [Batch 1872/3551] [D loss: 0.042934] [G loss: 0.986929]\n",
      "[Epoch 0/1] [Batch 1873/3551] [D loss: 0.052144] [G loss: 1.000968]\n",
      "[Epoch 0/1] [Batch 1874/3551] [D loss: 0.059838] [G loss: 0.975881]\n",
      "[Epoch 0/1] [Batch 1875/3551] [D loss: 0.042509] [G loss: 0.983640]\n",
      "[Epoch 0/1] [Batch 1876/3551] [D loss: 0.085335] [G loss: 0.987375]\n",
      "[Epoch 0/1] [Batch 1877/3551] [D loss: 0.043825] [G loss: 0.986504]\n",
      "[Epoch 0/1] [Batch 1878/3551] [D loss: 0.050088] [G loss: 0.989470]\n",
      "[Epoch 0/1] [Batch 1879/3551] [D loss: 0.040936] [G loss: 0.958782]\n",
      "[Epoch 0/1] [Batch 1880/3551] [D loss: 0.021252] [G loss: 0.980423]\n",
      "[Epoch 0/1] [Batch 1881/3551] [D loss: 0.052975] [G loss: 0.971428]\n",
      "[Epoch 0/1] [Batch 1882/3551] [D loss: 0.063683] [G loss: 0.980947]\n",
      "[Epoch 0/1] [Batch 1883/3551] [D loss: 0.039558] [G loss: 0.965202]\n",
      "[Epoch 0/1] [Batch 1884/3551] [D loss: 0.045109] [G loss: 0.998405]\n",
      "[Epoch 0/1] [Batch 1885/3551] [D loss: 0.112459] [G loss: 0.963056]\n",
      "[Epoch 0/1] [Batch 1886/3551] [D loss: 0.060733] [G loss: 0.972984]\n",
      "[Epoch 0/1] [Batch 1887/3551] [D loss: 0.048662] [G loss: 0.992589]\n",
      "[Epoch 0/1] [Batch 1888/3551] [D loss: 0.068503] [G loss: 0.967743]\n",
      "[Epoch 0/1] [Batch 1889/3551] [D loss: 0.044227] [G loss: 1.001682]\n",
      "[Epoch 0/1] [Batch 1890/3551] [D loss: 0.059930] [G loss: 0.987398]\n",
      "[Epoch 0/1] [Batch 1891/3551] [D loss: 0.043125] [G loss: 0.993023]\n",
      "[Epoch 0/1] [Batch 1892/3551] [D loss: 0.079517] [G loss: 0.975960]\n",
      "[Epoch 0/1] [Batch 1893/3551] [D loss: 0.051881] [G loss: 0.985412]\n",
      "[Epoch 0/1] [Batch 1894/3551] [D loss: 0.061146] [G loss: 0.968127]\n",
      "[Epoch 0/1] [Batch 1895/3551] [D loss: 0.073646] [G loss: 0.978325]\n",
      "[Epoch 0/1] [Batch 1896/3551] [D loss: 0.036642] [G loss: 0.974089]\n",
      "[Epoch 0/1] [Batch 1897/3551] [D loss: 0.055171] [G loss: 0.962942]\n",
      "[Epoch 0/1] [Batch 1898/3551] [D loss: 0.058224] [G loss: 0.962386]\n",
      "[Epoch 0/1] [Batch 1899/3551] [D loss: 0.067908] [G loss: 0.974071]\n",
      "[Epoch 0/1] [Batch 1900/3551] [D loss: 0.055783] [G loss: 0.981350]\n",
      "[Epoch 0/1] [Batch 1901/3551] [D loss: 0.066742] [G loss: 0.980793]\n",
      "[Epoch 0/1] [Batch 1902/3551] [D loss: 0.067516] [G loss: 0.977491]\n",
      "[Epoch 0/1] [Batch 1903/3551] [D loss: 0.059371] [G loss: 0.987292]\n",
      "[Epoch 0/1] [Batch 1904/3551] [D loss: 0.066193] [G loss: 0.979360]\n",
      "[Epoch 0/1] [Batch 1905/3551] [D loss: 0.043970] [G loss: 0.974523]\n",
      "[Epoch 0/1] [Batch 1906/3551] [D loss: 0.044327] [G loss: 0.992628]\n",
      "[Epoch 0/1] [Batch 1907/3551] [D loss: 0.049333] [G loss: 0.977564]\n",
      "[Epoch 0/1] [Batch 1908/3551] [D loss: 0.058548] [G loss: 0.968896]\n",
      "[Epoch 0/1] [Batch 1909/3551] [D loss: 0.047211] [G loss: 0.969319]\n",
      "[Epoch 0/1] [Batch 1910/3551] [D loss: 0.069228] [G loss: 0.972679]\n",
      "[Epoch 0/1] [Batch 1911/3551] [D loss: 0.039593] [G loss: 0.958364]\n",
      "[Epoch 0/1] [Batch 1912/3551] [D loss: 0.079469] [G loss: 0.955925]\n",
      "[Epoch 0/1] [Batch 1913/3551] [D loss: 0.021121] [G loss: 0.977070]\n",
      "[Epoch 0/1] [Batch 1914/3551] [D loss: 0.069898] [G loss: 0.959356]\n",
      "[Epoch 0/1] [Batch 1915/3551] [D loss: 0.063856] [G loss: 0.999348]\n",
      "[Epoch 0/1] [Batch 1916/3551] [D loss: 0.058362] [G loss: 0.980027]\n",
      "[Epoch 0/1] [Batch 1917/3551] [D loss: 0.053011] [G loss: 0.972833]\n",
      "[Epoch 0/1] [Batch 1918/3551] [D loss: 0.041000] [G loss: 0.974839]\n",
      "[Epoch 0/1] [Batch 1919/3551] [D loss: 0.075132] [G loss: 0.993493]\n",
      "[Epoch 0/1] [Batch 1920/3551] [D loss: 0.073880] [G loss: 0.976258]\n",
      "[Epoch 0/1] [Batch 1921/3551] [D loss: 0.059008] [G loss: 0.977081]\n",
      "[Epoch 0/1] [Batch 1922/3551] [D loss: 0.053120] [G loss: 0.971709]\n",
      "[Epoch 0/1] [Batch 1923/3551] [D loss: 0.038112] [G loss: 0.970554]\n",
      "[Epoch 0/1] [Batch 1924/3551] [D loss: 0.044477] [G loss: 0.984525]\n",
      "[Epoch 0/1] [Batch 1925/3551] [D loss: 0.077648] [G loss: 0.981828]\n",
      "[Epoch 0/1] [Batch 1926/3551] [D loss: 0.060031] [G loss: 0.971024]\n",
      "[Epoch 0/1] [Batch 1927/3551] [D loss: 0.053397] [G loss: 0.970437]\n",
      "[Epoch 0/1] [Batch 1928/3551] [D loss: 0.047929] [G loss: 0.978867]\n",
      "[Epoch 0/1] [Batch 1929/3551] [D loss: 0.035198] [G loss: 0.977401]\n",
      "[Epoch 0/1] [Batch 1930/3551] [D loss: 0.035216] [G loss: 0.980484]\n",
      "[Epoch 0/1] [Batch 1931/3551] [D loss: 0.039680] [G loss: 0.982730]\n",
      "[Epoch 0/1] [Batch 1932/3551] [D loss: 0.074905] [G loss: 0.963755]\n",
      "[Epoch 0/1] [Batch 1933/3551] [D loss: 0.043522] [G loss: 0.980495]\n",
      "[Epoch 0/1] [Batch 1934/3551] [D loss: 0.057341] [G loss: 0.974083]\n",
      "[Epoch 0/1] [Batch 1935/3551] [D loss: 0.134707] [G loss: 0.966989]\n",
      "[Epoch 0/1] [Batch 1936/3551] [D loss: 0.047043] [G loss: 0.973055]\n",
      "[Epoch 0/1] [Batch 1937/3551] [D loss: 0.055550] [G loss: 0.994864]\n",
      "[Epoch 0/1] [Batch 1938/3551] [D loss: 0.065182] [G loss: 0.971756]\n",
      "[Epoch 0/1] [Batch 1939/3551] [D loss: 0.065672] [G loss: 0.983440]\n",
      "[Epoch 0/1] [Batch 1940/3551] [D loss: 0.050179] [G loss: 0.982593]\n",
      "[Epoch 0/1] [Batch 1941/3551] [D loss: 0.043867] [G loss: 0.986707]\n",
      "[Epoch 0/1] [Batch 1942/3551] [D loss: 0.055382] [G loss: 0.969170]\n",
      "[Epoch 0/1] [Batch 1943/3551] [D loss: 0.037097] [G loss: 0.988239]\n",
      "[Epoch 0/1] [Batch 1944/3551] [D loss: 0.035923] [G loss: 0.989656]\n",
      "[Epoch 0/1] [Batch 1945/3551] [D loss: 0.042334] [G loss: 0.976421]\n",
      "[Epoch 0/1] [Batch 1946/3551] [D loss: 0.049095] [G loss: 0.979094]\n",
      "[Epoch 0/1] [Batch 1947/3551] [D loss: 0.061980] [G loss: 0.984871]\n",
      "[Epoch 0/1] [Batch 1948/3551] [D loss: 0.030422] [G loss: 0.982571]\n",
      "[Epoch 0/1] [Batch 1949/3551] [D loss: 0.066310] [G loss: 0.994629]\n",
      "[Epoch 0/1] [Batch 1950/3551] [D loss: 0.035266] [G loss: 0.985860]\n",
      "[Epoch 0/1] [Batch 1951/3551] [D loss: 0.045828] [G loss: 0.987289]\n",
      "[Epoch 0/1] [Batch 1952/3551] [D loss: 0.060194] [G loss: 0.983629]\n",
      "[Epoch 0/1] [Batch 1953/3551] [D loss: 0.041145] [G loss: 0.983525]\n",
      "[Epoch 0/1] [Batch 1954/3551] [D loss: 0.063619] [G loss: 0.973630]\n",
      "[Epoch 0/1] [Batch 1955/3551] [D loss: 0.063611] [G loss: 0.967201]\n",
      "[Epoch 0/1] [Batch 1956/3551] [D loss: 0.054771] [G loss: 1.001519]\n",
      "[Epoch 0/1] [Batch 1957/3551] [D loss: 0.078858] [G loss: 0.983931]\n",
      "[Epoch 0/1] [Batch 1958/3551] [D loss: 0.032611] [G loss: 0.962875]\n",
      "[Epoch 0/1] [Batch 1959/3551] [D loss: 0.056873] [G loss: 0.961645]\n",
      "[Epoch 0/1] [Batch 1960/3551] [D loss: 0.076342] [G loss: 0.973061]\n",
      "[Epoch 0/1] [Batch 1961/3551] [D loss: 0.065834] [G loss: 0.974914]\n",
      "[Epoch 0/1] [Batch 1962/3551] [D loss: 0.069894] [G loss: 0.982424]\n",
      "[Epoch 0/1] [Batch 1963/3551] [D loss: 0.048364] [G loss: 0.974628]\n",
      "[Epoch 0/1] [Batch 1964/3551] [D loss: 0.038135] [G loss: 0.980745]\n",
      "[Epoch 0/1] [Batch 1965/3551] [D loss: 0.051390] [G loss: 1.006064]\n",
      "[Epoch 0/1] [Batch 1966/3551] [D loss: 0.037839] [G loss: 0.978441]\n",
      "[Epoch 0/1] [Batch 1967/3551] [D loss: 0.092642] [G loss: 0.989194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 1968/3551] [D loss: 0.070806] [G loss: 0.990005]\n",
      "[Epoch 0/1] [Batch 1969/3551] [D loss: 0.042472] [G loss: 0.983201]\n",
      "[Epoch 0/1] [Batch 1970/3551] [D loss: 0.061519] [G loss: 0.990497]\n",
      "[Epoch 0/1] [Batch 1971/3551] [D loss: 0.044585] [G loss: 0.973282]\n",
      "[Epoch 0/1] [Batch 1972/3551] [D loss: 0.056397] [G loss: 0.995734]\n",
      "[Epoch 0/1] [Batch 1973/3551] [D loss: 0.047003] [G loss: 0.975137]\n",
      "[Epoch 0/1] [Batch 1974/3551] [D loss: 0.049363] [G loss: 0.972941]\n",
      "[Epoch 0/1] [Batch 1975/3551] [D loss: 0.044965] [G loss: 0.986911]\n",
      "[Epoch 0/1] [Batch 1976/3551] [D loss: 0.049374] [G loss: 0.971282]\n",
      "[Epoch 0/1] [Batch 1977/3551] [D loss: 0.055767] [G loss: 0.987213]\n",
      "[Epoch 0/1] [Batch 1978/3551] [D loss: 0.050650] [G loss: 0.971676]\n",
      "[Epoch 0/1] [Batch 1979/3551] [D loss: 0.052363] [G loss: 0.964376]\n",
      "[Epoch 0/1] [Batch 1980/3551] [D loss: 0.039891] [G loss: 0.972115]\n",
      "[Epoch 0/1] [Batch 1981/3551] [D loss: 0.034538] [G loss: 0.968163]\n",
      "[Epoch 0/1] [Batch 1982/3551] [D loss: 0.047533] [G loss: 0.977746]\n",
      "[Epoch 0/1] [Batch 1983/3551] [D loss: 0.058874] [G loss: 0.972203]\n",
      "[Epoch 0/1] [Batch 1984/3551] [D loss: 0.061374] [G loss: 0.963951]\n",
      "[Epoch 0/1] [Batch 1985/3551] [D loss: 0.070923] [G loss: 0.973100]\n",
      "[Epoch 0/1] [Batch 1986/3551] [D loss: 0.055961] [G loss: 0.990573]\n",
      "[Epoch 0/1] [Batch 1987/3551] [D loss: 0.061175] [G loss: 0.971470]\n",
      "[Epoch 0/1] [Batch 1988/3551] [D loss: 0.029133] [G loss: 0.976278]\n",
      "[Epoch 0/1] [Batch 1989/3551] [D loss: 0.059081] [G loss: 0.989345]\n",
      "[Epoch 0/1] [Batch 1990/3551] [D loss: 0.064072] [G loss: 0.967984]\n",
      "[Epoch 0/1] [Batch 1991/3551] [D loss: 0.044141] [G loss: 0.966687]\n",
      "[Epoch 0/1] [Batch 1992/3551] [D loss: 0.065555] [G loss: 0.959600]\n",
      "[Epoch 0/1] [Batch 1993/3551] [D loss: 0.035355] [G loss: 0.985367]\n",
      "[Epoch 0/1] [Batch 1994/3551] [D loss: 0.042262] [G loss: 0.979688]\n",
      "[Epoch 0/1] [Batch 1995/3551] [D loss: 0.061066] [G loss: 0.987949]\n",
      "[Epoch 0/1] [Batch 1996/3551] [D loss: 0.052823] [G loss: 0.958815]\n",
      "[Epoch 0/1] [Batch 1997/3551] [D loss: 0.032366] [G loss: 0.970799]\n",
      "[Epoch 0/1] [Batch 1998/3551] [D loss: 0.043207] [G loss: 0.972726]\n",
      "[Epoch 0/1] [Batch 1999/3551] [D loss: 0.063267] [G loss: 0.971672]\n",
      "[Epoch 0/1] [Batch 2000/3551] [D loss: 0.059317] [G loss: 0.961186]\n",
      "[Epoch 0/1] [Batch 2001/3551] [D loss: 0.063781] [G loss: 0.985673]\n",
      "[Epoch 0/1] [Batch 2002/3551] [D loss: 0.050265] [G loss: 1.001239]\n",
      "[Epoch 0/1] [Batch 2003/3551] [D loss: 0.060916] [G loss: 0.994470]\n",
      "[Epoch 0/1] [Batch 2004/3551] [D loss: 0.045717] [G loss: 0.970545]\n",
      "[Epoch 0/1] [Batch 2005/3551] [D loss: 0.068623] [G loss: 0.971697]\n",
      "[Epoch 0/1] [Batch 2006/3551] [D loss: 0.098714] [G loss: 0.977220]\n",
      "[Epoch 0/1] [Batch 2007/3551] [D loss: 0.064684] [G loss: 0.950953]\n",
      "[Epoch 0/1] [Batch 2008/3551] [D loss: 0.057492] [G loss: 0.975744]\n",
      "[Epoch 0/1] [Batch 2009/3551] [D loss: 0.055320] [G loss: 0.988022]\n",
      "[Epoch 0/1] [Batch 2010/3551] [D loss: 0.052438] [G loss: 0.967135]\n",
      "[Epoch 0/1] [Batch 2011/3551] [D loss: 0.042500] [G loss: 0.975699]\n",
      "[Epoch 0/1] [Batch 2012/3551] [D loss: 0.050047] [G loss: 0.971550]\n",
      "[Epoch 0/1] [Batch 2013/3551] [D loss: 0.034979] [G loss: 0.975857]\n",
      "[Epoch 0/1] [Batch 2014/3551] [D loss: 0.055897] [G loss: 0.964610]\n",
      "[Epoch 0/1] [Batch 2015/3551] [D loss: 0.054942] [G loss: 0.965796]\n",
      "[Epoch 0/1] [Batch 2016/3551] [D loss: 0.054487] [G loss: 0.976279]\n",
      "[Epoch 0/1] [Batch 2017/3551] [D loss: 0.067652] [G loss: 0.994924]\n",
      "[Epoch 0/1] [Batch 2018/3551] [D loss: 0.037161] [G loss: 0.962764]\n",
      "[Epoch 0/1] [Batch 2019/3551] [D loss: 0.034748] [G loss: 0.963974]\n",
      "[Epoch 0/1] [Batch 2020/3551] [D loss: 0.041236] [G loss: 0.970407]\n",
      "[Epoch 0/1] [Batch 2021/3551] [D loss: 0.032522] [G loss: 0.965844]\n",
      "[Epoch 0/1] [Batch 2022/3551] [D loss: 0.048975] [G loss: 0.967103]\n",
      "[Epoch 0/1] [Batch 2023/3551] [D loss: 0.050424] [G loss: 0.972891]\n",
      "[Epoch 0/1] [Batch 2024/3551] [D loss: 0.064390] [G loss: 0.978879]\n",
      "[Epoch 0/1] [Batch 2025/3551] [D loss: 0.060277] [G loss: 0.981819]\n",
      "[Epoch 0/1] [Batch 2026/3551] [D loss: 0.050055] [G loss: 0.979893]\n",
      "[Epoch 0/1] [Batch 2027/3551] [D loss: 0.049612] [G loss: 0.968265]\n",
      "[Epoch 0/1] [Batch 2028/3551] [D loss: 0.044091] [G loss: 0.974228]\n",
      "[Epoch 0/1] [Batch 2029/3551] [D loss: 0.073242] [G loss: 0.970874]\n",
      "[Epoch 0/1] [Batch 2030/3551] [D loss: 0.063192] [G loss: 0.997688]\n",
      "[Epoch 0/1] [Batch 2031/3551] [D loss: 0.027739] [G loss: 0.980754]\n",
      "[Epoch 0/1] [Batch 2032/3551] [D loss: 0.045382] [G loss: 0.965607]\n",
      "[Epoch 0/1] [Batch 2033/3551] [D loss: 0.065455] [G loss: 0.983118]\n",
      "[Epoch 0/1] [Batch 2034/3551] [D loss: 0.036921] [G loss: 0.981872]\n",
      "[Epoch 0/1] [Batch 2035/3551] [D loss: 0.086214] [G loss: 0.991037]\n",
      "[Epoch 0/1] [Batch 2036/3551] [D loss: 0.024028] [G loss: 0.976322]\n",
      "[Epoch 0/1] [Batch 2037/3551] [D loss: 0.042651] [G loss: 0.979362]\n",
      "[Epoch 0/1] [Batch 2038/3551] [D loss: 0.038387] [G loss: 0.973694]\n",
      "[Epoch 0/1] [Batch 2039/3551] [D loss: 0.086258] [G loss: 0.965986]\n",
      "[Epoch 0/1] [Batch 2040/3551] [D loss: 0.049477] [G loss: 0.979015]\n",
      "[Epoch 0/1] [Batch 2041/3551] [D loss: 0.064482] [G loss: 0.953373]\n",
      "[Epoch 0/1] [Batch 2042/3551] [D loss: 0.071242] [G loss: 1.004440]\n",
      "[Epoch 0/1] [Batch 2043/3551] [D loss: 0.035525] [G loss: 0.988610]\n",
      "[Epoch 0/1] [Batch 2044/3551] [D loss: 0.069297] [G loss: 0.981171]\n",
      "[Epoch 0/1] [Batch 2045/3551] [D loss: 0.069954] [G loss: 0.987920]\n",
      "[Epoch 0/1] [Batch 2046/3551] [D loss: 0.042717] [G loss: 0.985057]\n",
      "[Epoch 0/1] [Batch 2047/3551] [D loss: 0.055285] [G loss: 0.967205]\n",
      "[Epoch 0/1] [Batch 2048/3551] [D loss: 0.087963] [G loss: 0.963921]\n",
      "[Epoch 0/1] [Batch 2049/3551] [D loss: 0.061024] [G loss: 0.972066]\n",
      "[Epoch 0/1] [Batch 2050/3551] [D loss: 0.044579] [G loss: 0.987848]\n",
      "[Epoch 0/1] [Batch 2051/3551] [D loss: 0.027684] [G loss: 0.977777]\n",
      "[Epoch 0/1] [Batch 2052/3551] [D loss: 0.056447] [G loss: 0.971848]\n",
      "[Epoch 0/1] [Batch 2053/3551] [D loss: 0.046092] [G loss: 0.995180]\n",
      "[Epoch 0/1] [Batch 2054/3551] [D loss: 0.046617] [G loss: 0.993076]\n",
      "[Epoch 0/1] [Batch 2055/3551] [D loss: 0.041434] [G loss: 0.973983]\n",
      "[Epoch 0/1] [Batch 2056/3551] [D loss: 0.032236] [G loss: 0.979653]\n",
      "[Epoch 0/1] [Batch 2057/3551] [D loss: 0.056074] [G loss: 0.971583]\n",
      "[Epoch 0/1] [Batch 2058/3551] [D loss: 0.051975] [G loss: 0.997002]\n",
      "[Epoch 0/1] [Batch 2059/3551] [D loss: 0.041121] [G loss: 0.983147]\n",
      "[Epoch 0/1] [Batch 2060/3551] [D loss: 0.041625] [G loss: 0.990442]\n",
      "[Epoch 0/1] [Batch 2061/3551] [D loss: 0.059874] [G loss: 1.000367]\n",
      "[Epoch 0/1] [Batch 2062/3551] [D loss: 0.034277] [G loss: 0.978372]\n",
      "[Epoch 0/1] [Batch 2063/3551] [D loss: 0.064769] [G loss: 0.994536]\n",
      "[Epoch 0/1] [Batch 2064/3551] [D loss: 0.034872] [G loss: 0.985854]\n",
      "[Epoch 0/1] [Batch 2065/3551] [D loss: 0.063246] [G loss: 0.988405]\n",
      "[Epoch 0/1] [Batch 2066/3551] [D loss: 0.044367] [G loss: 0.973426]\n",
      "[Epoch 0/1] [Batch 2067/3551] [D loss: 0.044739] [G loss: 1.001494]\n",
      "[Epoch 0/1] [Batch 2068/3551] [D loss: 0.045103] [G loss: 0.973040]\n",
      "[Epoch 0/1] [Batch 2069/3551] [D loss: 0.087470] [G loss: 0.971620]\n",
      "[Epoch 0/1] [Batch 2070/3551] [D loss: 0.054414] [G loss: 0.973668]\n",
      "[Epoch 0/1] [Batch 2071/3551] [D loss: 0.046839] [G loss: 0.973195]\n",
      "[Epoch 0/1] [Batch 2072/3551] [D loss: 0.035496] [G loss: 0.990008]\n",
      "[Epoch 0/1] [Batch 2073/3551] [D loss: 0.046277] [G loss: 0.963804]\n",
      "[Epoch 0/1] [Batch 2074/3551] [D loss: 0.057019] [G loss: 0.973968]\n",
      "[Epoch 0/1] [Batch 2075/3551] [D loss: 0.044984] [G loss: 0.976085]\n",
      "[Epoch 0/1] [Batch 2076/3551] [D loss: 0.073235] [G loss: 0.989502]\n",
      "[Epoch 0/1] [Batch 2077/3551] [D loss: 0.027519] [G loss: 0.971675]\n",
      "[Epoch 0/1] [Batch 2078/3551] [D loss: 0.032023] [G loss: 0.992858]\n",
      "[Epoch 0/1] [Batch 2079/3551] [D loss: 0.051271] [G loss: 0.984598]\n",
      "[Epoch 0/1] [Batch 2080/3551] [D loss: 0.055997] [G loss: 0.980178]\n",
      "[Epoch 0/1] [Batch 2081/3551] [D loss: 0.037609] [G loss: 0.964744]\n",
      "[Epoch 0/1] [Batch 2082/3551] [D loss: 0.044003] [G loss: 0.989826]\n",
      "[Epoch 0/1] [Batch 2083/3551] [D loss: 0.025784] [G loss: 0.990332]\n",
      "[Epoch 0/1] [Batch 2084/3551] [D loss: 0.048086] [G loss: 0.972529]\n",
      "[Epoch 0/1] [Batch 2085/3551] [D loss: 0.052874] [G loss: 0.969027]\n",
      "[Epoch 0/1] [Batch 2086/3551] [D loss: 0.037765] [G loss: 0.971311]\n",
      "[Epoch 0/1] [Batch 2087/3551] [D loss: 0.058903] [G loss: 0.962945]\n",
      "[Epoch 0/1] [Batch 2088/3551] [D loss: 0.046697] [G loss: 0.965708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2089/3551] [D loss: 0.059876] [G loss: 0.987130]\n",
      "[Epoch 0/1] [Batch 2090/3551] [D loss: 0.068339] [G loss: 0.985626]\n",
      "[Epoch 0/1] [Batch 2091/3551] [D loss: 0.034462] [G loss: 0.982355]\n",
      "[Epoch 0/1] [Batch 2092/3551] [D loss: 0.053544] [G loss: 0.980066]\n",
      "[Epoch 0/1] [Batch 2093/3551] [D loss: 0.052959] [G loss: 0.983496]\n",
      "[Epoch 0/1] [Batch 2094/3551] [D loss: 0.055226] [G loss: 0.972856]\n",
      "[Epoch 0/1] [Batch 2095/3551] [D loss: 0.058186] [G loss: 0.961738]\n",
      "[Epoch 0/1] [Batch 2096/3551] [D loss: 0.044852] [G loss: 0.983933]\n",
      "[Epoch 0/1] [Batch 2097/3551] [D loss: 0.035835] [G loss: 0.981439]\n",
      "[Epoch 0/1] [Batch 2098/3551] [D loss: 0.047944] [G loss: 0.973768]\n",
      "[Epoch 0/1] [Batch 2099/3551] [D loss: 0.047287] [G loss: 0.987180]\n",
      "[Epoch 0/1] [Batch 2100/3551] [D loss: 0.059671] [G loss: 0.972275]\n",
      "[Epoch 0/1] [Batch 2101/3551] [D loss: 0.072728] [G loss: 0.971321]\n",
      "[Epoch 0/1] [Batch 2102/3551] [D loss: 0.023061] [G loss: 0.975639]\n",
      "[Epoch 0/1] [Batch 2103/3551] [D loss: 0.043076] [G loss: 0.976082]\n",
      "[Epoch 0/1] [Batch 2104/3551] [D loss: 0.045746] [G loss: 0.975989]\n",
      "[Epoch 0/1] [Batch 2105/3551] [D loss: 0.045063] [G loss: 0.978547]\n",
      "[Epoch 0/1] [Batch 2106/3551] [D loss: 0.057022] [G loss: 0.980586]\n",
      "[Epoch 0/1] [Batch 2107/3551] [D loss: 0.058501] [G loss: 0.973590]\n",
      "[Epoch 0/1] [Batch 2108/3551] [D loss: 0.049171] [G loss: 0.970673]\n",
      "[Epoch 0/1] [Batch 2109/3551] [D loss: 0.051097] [G loss: 0.977063]\n",
      "[Epoch 0/1] [Batch 2110/3551] [D loss: 0.029144] [G loss: 0.969822]\n",
      "[Epoch 0/1] [Batch 2111/3551] [D loss: 0.027838] [G loss: 0.954656]\n",
      "[Epoch 0/1] [Batch 2112/3551] [D loss: 0.051400] [G loss: 0.964536]\n",
      "[Epoch 0/1] [Batch 2113/3551] [D loss: 0.043220] [G loss: 0.977585]\n",
      "[Epoch 0/1] [Batch 2114/3551] [D loss: 0.050262] [G loss: 0.962977]\n",
      "[Epoch 0/1] [Batch 2115/3551] [D loss: 0.055417] [G loss: 0.973237]\n",
      "[Epoch 0/1] [Batch 2116/3551] [D loss: 0.044917] [G loss: 0.967297]\n",
      "[Epoch 0/1] [Batch 2117/3551] [D loss: 0.062547] [G loss: 0.974042]\n",
      "[Epoch 0/1] [Batch 2118/3551] [D loss: 0.072314] [G loss: 0.988519]\n",
      "[Epoch 0/1] [Batch 2119/3551] [D loss: 0.054247] [G loss: 0.962711]\n",
      "[Epoch 0/1] [Batch 2120/3551] [D loss: 0.065159] [G loss: 0.980616]\n",
      "[Epoch 0/1] [Batch 2121/3551] [D loss: 0.061926] [G loss: 0.985365]\n",
      "[Epoch 0/1] [Batch 2122/3551] [D loss: 0.041300] [G loss: 0.988704]\n",
      "[Epoch 0/1] [Batch 2123/3551] [D loss: 0.050599] [G loss: 0.990801]\n",
      "[Epoch 0/1] [Batch 2124/3551] [D loss: 0.034237] [G loss: 0.962595]\n",
      "[Epoch 0/1] [Batch 2125/3551] [D loss: 0.044269] [G loss: 0.984290]\n",
      "[Epoch 0/1] [Batch 2126/3551] [D loss: 0.057254] [G loss: 1.003023]\n",
      "[Epoch 0/1] [Batch 2127/3551] [D loss: 0.056299] [G loss: 0.979733]\n",
      "[Epoch 0/1] [Batch 2128/3551] [D loss: 0.054473] [G loss: 0.975364]\n",
      "[Epoch 0/1] [Batch 2129/3551] [D loss: 0.050415] [G loss: 0.984588]\n",
      "[Epoch 0/1] [Batch 2130/3551] [D loss: 0.052374] [G loss: 0.992883]\n",
      "[Epoch 0/1] [Batch 2131/3551] [D loss: 0.065467] [G loss: 0.973967]\n",
      "[Epoch 0/1] [Batch 2132/3551] [D loss: 0.044273] [G loss: 0.993851]\n",
      "[Epoch 0/1] [Batch 2133/3551] [D loss: 0.041294] [G loss: 0.985399]\n",
      "[Epoch 0/1] [Batch 2134/3551] [D loss: 0.041040] [G loss: 0.971183]\n",
      "[Epoch 0/1] [Batch 2135/3551] [D loss: 0.032743] [G loss: 0.974023]\n",
      "[Epoch 0/1] [Batch 2136/3551] [D loss: 0.035091] [G loss: 0.982418]\n",
      "[Epoch 0/1] [Batch 2137/3551] [D loss: 0.060688] [G loss: 0.981106]\n",
      "[Epoch 0/1] [Batch 2138/3551] [D loss: 0.041158] [G loss: 0.969704]\n",
      "[Epoch 0/1] [Batch 2139/3551] [D loss: 0.053025] [G loss: 0.982113]\n",
      "[Epoch 0/1] [Batch 2140/3551] [D loss: 0.038616] [G loss: 0.969812]\n",
      "[Epoch 0/1] [Batch 2141/3551] [D loss: 0.042264] [G loss: 0.966819]\n",
      "[Epoch 0/1] [Batch 2142/3551] [D loss: 0.044487] [G loss: 0.995973]\n",
      "[Epoch 0/1] [Batch 2143/3551] [D loss: 0.037415] [G loss: 0.987076]\n",
      "[Epoch 0/1] [Batch 2144/3551] [D loss: 0.039400] [G loss: 0.996186]\n",
      "[Epoch 0/1] [Batch 2145/3551] [D loss: 0.034077] [G loss: 0.974812]\n",
      "[Epoch 0/1] [Batch 2146/3551] [D loss: 0.028452] [G loss: 0.982175]\n",
      "[Epoch 0/1] [Batch 2147/3551] [D loss: 0.040149] [G loss: 0.973234]\n",
      "[Epoch 0/1] [Batch 2148/3551] [D loss: 0.043130] [G loss: 0.989474]\n",
      "[Epoch 0/1] [Batch 2149/3551] [D loss: 0.041800] [G loss: 0.984753]\n",
      "[Epoch 0/1] [Batch 2150/3551] [D loss: 0.036526] [G loss: 0.982992]\n",
      "[Epoch 0/1] [Batch 2151/3551] [D loss: 0.056690] [G loss: 0.956143]\n",
      "[Epoch 0/1] [Batch 2152/3551] [D loss: 0.049141] [G loss: 1.004802]\n",
      "[Epoch 0/1] [Batch 2153/3551] [D loss: 0.026300] [G loss: 0.979569]\n",
      "[Epoch 0/1] [Batch 2154/3551] [D loss: 0.049329] [G loss: 0.994344]\n",
      "[Epoch 0/1] [Batch 2155/3551] [D loss: 0.040048] [G loss: 0.970183]\n",
      "[Epoch 0/1] [Batch 2156/3551] [D loss: 0.078467] [G loss: 1.002170]\n",
      "[Epoch 0/1] [Batch 2157/3551] [D loss: 0.035631] [G loss: 0.979492]\n",
      "[Epoch 0/1] [Batch 2158/3551] [D loss: 0.057828] [G loss: 0.977258]\n",
      "[Epoch 0/1] [Batch 2159/3551] [D loss: 0.061267] [G loss: 0.988405]\n",
      "[Epoch 0/1] [Batch 2160/3551] [D loss: 0.057701] [G loss: 0.974259]\n",
      "[Epoch 0/1] [Batch 2161/3551] [D loss: 0.032501] [G loss: 0.986062]\n",
      "[Epoch 0/1] [Batch 2162/3551] [D loss: 0.033955] [G loss: 0.983393]\n",
      "[Epoch 0/1] [Batch 2163/3551] [D loss: 0.042658] [G loss: 0.965314]\n",
      "[Epoch 0/1] [Batch 2164/3551] [D loss: 0.087168] [G loss: 0.972801]\n",
      "[Epoch 0/1] [Batch 2165/3551] [D loss: 0.088901] [G loss: 0.973218]\n",
      "[Epoch 0/1] [Batch 2166/3551] [D loss: 0.045210] [G loss: 0.970617]\n",
      "[Epoch 0/1] [Batch 2167/3551] [D loss: 0.042537] [G loss: 0.993964]\n",
      "[Epoch 0/1] [Batch 2168/3551] [D loss: 0.037853] [G loss: 0.978108]\n",
      "[Epoch 0/1] [Batch 2169/3551] [D loss: 0.053536] [G loss: 0.975413]\n",
      "[Epoch 0/1] [Batch 2170/3551] [D loss: 0.048179] [G loss: 0.969482]\n",
      "[Epoch 0/1] [Batch 2171/3551] [D loss: 0.036867] [G loss: 0.963053]\n",
      "[Epoch 0/1] [Batch 2172/3551] [D loss: 0.032809] [G loss: 0.981403]\n",
      "[Epoch 0/1] [Batch 2173/3551] [D loss: 0.042439] [G loss: 0.976574]\n",
      "[Epoch 0/1] [Batch 2174/3551] [D loss: 0.041411] [G loss: 0.971884]\n",
      "[Epoch 0/1] [Batch 2175/3551] [D loss: 0.025251] [G loss: 0.986610]\n",
      "[Epoch 0/1] [Batch 2176/3551] [D loss: 0.066553] [G loss: 0.979446]\n",
      "[Epoch 0/1] [Batch 2177/3551] [D loss: 0.061601] [G loss: 0.978417]\n",
      "[Epoch 0/1] [Batch 2178/3551] [D loss: 0.031042] [G loss: 0.970169]\n",
      "[Epoch 0/1] [Batch 2179/3551] [D loss: 0.057630] [G loss: 0.978182]\n",
      "[Epoch 0/1] [Batch 2180/3551] [D loss: 0.045958] [G loss: 0.983867]\n",
      "[Epoch 0/1] [Batch 2181/3551] [D loss: 0.035685] [G loss: 0.997488]\n",
      "[Epoch 0/1] [Batch 2182/3551] [D loss: 0.045741] [G loss: 0.996734]\n",
      "[Epoch 0/1] [Batch 2183/3551] [D loss: 0.039840] [G loss: 0.984232]\n",
      "[Epoch 0/1] [Batch 2184/3551] [D loss: 0.032480] [G loss: 0.976479]\n",
      "[Epoch 0/1] [Batch 2185/3551] [D loss: 0.035255] [G loss: 0.986029]\n",
      "[Epoch 0/1] [Batch 2186/3551] [D loss: 0.039006] [G loss: 0.979107]\n",
      "[Epoch 0/1] [Batch 2187/3551] [D loss: 0.054044] [G loss: 0.985322]\n",
      "[Epoch 0/1] [Batch 2188/3551] [D loss: 0.033002] [G loss: 0.981939]\n",
      "[Epoch 0/1] [Batch 2189/3551] [D loss: 0.055738] [G loss: 0.975371]\n",
      "[Epoch 0/1] [Batch 2190/3551] [D loss: 0.045184] [G loss: 0.981719]\n",
      "[Epoch 0/1] [Batch 2191/3551] [D loss: 0.077183] [G loss: 0.959857]\n",
      "[Epoch 0/1] [Batch 2192/3551] [D loss: 0.063872] [G loss: 0.970443]\n",
      "[Epoch 0/1] [Batch 2193/3551] [D loss: 0.051284] [G loss: 0.974853]\n",
      "[Epoch 0/1] [Batch 2194/3551] [D loss: 0.052465] [G loss: 0.975309]\n",
      "[Epoch 0/1] [Batch 2195/3551] [D loss: 0.055474] [G loss: 0.996491]\n",
      "[Epoch 0/1] [Batch 2196/3551] [D loss: 0.056475] [G loss: 0.967393]\n",
      "[Epoch 0/1] [Batch 2197/3551] [D loss: 0.027395] [G loss: 0.980687]\n",
      "[Epoch 0/1] [Batch 2198/3551] [D loss: 0.037617] [G loss: 0.983239]\n",
      "[Epoch 0/1] [Batch 2199/3551] [D loss: 0.048728] [G loss: 0.974682]\n",
      "[Epoch 0/1] [Batch 2200/3551] [D loss: 0.066469] [G loss: 0.992340]\n",
      "[Epoch 0/1] [Batch 2201/3551] [D loss: 0.044166] [G loss: 0.976107]\n",
      "[Epoch 0/1] [Batch 2202/3551] [D loss: 0.039548] [G loss: 0.983325]\n",
      "[Epoch 0/1] [Batch 2203/3551] [D loss: 0.049534] [G loss: 0.968922]\n",
      "[Epoch 0/1] [Batch 2204/3551] [D loss: 0.043720] [G loss: 0.981465]\n",
      "[Epoch 0/1] [Batch 2205/3551] [D loss: 0.040828] [G loss: 1.003949]\n",
      "[Epoch 0/1] [Batch 2206/3551] [D loss: 0.054703] [G loss: 0.974522]\n",
      "[Epoch 0/1] [Batch 2207/3551] [D loss: 0.047302] [G loss: 0.973204]\n",
      "[Epoch 0/1] [Batch 2208/3551] [D loss: 0.082994] [G loss: 0.977528]\n",
      "[Epoch 0/1] [Batch 2209/3551] [D loss: 0.035739] [G loss: 0.987377]\n",
      "[Epoch 0/1] [Batch 2210/3551] [D loss: 0.044689] [G loss: 0.980472]\n",
      "[Epoch 0/1] [Batch 2211/3551] [D loss: 0.045660] [G loss: 0.983453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2212/3551] [D loss: 0.067665] [G loss: 0.983987]\n",
      "[Epoch 0/1] [Batch 2213/3551] [D loss: 0.032984] [G loss: 0.963247]\n",
      "[Epoch 0/1] [Batch 2214/3551] [D loss: 0.030788] [G loss: 0.988393]\n",
      "[Epoch 0/1] [Batch 2215/3551] [D loss: 0.036704] [G loss: 0.993041]\n",
      "[Epoch 0/1] [Batch 2216/3551] [D loss: 0.031695] [G loss: 0.978602]\n",
      "[Epoch 0/1] [Batch 2217/3551] [D loss: 0.059486] [G loss: 0.986647]\n",
      "[Epoch 0/1] [Batch 2218/3551] [D loss: 0.051342] [G loss: 0.972672]\n",
      "[Epoch 0/1] [Batch 2219/3551] [D loss: 0.065709] [G loss: 0.986517]\n",
      "[Epoch 0/1] [Batch 2220/3551] [D loss: 0.026638] [G loss: 0.980261]\n",
      "[Epoch 0/1] [Batch 2221/3551] [D loss: 0.027049] [G loss: 0.975860]\n",
      "[Epoch 0/1] [Batch 2222/3551] [D loss: 0.069566] [G loss: 0.976171]\n",
      "[Epoch 0/1] [Batch 2223/3551] [D loss: 0.046055] [G loss: 0.967359]\n",
      "[Epoch 0/1] [Batch 2224/3551] [D loss: 0.044383] [G loss: 0.989127]\n",
      "[Epoch 0/1] [Batch 2225/3551] [D loss: 0.060714] [G loss: 0.975853]\n",
      "[Epoch 0/1] [Batch 2226/3551] [D loss: 0.039318] [G loss: 0.972039]\n",
      "[Epoch 0/1] [Batch 2227/3551] [D loss: 0.065363] [G loss: 0.962226]\n",
      "[Epoch 0/1] [Batch 2228/3551] [D loss: 0.054519] [G loss: 0.976762]\n",
      "[Epoch 0/1] [Batch 2229/3551] [D loss: 0.038847] [G loss: 0.975706]\n",
      "[Epoch 0/1] [Batch 2230/3551] [D loss: 0.033679] [G loss: 0.980330]\n",
      "[Epoch 0/1] [Batch 2231/3551] [D loss: 0.038076] [G loss: 0.962662]\n",
      "[Epoch 0/1] [Batch 2232/3551] [D loss: 0.067164] [G loss: 0.976551]\n",
      "[Epoch 0/1] [Batch 2233/3551] [D loss: 0.023019] [G loss: 0.978176]\n",
      "[Epoch 0/1] [Batch 2234/3551] [D loss: 0.030447] [G loss: 0.964604]\n",
      "[Epoch 0/1] [Batch 2235/3551] [D loss: 0.049566] [G loss: 0.982827]\n",
      "[Epoch 0/1] [Batch 2236/3551] [D loss: 0.045445] [G loss: 0.985495]\n",
      "[Epoch 0/1] [Batch 2237/3551] [D loss: 0.043216] [G loss: 0.963973]\n",
      "[Epoch 0/1] [Batch 2238/3551] [D loss: 0.028425] [G loss: 0.975869]\n",
      "[Epoch 0/1] [Batch 2239/3551] [D loss: 0.053003] [G loss: 0.982718]\n",
      "[Epoch 0/1] [Batch 2240/3551] [D loss: 0.048740] [G loss: 0.978984]\n",
      "[Epoch 0/1] [Batch 2241/3551] [D loss: 0.054553] [G loss: 0.967761]\n",
      "[Epoch 0/1] [Batch 2242/3551] [D loss: 0.054854] [G loss: 0.981089]\n",
      "[Epoch 0/1] [Batch 2243/3551] [D loss: 0.033245] [G loss: 0.989353]\n",
      "[Epoch 0/1] [Batch 2244/3551] [D loss: 0.063411] [G loss: 0.978171]\n",
      "[Epoch 0/1] [Batch 2245/3551] [D loss: 0.050209] [G loss: 0.965801]\n",
      "[Epoch 0/1] [Batch 2246/3551] [D loss: 0.034810] [G loss: 0.977113]\n",
      "[Epoch 0/1] [Batch 2247/3551] [D loss: 0.060710] [G loss: 0.983606]\n",
      "[Epoch 0/1] [Batch 2248/3551] [D loss: 0.052284] [G loss: 0.973637]\n",
      "[Epoch 0/1] [Batch 2249/3551] [D loss: 0.045560] [G loss: 0.982148]\n",
      "[Epoch 0/1] [Batch 2250/3551] [D loss: 0.052713] [G loss: 0.982208]\n",
      "[Epoch 0/1] [Batch 2251/3551] [D loss: 0.044957] [G loss: 0.977082]\n",
      "[Epoch 0/1] [Batch 2252/3551] [D loss: 0.066352] [G loss: 0.999710]\n",
      "[Epoch 0/1] [Batch 2253/3551] [D loss: 0.037697] [G loss: 0.981773]\n",
      "[Epoch 0/1] [Batch 2254/3551] [D loss: 0.056496] [G loss: 0.981031]\n",
      "[Epoch 0/1] [Batch 2255/3551] [D loss: 0.035716] [G loss: 0.989348]\n",
      "[Epoch 0/1] [Batch 2256/3551] [D loss: 0.043243] [G loss: 0.996832]\n",
      "[Epoch 0/1] [Batch 2257/3551] [D loss: 0.073693] [G loss: 0.988818]\n",
      "[Epoch 0/1] [Batch 2258/3551] [D loss: 0.034836] [G loss: 0.972316]\n",
      "[Epoch 0/1] [Batch 2259/3551] [D loss: 0.030457] [G loss: 0.981098]\n",
      "[Epoch 0/1] [Batch 2260/3551] [D loss: 0.036835] [G loss: 0.982423]\n",
      "[Epoch 0/1] [Batch 2261/3551] [D loss: 0.054129] [G loss: 0.978927]\n",
      "[Epoch 0/1] [Batch 2262/3551] [D loss: 0.057076] [G loss: 0.988058]\n",
      "[Epoch 0/1] [Batch 2263/3551] [D loss: 0.041876] [G loss: 0.994018]\n",
      "[Epoch 0/1] [Batch 2264/3551] [D loss: 0.037614] [G loss: 0.991837]\n",
      "[Epoch 0/1] [Batch 2265/3551] [D loss: 0.059611] [G loss: 0.991977]\n",
      "[Epoch 0/1] [Batch 2266/3551] [D loss: 0.043111] [G loss: 0.980396]\n",
      "[Epoch 0/1] [Batch 2267/3551] [D loss: 0.017611] [G loss: 0.975850]\n",
      "[Epoch 0/1] [Batch 2268/3551] [D loss: 0.045870] [G loss: 0.995001]\n",
      "[Epoch 0/1] [Batch 2269/3551] [D loss: 0.042832] [G loss: 0.990412]\n",
      "[Epoch 0/1] [Batch 2270/3551] [D loss: 0.062995] [G loss: 0.973382]\n",
      "[Epoch 0/1] [Batch 2271/3551] [D loss: 0.050398] [G loss: 0.986838]\n",
      "[Epoch 0/1] [Batch 2272/3551] [D loss: 0.033688] [G loss: 0.990933]\n",
      "[Epoch 0/1] [Batch 2273/3551] [D loss: 0.051026] [G loss: 0.993795]\n",
      "[Epoch 0/1] [Batch 2274/3551] [D loss: 0.051007] [G loss: 0.982473]\n",
      "[Epoch 0/1] [Batch 2275/3551] [D loss: 0.038609] [G loss: 0.980089]\n",
      "[Epoch 0/1] [Batch 2276/3551] [D loss: 0.039604] [G loss: 0.990061]\n",
      "[Epoch 0/1] [Batch 2277/3551] [D loss: 0.051747] [G loss: 0.986375]\n",
      "[Epoch 0/1] [Batch 2278/3551] [D loss: 0.046124] [G loss: 0.995514]\n",
      "[Epoch 0/1] [Batch 2279/3551] [D loss: 0.069011] [G loss: 0.987416]\n",
      "[Epoch 0/1] [Batch 2280/3551] [D loss: 0.029947] [G loss: 0.987549]\n",
      "[Epoch 0/1] [Batch 2281/3551] [D loss: 0.033442] [G loss: 0.992769]\n",
      "[Epoch 0/1] [Batch 2282/3551] [D loss: 0.060335] [G loss: 0.986072]\n",
      "[Epoch 0/1] [Batch 2283/3551] [D loss: 0.038135] [G loss: 0.996571]\n",
      "[Epoch 0/1] [Batch 2284/3551] [D loss: 0.053679] [G loss: 0.972851]\n",
      "[Epoch 0/1] [Batch 2285/3551] [D loss: 0.055885] [G loss: 0.982471]\n",
      "[Epoch 0/1] [Batch 2286/3551] [D loss: 0.029075] [G loss: 0.977331]\n",
      "[Epoch 0/1] [Batch 2287/3551] [D loss: 0.042763] [G loss: 0.989624]\n",
      "[Epoch 0/1] [Batch 2288/3551] [D loss: 0.037525] [G loss: 0.975531]\n",
      "[Epoch 0/1] [Batch 2289/3551] [D loss: 0.035123] [G loss: 0.991138]\n",
      "[Epoch 0/1] [Batch 2290/3551] [D loss: 0.049010] [G loss: 0.981477]\n",
      "[Epoch 0/1] [Batch 2291/3551] [D loss: 0.042524] [G loss: 0.984117]\n",
      "[Epoch 0/1] [Batch 2292/3551] [D loss: 0.050982] [G loss: 0.977027]\n",
      "[Epoch 0/1] [Batch 2293/3551] [D loss: 0.028399] [G loss: 0.987088]\n",
      "[Epoch 0/1] [Batch 2294/3551] [D loss: 0.053455] [G loss: 0.977274]\n",
      "[Epoch 0/1] [Batch 2295/3551] [D loss: 0.066817] [G loss: 0.985883]\n",
      "[Epoch 0/1] [Batch 2296/3551] [D loss: 0.045796] [G loss: 0.993129]\n",
      "[Epoch 0/1] [Batch 2297/3551] [D loss: 0.032712] [G loss: 0.976356]\n",
      "[Epoch 0/1] [Batch 2298/3551] [D loss: 0.081451] [G loss: 0.967992]\n",
      "[Epoch 0/1] [Batch 2299/3551] [D loss: 0.048690] [G loss: 0.994773]\n",
      "[Epoch 0/1] [Batch 2300/3551] [D loss: 0.033234] [G loss: 0.971710]\n",
      "[Epoch 0/1] [Batch 2301/3551] [D loss: 0.030485] [G loss: 0.976467]\n",
      "[Epoch 0/1] [Batch 2302/3551] [D loss: 0.050747] [G loss: 0.988110]\n",
      "[Epoch 0/1] [Batch 2303/3551] [D loss: 0.030630] [G loss: 0.983045]\n",
      "[Epoch 0/1] [Batch 2304/3551] [D loss: 0.016190] [G loss: 0.972962]\n",
      "[Epoch 0/1] [Batch 2305/3551] [D loss: 0.028072] [G loss: 0.976714]\n",
      "[Epoch 0/1] [Batch 2306/3551] [D loss: 0.062461] [G loss: 0.991161]\n",
      "[Epoch 0/1] [Batch 2307/3551] [D loss: 0.032158] [G loss: 0.986325]\n",
      "[Epoch 0/1] [Batch 2308/3551] [D loss: 0.058855] [G loss: 0.990724]\n",
      "[Epoch 0/1] [Batch 2309/3551] [D loss: 0.038951] [G loss: 0.994786]\n",
      "[Epoch 0/1] [Batch 2310/3551] [D loss: 0.042521] [G loss: 0.980770]\n",
      "[Epoch 0/1] [Batch 2311/3551] [D loss: 0.034497] [G loss: 0.986492]\n",
      "[Epoch 0/1] [Batch 2312/3551] [D loss: 0.029226] [G loss: 0.982908]\n",
      "[Epoch 0/1] [Batch 2313/3551] [D loss: 0.049499] [G loss: 0.970539]\n",
      "[Epoch 0/1] [Batch 2314/3551] [D loss: 0.033470] [G loss: 0.978777]\n",
      "[Epoch 0/1] [Batch 2315/3551] [D loss: 0.030988] [G loss: 0.993479]\n",
      "[Epoch 0/1] [Batch 2316/3551] [D loss: 0.037964] [G loss: 0.982657]\n",
      "[Epoch 0/1] [Batch 2317/3551] [D loss: 0.039351] [G loss: 0.963370]\n",
      "[Epoch 0/1] [Batch 2318/3551] [D loss: 0.037576] [G loss: 0.990443]\n",
      "[Epoch 0/1] [Batch 2319/3551] [D loss: 0.054939] [G loss: 0.989218]\n",
      "[Epoch 0/1] [Batch 2320/3551] [D loss: 0.027611] [G loss: 0.979329]\n",
      "[Epoch 0/1] [Batch 2321/3551] [D loss: 0.030522] [G loss: 0.979090]\n",
      "[Epoch 0/1] [Batch 2322/3551] [D loss: 0.041625] [G loss: 0.974979]\n",
      "[Epoch 0/1] [Batch 2323/3551] [D loss: 0.027829] [G loss: 0.975605]\n",
      "[Epoch 0/1] [Batch 2324/3551] [D loss: 0.042861] [G loss: 0.993684]\n",
      "[Epoch 0/1] [Batch 2325/3551] [D loss: 0.042071] [G loss: 0.991202]\n",
      "[Epoch 0/1] [Batch 2326/3551] [D loss: 0.045021] [G loss: 0.965379]\n",
      "[Epoch 0/1] [Batch 2327/3551] [D loss: 0.052673] [G loss: 0.987981]\n",
      "[Epoch 0/1] [Batch 2328/3551] [D loss: 0.045850] [G loss: 0.974457]\n",
      "[Epoch 0/1] [Batch 2329/3551] [D loss: 0.029055] [G loss: 0.984334]\n",
      "[Epoch 0/1] [Batch 2330/3551] [D loss: 0.037473] [G loss: 0.974440]\n",
      "[Epoch 0/1] [Batch 2331/3551] [D loss: 0.049791] [G loss: 0.990425]\n",
      "[Epoch 0/1] [Batch 2332/3551] [D loss: 0.029844] [G loss: 0.981776]\n",
      "[Epoch 0/1] [Batch 2333/3551] [D loss: 0.032601] [G loss: 0.997890]\n",
      "[Epoch 0/1] [Batch 2334/3551] [D loss: 0.038087] [G loss: 0.971221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2335/3551] [D loss: 0.034543] [G loss: 0.974293]\n",
      "[Epoch 0/1] [Batch 2336/3551] [D loss: 0.049104] [G loss: 1.001837]\n",
      "[Epoch 0/1] [Batch 2337/3551] [D loss: 0.058538] [G loss: 0.986881]\n",
      "[Epoch 0/1] [Batch 2338/3551] [D loss: 0.026578] [G loss: 0.981086]\n",
      "[Epoch 0/1] [Batch 2339/3551] [D loss: 0.050050] [G loss: 0.974450]\n",
      "[Epoch 0/1] [Batch 2340/3551] [D loss: 0.052383] [G loss: 0.979127]\n",
      "[Epoch 0/1] [Batch 2341/3551] [D loss: 0.022062] [G loss: 1.004445]\n",
      "[Epoch 0/1] [Batch 2342/3551] [D loss: 0.040078] [G loss: 0.987998]\n",
      "[Epoch 0/1] [Batch 2343/3551] [D loss: 0.054329] [G loss: 0.972806]\n",
      "[Epoch 0/1] [Batch 2344/3551] [D loss: 0.040775] [G loss: 1.003289]\n",
      "[Epoch 0/1] [Batch 2345/3551] [D loss: 0.032295] [G loss: 0.990533]\n",
      "[Epoch 0/1] [Batch 2346/3551] [D loss: 0.045119] [G loss: 0.986200]\n",
      "[Epoch 0/1] [Batch 2347/3551] [D loss: 0.034003] [G loss: 0.987453]\n",
      "[Epoch 0/1] [Batch 2348/3551] [D loss: 0.084067] [G loss: 0.980928]\n",
      "[Epoch 0/1] [Batch 2349/3551] [D loss: 0.022019] [G loss: 0.984324]\n",
      "[Epoch 0/1] [Batch 2350/3551] [D loss: 0.027436] [G loss: 0.992132]\n",
      "[Epoch 0/1] [Batch 2351/3551] [D loss: 0.034793] [G loss: 0.993949]\n",
      "[Epoch 0/1] [Batch 2352/3551] [D loss: 0.045190] [G loss: 0.985733]\n",
      "[Epoch 0/1] [Batch 2353/3551] [D loss: 0.030386] [G loss: 0.985069]\n",
      "[Epoch 0/1] [Batch 2354/3551] [D loss: 0.047125] [G loss: 0.988482]\n",
      "[Epoch 0/1] [Batch 2355/3551] [D loss: 0.018579] [G loss: 0.989094]\n",
      "[Epoch 0/1] [Batch 2356/3551] [D loss: 0.049682] [G loss: 0.999195]\n",
      "[Epoch 0/1] [Batch 2357/3551] [D loss: 0.042395] [G loss: 0.992272]\n",
      "[Epoch 0/1] [Batch 2358/3551] [D loss: 0.051328] [G loss: 0.977724]\n",
      "[Epoch 0/1] [Batch 2359/3551] [D loss: 0.033777] [G loss: 0.996507]\n",
      "[Epoch 0/1] [Batch 2360/3551] [D loss: 0.047241] [G loss: 0.974357]\n",
      "[Epoch 0/1] [Batch 2361/3551] [D loss: 0.049527] [G loss: 0.980594]\n",
      "[Epoch 0/1] [Batch 2362/3551] [D loss: 0.027070] [G loss: 0.980265]\n",
      "[Epoch 0/1] [Batch 2363/3551] [D loss: 0.025752] [G loss: 0.983928]\n",
      "[Epoch 0/1] [Batch 2364/3551] [D loss: 0.059837] [G loss: 0.978522]\n",
      "[Epoch 0/1] [Batch 2365/3551] [D loss: 0.038382] [G loss: 0.982115]\n",
      "[Epoch 0/1] [Batch 2366/3551] [D loss: 0.023767] [G loss: 0.992616]\n",
      "[Epoch 0/1] [Batch 2367/3551] [D loss: 0.028422] [G loss: 0.991250]\n",
      "[Epoch 0/1] [Batch 2368/3551] [D loss: 0.078341] [G loss: 0.978897]\n",
      "[Epoch 0/1] [Batch 2369/3551] [D loss: 0.056377] [G loss: 0.972908]\n",
      "[Epoch 0/1] [Batch 2370/3551] [D loss: 0.027973] [G loss: 0.969623]\n",
      "[Epoch 0/1] [Batch 2371/3551] [D loss: 0.036153] [G loss: 0.987381]\n",
      "[Epoch 0/1] [Batch 2372/3551] [D loss: 0.051668] [G loss: 0.985218]\n",
      "[Epoch 0/1] [Batch 2373/3551] [D loss: 0.037104] [G loss: 0.990967]\n",
      "[Epoch 0/1] [Batch 2374/3551] [D loss: 0.044028] [G loss: 0.984015]\n",
      "[Epoch 0/1] [Batch 2375/3551] [D loss: 0.043316] [G loss: 0.977237]\n",
      "[Epoch 0/1] [Batch 2376/3551] [D loss: 0.032213] [G loss: 0.989866]\n",
      "[Epoch 0/1] [Batch 2377/3551] [D loss: 0.050083] [G loss: 0.971293]\n",
      "[Epoch 0/1] [Batch 2378/3551] [D loss: 0.038280] [G loss: 0.977549]\n",
      "[Epoch 0/1] [Batch 2379/3551] [D loss: 0.029811] [G loss: 0.980455]\n",
      "[Epoch 0/1] [Batch 2380/3551] [D loss: 0.043346] [G loss: 0.995914]\n",
      "[Epoch 0/1] [Batch 2381/3551] [D loss: 0.053876] [G loss: 0.998618]\n",
      "[Epoch 0/1] [Batch 2382/3551] [D loss: 0.035128] [G loss: 0.966133]\n",
      "[Epoch 0/1] [Batch 2383/3551] [D loss: 0.058844] [G loss: 0.975362]\n",
      "[Epoch 0/1] [Batch 2384/3551] [D loss: 0.024821] [G loss: 0.987756]\n",
      "[Epoch 0/1] [Batch 2385/3551] [D loss: 0.052530] [G loss: 0.984560]\n",
      "[Epoch 0/1] [Batch 2386/3551] [D loss: 0.064091] [G loss: 0.978622]\n",
      "[Epoch 0/1] [Batch 2387/3551] [D loss: 0.039360] [G loss: 0.983082]\n",
      "[Epoch 0/1] [Batch 2388/3551] [D loss: 0.035968] [G loss: 0.982981]\n",
      "[Epoch 0/1] [Batch 2389/3551] [D loss: 0.067825] [G loss: 0.989375]\n",
      "[Epoch 0/1] [Batch 2390/3551] [D loss: 0.058974] [G loss: 0.964772]\n",
      "[Epoch 0/1] [Batch 2391/3551] [D loss: 0.042229] [G loss: 0.978290]\n",
      "[Epoch 0/1] [Batch 2392/3551] [D loss: 0.028711] [G loss: 0.986578]\n",
      "[Epoch 0/1] [Batch 2393/3551] [D loss: 0.035956] [G loss: 0.968744]\n",
      "[Epoch 0/1] [Batch 2394/3551] [D loss: 0.042799] [G loss: 0.982643]\n",
      "[Epoch 0/1] [Batch 2395/3551] [D loss: 0.036440] [G loss: 0.974190]\n",
      "[Epoch 0/1] [Batch 2396/3551] [D loss: 0.050477] [G loss: 1.000472]\n",
      "[Epoch 0/1] [Batch 2397/3551] [D loss: 0.046104] [G loss: 0.981108]\n",
      "[Epoch 0/1] [Batch 2398/3551] [D loss: 0.056952] [G loss: 0.993402]\n",
      "[Epoch 0/1] [Batch 2399/3551] [D loss: 0.049321] [G loss: 0.986937]\n",
      "[Epoch 0/1] [Batch 2400/3551] [D loss: 0.023585] [G loss: 0.973664]\n",
      "[Epoch 0/1] [Batch 2401/3551] [D loss: 0.040070] [G loss: 0.963135]\n",
      "[Epoch 0/1] [Batch 2402/3551] [D loss: 0.052501] [G loss: 0.981321]\n",
      "[Epoch 0/1] [Batch 2403/3551] [D loss: 0.029816] [G loss: 0.986205]\n",
      "[Epoch 0/1] [Batch 2404/3551] [D loss: 0.021875] [G loss: 0.969537]\n",
      "[Epoch 0/1] [Batch 2405/3551] [D loss: 0.020943] [G loss: 0.974671]\n",
      "[Epoch 0/1] [Batch 2406/3551] [D loss: 0.042393] [G loss: 0.986123]\n",
      "[Epoch 0/1] [Batch 2407/3551] [D loss: 0.035865] [G loss: 0.989996]\n",
      "[Epoch 0/1] [Batch 2408/3551] [D loss: 0.049251] [G loss: 0.993195]\n",
      "[Epoch 0/1] [Batch 2409/3551] [D loss: 0.047489] [G loss: 0.987866]\n",
      "[Epoch 0/1] [Batch 2410/3551] [D loss: 0.028583] [G loss: 0.996626]\n",
      "[Epoch 0/1] [Batch 2411/3551] [D loss: 0.060639] [G loss: 0.984780]\n",
      "[Epoch 0/1] [Batch 2412/3551] [D loss: 0.045735] [G loss: 0.981319]\n",
      "[Epoch 0/1] [Batch 2413/3551] [D loss: 0.032109] [G loss: 0.980030]\n",
      "[Epoch 0/1] [Batch 2414/3551] [D loss: 0.036903] [G loss: 0.982322]\n",
      "[Epoch 0/1] [Batch 2415/3551] [D loss: 0.025715] [G loss: 0.977538]\n",
      "[Epoch 0/1] [Batch 2416/3551] [D loss: 0.037058] [G loss: 0.991509]\n",
      "[Epoch 0/1] [Batch 2417/3551] [D loss: 0.046147] [G loss: 0.987036]\n",
      "[Epoch 0/1] [Batch 2418/3551] [D loss: 0.033738] [G loss: 0.983934]\n",
      "[Epoch 0/1] [Batch 2419/3551] [D loss: 0.051636] [G loss: 0.979367]\n",
      "[Epoch 0/1] [Batch 2420/3551] [D loss: 0.056393] [G loss: 1.007421]\n",
      "[Epoch 0/1] [Batch 2421/3551] [D loss: 0.032150] [G loss: 0.981570]\n",
      "[Epoch 0/1] [Batch 2422/3551] [D loss: 0.045239] [G loss: 0.975584]\n",
      "[Epoch 0/1] [Batch 2423/3551] [D loss: 0.038843] [G loss: 0.978640]\n",
      "[Epoch 0/1] [Batch 2424/3551] [D loss: 0.052405] [G loss: 0.984653]\n",
      "[Epoch 0/1] [Batch 2425/3551] [D loss: 0.045980] [G loss: 0.979678]\n",
      "[Epoch 0/1] [Batch 2426/3551] [D loss: 0.045074] [G loss: 0.975182]\n",
      "[Epoch 0/1] [Batch 2427/3551] [D loss: 0.031929] [G loss: 0.985333]\n",
      "[Epoch 0/1] [Batch 2428/3551] [D loss: 0.048832] [G loss: 0.989600]\n",
      "[Epoch 0/1] [Batch 2429/3551] [D loss: 0.035249] [G loss: 0.975995]\n",
      "[Epoch 0/1] [Batch 2430/3551] [D loss: 0.047570] [G loss: 1.000116]\n",
      "[Epoch 0/1] [Batch 2431/3551] [D loss: 0.033189] [G loss: 0.997413]\n",
      "[Epoch 0/1] [Batch 2432/3551] [D loss: 0.038210] [G loss: 0.989774]\n",
      "[Epoch 0/1] [Batch 2433/3551] [D loss: 0.050171] [G loss: 0.987027]\n",
      "[Epoch 0/1] [Batch 2434/3551] [D loss: 0.028440] [G loss: 0.993105]\n",
      "[Epoch 0/1] [Batch 2435/3551] [D loss: 0.035992] [G loss: 0.995412]\n",
      "[Epoch 0/1] [Batch 2436/3551] [D loss: 0.042815] [G loss: 0.991755]\n",
      "[Epoch 0/1] [Batch 2437/3551] [D loss: 0.053064] [G loss: 0.987572]\n",
      "[Epoch 0/1] [Batch 2438/3551] [D loss: 0.040058] [G loss: 0.977789]\n",
      "[Epoch 0/1] [Batch 2439/3551] [D loss: 0.024310] [G loss: 0.980550]\n",
      "[Epoch 0/1] [Batch 2440/3551] [D loss: 0.040959] [G loss: 0.991032]\n",
      "[Epoch 0/1] [Batch 2441/3551] [D loss: 0.047631] [G loss: 0.969138]\n",
      "[Epoch 0/1] [Batch 2442/3551] [D loss: 0.050780] [G loss: 0.978249]\n",
      "[Epoch 0/1] [Batch 2443/3551] [D loss: 0.031554] [G loss: 0.974626]\n",
      "[Epoch 0/1] [Batch 2444/3551] [D loss: 0.046302] [G loss: 0.981615]\n",
      "[Epoch 0/1] [Batch 2445/3551] [D loss: 0.049290] [G loss: 0.987962]\n",
      "[Epoch 0/1] [Batch 2446/3551] [D loss: 0.036812] [G loss: 0.990028]\n",
      "[Epoch 0/1] [Batch 2447/3551] [D loss: 0.054726] [G loss: 0.984008]\n",
      "[Epoch 0/1] [Batch 2448/3551] [D loss: 0.039567] [G loss: 0.983217]\n",
      "[Epoch 0/1] [Batch 2449/3551] [D loss: 0.028595] [G loss: 0.987669]\n",
      "[Epoch 0/1] [Batch 2450/3551] [D loss: 0.039187] [G loss: 0.993593]\n",
      "[Epoch 0/1] [Batch 2451/3551] [D loss: 0.035812] [G loss: 0.967733]\n",
      "[Epoch 0/1] [Batch 2452/3551] [D loss: 0.055192] [G loss: 0.976127]\n",
      "[Epoch 0/1] [Batch 2453/3551] [D loss: 0.039268] [G loss: 1.003885]\n",
      "[Epoch 0/1] [Batch 2454/3551] [D loss: 0.026864] [G loss: 0.978079]\n",
      "[Epoch 0/1] [Batch 2455/3551] [D loss: 0.060643] [G loss: 0.980320]\n",
      "[Epoch 0/1] [Batch 2456/3551] [D loss: 0.043020] [G loss: 0.977554]\n",
      "[Epoch 0/1] [Batch 2457/3551] [D loss: 0.049121] [G loss: 0.976656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2458/3551] [D loss: 0.029270] [G loss: 0.994759]\n",
      "[Epoch 0/1] [Batch 2459/3551] [D loss: 0.042082] [G loss: 0.989448]\n",
      "[Epoch 0/1] [Batch 2460/3551] [D loss: 0.043467] [G loss: 0.983809]\n",
      "[Epoch 0/1] [Batch 2461/3551] [D loss: 0.033429] [G loss: 0.996610]\n",
      "[Epoch 0/1] [Batch 2462/3551] [D loss: 0.033250] [G loss: 0.975304]\n",
      "[Epoch 0/1] [Batch 2463/3551] [D loss: 0.037677] [G loss: 0.996550]\n",
      "[Epoch 0/1] [Batch 2464/3551] [D loss: 0.041389] [G loss: 0.979547]\n",
      "[Epoch 0/1] [Batch 2465/3551] [D loss: 0.027510] [G loss: 0.978245]\n",
      "[Epoch 0/1] [Batch 2466/3551] [D loss: 0.026805] [G loss: 0.977907]\n",
      "[Epoch 0/1] [Batch 2467/3551] [D loss: 0.076463] [G loss: 0.967414]\n",
      "[Epoch 0/1] [Batch 2468/3551] [D loss: 0.021400] [G loss: 0.982629]\n",
      "[Epoch 0/1] [Batch 2469/3551] [D loss: 0.024782] [G loss: 1.008533]\n",
      "[Epoch 0/1] [Batch 2470/3551] [D loss: 0.043306] [G loss: 0.980806]\n",
      "[Epoch 0/1] [Batch 2471/3551] [D loss: 0.052724] [G loss: 0.982813]\n",
      "[Epoch 0/1] [Batch 2472/3551] [D loss: 0.031866] [G loss: 0.980001]\n",
      "[Epoch 0/1] [Batch 2473/3551] [D loss: 0.037919] [G loss: 0.987705]\n",
      "[Epoch 0/1] [Batch 2474/3551] [D loss: 0.051268] [G loss: 0.973271]\n",
      "[Epoch 0/1] [Batch 2475/3551] [D loss: 0.029998] [G loss: 0.974489]\n",
      "[Epoch 0/1] [Batch 2476/3551] [D loss: 0.052887] [G loss: 0.983632]\n",
      "[Epoch 0/1] [Batch 2477/3551] [D loss: 0.041245] [G loss: 0.973392]\n",
      "[Epoch 0/1] [Batch 2478/3551] [D loss: 0.034629] [G loss: 0.988493]\n",
      "[Epoch 0/1] [Batch 2479/3551] [D loss: 0.047516] [G loss: 0.976593]\n",
      "[Epoch 0/1] [Batch 2480/3551] [D loss: 0.026921] [G loss: 0.976712]\n",
      "[Epoch 0/1] [Batch 2481/3551] [D loss: 0.046938] [G loss: 0.975113]\n",
      "[Epoch 0/1] [Batch 2482/3551] [D loss: 0.044160] [G loss: 0.986994]\n",
      "[Epoch 0/1] [Batch 2483/3551] [D loss: 0.038480] [G loss: 0.994400]\n",
      "[Epoch 0/1] [Batch 2484/3551] [D loss: 0.053647] [G loss: 0.987552]\n",
      "[Epoch 0/1] [Batch 2485/3551] [D loss: 0.033361] [G loss: 0.984685]\n",
      "[Epoch 0/1] [Batch 2486/3551] [D loss: 0.026993] [G loss: 0.988619]\n",
      "[Epoch 0/1] [Batch 2487/3551] [D loss: 0.043686] [G loss: 0.983676]\n",
      "[Epoch 0/1] [Batch 2488/3551] [D loss: 0.033856] [G loss: 0.988450]\n",
      "[Epoch 0/1] [Batch 2489/3551] [D loss: 0.054187] [G loss: 0.975697]\n",
      "[Epoch 0/1] [Batch 2490/3551] [D loss: 0.048171] [G loss: 0.993245]\n",
      "[Epoch 0/1] [Batch 2491/3551] [D loss: 0.020887] [G loss: 0.988220]\n",
      "[Epoch 0/1] [Batch 2492/3551] [D loss: 0.049055] [G loss: 0.983979]\n",
      "[Epoch 0/1] [Batch 2493/3551] [D loss: 0.035270] [G loss: 0.983811]\n",
      "[Epoch 0/1] [Batch 2494/3551] [D loss: 0.036841] [G loss: 0.989074]\n",
      "[Epoch 0/1] [Batch 2495/3551] [D loss: 0.054088] [G loss: 0.973879]\n",
      "[Epoch 0/1] [Batch 2496/3551] [D loss: 0.030280] [G loss: 0.990492]\n",
      "[Epoch 0/1] [Batch 2497/3551] [D loss: 0.042139] [G loss: 0.994099]\n",
      "[Epoch 0/1] [Batch 2498/3551] [D loss: 0.020419] [G loss: 0.985950]\n",
      "[Epoch 0/1] [Batch 2499/3551] [D loss: 0.071395] [G loss: 0.969594]\n",
      "[Epoch 0/1] [Batch 2500/3551] [D loss: 0.028342] [G loss: 0.992280]\n",
      "[Epoch 0/1] [Batch 2501/3551] [D loss: 0.035819] [G loss: 0.983190]\n",
      "[Epoch 0/1] [Batch 2502/3551] [D loss: 0.029422] [G loss: 0.979952]\n",
      "[Epoch 0/1] [Batch 2503/3551] [D loss: 0.034007] [G loss: 0.993104]\n",
      "[Epoch 0/1] [Batch 2504/3551] [D loss: 0.037057] [G loss: 0.990411]\n",
      "[Epoch 0/1] [Batch 2505/3551] [D loss: 0.038881] [G loss: 1.000749]\n",
      "[Epoch 0/1] [Batch 2506/3551] [D loss: 0.018476] [G loss: 0.996733]\n",
      "[Epoch 0/1] [Batch 2507/3551] [D loss: 0.049629] [G loss: 0.995198]\n",
      "[Epoch 0/1] [Batch 2508/3551] [D loss: 0.033382] [G loss: 0.988216]\n",
      "[Epoch 0/1] [Batch 2509/3551] [D loss: 0.046400] [G loss: 0.981156]\n",
      "[Epoch 0/1] [Batch 2510/3551] [D loss: 0.025169] [G loss: 0.985449]\n",
      "[Epoch 0/1] [Batch 2511/3551] [D loss: 0.030128] [G loss: 0.994005]\n",
      "[Epoch 0/1] [Batch 2512/3551] [D loss: 0.042734] [G loss: 0.988507]\n",
      "[Epoch 0/1] [Batch 2513/3551] [D loss: 0.048458] [G loss: 0.991662]\n",
      "[Epoch 0/1] [Batch 2514/3551] [D loss: 0.026313] [G loss: 0.974448]\n",
      "[Epoch 0/1] [Batch 2515/3551] [D loss: 0.028702] [G loss: 0.987622]\n",
      "[Epoch 0/1] [Batch 2516/3551] [D loss: 0.044309] [G loss: 0.993669]\n",
      "[Epoch 0/1] [Batch 2517/3551] [D loss: 0.032480] [G loss: 0.978846]\n",
      "[Epoch 0/1] [Batch 2518/3551] [D loss: 0.025072] [G loss: 0.991681]\n",
      "[Epoch 0/1] [Batch 2519/3551] [D loss: 0.038072] [G loss: 0.978881]\n",
      "[Epoch 0/1] [Batch 2520/3551] [D loss: 0.049081] [G loss: 0.991855]\n",
      "[Epoch 0/1] [Batch 2521/3551] [D loss: 0.036249] [G loss: 0.992015]\n",
      "[Epoch 0/1] [Batch 2522/3551] [D loss: 0.031378] [G loss: 0.984397]\n",
      "[Epoch 0/1] [Batch 2523/3551] [D loss: 0.026149] [G loss: 0.977730]\n",
      "[Epoch 0/1] [Batch 2524/3551] [D loss: 0.034283] [G loss: 0.989195]\n",
      "[Epoch 0/1] [Batch 2525/3551] [D loss: 0.043173] [G loss: 0.977413]\n",
      "[Epoch 0/1] [Batch 2526/3551] [D loss: 0.036460] [G loss: 0.966644]\n",
      "[Epoch 0/1] [Batch 2527/3551] [D loss: 0.035906] [G loss: 0.980955]\n",
      "[Epoch 0/1] [Batch 2528/3551] [D loss: 0.029261] [G loss: 0.986138]\n",
      "[Epoch 0/1] [Batch 2529/3551] [D loss: 0.039846] [G loss: 0.976415]\n",
      "[Epoch 0/1] [Batch 2530/3551] [D loss: 0.022396] [G loss: 0.967043]\n",
      "[Epoch 0/1] [Batch 2531/3551] [D loss: 0.020596] [G loss: 0.965270]\n",
      "[Epoch 0/1] [Batch 2532/3551] [D loss: 0.036410] [G loss: 0.977816]\n",
      "[Epoch 0/1] [Batch 2533/3551] [D loss: 0.026264] [G loss: 0.981216]\n",
      "[Epoch 0/1] [Batch 2534/3551] [D loss: 0.024717] [G loss: 0.975215]\n",
      "[Epoch 0/1] [Batch 2535/3551] [D loss: 0.038533] [G loss: 0.974296]\n",
      "[Epoch 0/1] [Batch 2536/3551] [D loss: 0.031117] [G loss: 0.979030]\n",
      "[Epoch 0/1] [Batch 2537/3551] [D loss: 0.040406] [G loss: 0.985223]\n",
      "[Epoch 0/1] [Batch 2538/3551] [D loss: 0.062335] [G loss: 0.967582]\n",
      "[Epoch 0/1] [Batch 2539/3551] [D loss: 0.032469] [G loss: 1.001214]\n",
      "[Epoch 0/1] [Batch 2540/3551] [D loss: 0.024370] [G loss: 0.996148]\n",
      "[Epoch 0/1] [Batch 2541/3551] [D loss: 0.040478] [G loss: 0.975962]\n",
      "[Epoch 0/1] [Batch 2542/3551] [D loss: 0.028724] [G loss: 1.001870]\n",
      "[Epoch 0/1] [Batch 2543/3551] [D loss: 0.053194] [G loss: 1.002988]\n",
      "[Epoch 0/1] [Batch 2544/3551] [D loss: 0.022973] [G loss: 0.985096]\n",
      "[Epoch 0/1] [Batch 2545/3551] [D loss: 0.022607] [G loss: 0.978240]\n",
      "[Epoch 0/1] [Batch 2546/3551] [D loss: 0.041325] [G loss: 0.983823]\n",
      "[Epoch 0/1] [Batch 2547/3551] [D loss: 0.052147] [G loss: 0.970706]\n",
      "[Epoch 0/1] [Batch 2548/3551] [D loss: 0.023699] [G loss: 0.985518]\n",
      "[Epoch 0/1] [Batch 2549/3551] [D loss: 0.017745] [G loss: 0.990287]\n",
      "[Epoch 0/1] [Batch 2550/3551] [D loss: 0.040818] [G loss: 0.990568]\n",
      "[Epoch 0/1] [Batch 2551/3551] [D loss: 0.040667] [G loss: 0.977825]\n",
      "[Epoch 0/1] [Batch 2552/3551] [D loss: 0.034850] [G loss: 0.988197]\n",
      "[Epoch 0/1] [Batch 2553/3551] [D loss: 0.028177] [G loss: 0.981455]\n",
      "[Epoch 0/1] [Batch 2554/3551] [D loss: 0.035841] [G loss: 0.984270]\n",
      "[Epoch 0/1] [Batch 2555/3551] [D loss: 0.049204] [G loss: 0.980370]\n",
      "[Epoch 0/1] [Batch 2556/3551] [D loss: 0.035415] [G loss: 0.978150]\n",
      "[Epoch 0/1] [Batch 2557/3551] [D loss: 0.029106] [G loss: 0.985951]\n",
      "[Epoch 0/1] [Batch 2558/3551] [D loss: 0.055095] [G loss: 0.990454]\n",
      "[Epoch 0/1] [Batch 2559/3551] [D loss: 0.035203] [G loss: 0.982507]\n",
      "[Epoch 0/1] [Batch 2560/3551] [D loss: 0.064248] [G loss: 0.988106]\n",
      "[Epoch 0/1] [Batch 2561/3551] [D loss: 0.026967] [G loss: 0.979124]\n",
      "[Epoch 0/1] [Batch 2562/3551] [D loss: 0.036503] [G loss: 0.982388]\n",
      "[Epoch 0/1] [Batch 2563/3551] [D loss: 0.052298] [G loss: 0.985011]\n",
      "[Epoch 0/1] [Batch 2564/3551] [D loss: 0.033031] [G loss: 1.001513]\n",
      "[Epoch 0/1] [Batch 2565/3551] [D loss: 0.020434] [G loss: 0.972735]\n",
      "[Epoch 0/1] [Batch 2566/3551] [D loss: 0.035072] [G loss: 0.975321]\n",
      "[Epoch 0/1] [Batch 2567/3551] [D loss: 0.025016] [G loss: 0.986821]\n",
      "[Epoch 0/1] [Batch 2568/3551] [D loss: 0.037382] [G loss: 0.983397]\n",
      "[Epoch 0/1] [Batch 2569/3551] [D loss: 0.033172] [G loss: 0.991586]\n",
      "[Epoch 0/1] [Batch 2570/3551] [D loss: 0.044815] [G loss: 0.992375]\n",
      "[Epoch 0/1] [Batch 2571/3551] [D loss: 0.022622] [G loss: 0.986065]\n",
      "[Epoch 0/1] [Batch 2572/3551] [D loss: 0.044706] [G loss: 0.971299]\n",
      "[Epoch 0/1] [Batch 2573/3551] [D loss: 0.042363] [G loss: 0.981848]\n",
      "[Epoch 0/1] [Batch 2574/3551] [D loss: 0.042122] [G loss: 0.995115]\n",
      "[Epoch 0/1] [Batch 2575/3551] [D loss: 0.038257] [G loss: 0.995764]\n",
      "[Epoch 0/1] [Batch 2576/3551] [D loss: 0.035388] [G loss: 0.992834]\n",
      "[Epoch 0/1] [Batch 2577/3551] [D loss: 0.053245] [G loss: 0.983296]\n",
      "[Epoch 0/1] [Batch 2578/3551] [D loss: 0.041380] [G loss: 0.979673]\n",
      "[Epoch 0/1] [Batch 2579/3551] [D loss: 0.046128] [G loss: 0.988607]\n",
      "[Epoch 0/1] [Batch 2580/3551] [D loss: 0.032466] [G loss: 0.986506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2581/3551] [D loss: 0.029686] [G loss: 0.975690]\n",
      "[Epoch 0/1] [Batch 2582/3551] [D loss: 0.037824] [G loss: 0.977292]\n",
      "[Epoch 0/1] [Batch 2583/3551] [D loss: 0.028171] [G loss: 1.004204]\n",
      "[Epoch 0/1] [Batch 2584/3551] [D loss: 0.054262] [G loss: 0.984135]\n",
      "[Epoch 0/1] [Batch 2585/3551] [D loss: 0.030889] [G loss: 0.987775]\n",
      "[Epoch 0/1] [Batch 2586/3551] [D loss: 0.044888] [G loss: 0.982926]\n",
      "[Epoch 0/1] [Batch 2587/3551] [D loss: 0.040465] [G loss: 0.983498]\n",
      "[Epoch 0/1] [Batch 2588/3551] [D loss: 0.027243] [G loss: 0.992153]\n",
      "[Epoch 0/1] [Batch 2589/3551] [D loss: 0.056625] [G loss: 0.991895]\n",
      "[Epoch 0/1] [Batch 2590/3551] [D loss: 0.041157] [G loss: 0.985960]\n",
      "[Epoch 0/1] [Batch 2591/3551] [D loss: 0.036326] [G loss: 0.984877]\n",
      "[Epoch 0/1] [Batch 2592/3551] [D loss: 0.043795] [G loss: 0.988858]\n",
      "[Epoch 0/1] [Batch 2593/3551] [D loss: 0.022021] [G loss: 0.986074]\n",
      "[Epoch 0/1] [Batch 2594/3551] [D loss: 0.033134] [G loss: 0.989301]\n",
      "[Epoch 0/1] [Batch 2595/3551] [D loss: 0.035590] [G loss: 0.978762]\n",
      "[Epoch 0/1] [Batch 2596/3551] [D loss: 0.038959] [G loss: 0.992342]\n",
      "[Epoch 0/1] [Batch 2597/3551] [D loss: 0.034369] [G loss: 0.978785]\n",
      "[Epoch 0/1] [Batch 2598/3551] [D loss: 0.029633] [G loss: 0.994720]\n",
      "[Epoch 0/1] [Batch 2599/3551] [D loss: 0.035296] [G loss: 0.981965]\n",
      "[Epoch 0/1] [Batch 2600/3551] [D loss: 0.039263] [G loss: 1.001643]\n",
      "[Epoch 0/1] [Batch 2601/3551] [D loss: 0.085443] [G loss: 0.983379]\n",
      "[Epoch 0/1] [Batch 2602/3551] [D loss: 0.029014] [G loss: 0.980960]\n",
      "[Epoch 0/1] [Batch 2603/3551] [D loss: 0.020771] [G loss: 0.994714]\n",
      "[Epoch 0/1] [Batch 2604/3551] [D loss: 0.028181] [G loss: 0.976796]\n",
      "[Epoch 0/1] [Batch 2605/3551] [D loss: 0.035249] [G loss: 0.989041]\n",
      "[Epoch 0/1] [Batch 2606/3551] [D loss: 0.050720] [G loss: 0.970623]\n",
      "[Epoch 0/1] [Batch 2607/3551] [D loss: 0.045186] [G loss: 0.983190]\n",
      "[Epoch 0/1] [Batch 2608/3551] [D loss: 0.025636] [G loss: 0.985130]\n",
      "[Epoch 0/1] [Batch 2609/3551] [D loss: 0.041634] [G loss: 0.976497]\n",
      "[Epoch 0/1] [Batch 2610/3551] [D loss: 0.033056] [G loss: 0.985347]\n",
      "[Epoch 0/1] [Batch 2611/3551] [D loss: 0.036155] [G loss: 0.982280]\n",
      "[Epoch 0/1] [Batch 2612/3551] [D loss: 0.022667] [G loss: 0.997022]\n",
      "[Epoch 0/1] [Batch 2613/3551] [D loss: 0.035401] [G loss: 0.990871]\n",
      "[Epoch 0/1] [Batch 2614/3551] [D loss: 0.026514] [G loss: 0.987588]\n",
      "[Epoch 0/1] [Batch 2615/3551] [D loss: 0.034555] [G loss: 0.988291]\n",
      "[Epoch 0/1] [Batch 2616/3551] [D loss: 0.021130] [G loss: 0.983414]\n",
      "[Epoch 0/1] [Batch 2617/3551] [D loss: 0.034694] [G loss: 0.984541]\n",
      "[Epoch 0/1] [Batch 2618/3551] [D loss: 0.050332] [G loss: 0.984401]\n",
      "[Epoch 0/1] [Batch 2619/3551] [D loss: 0.038459] [G loss: 0.989518]\n",
      "[Epoch 0/1] [Batch 2620/3551] [D loss: 0.029837] [G loss: 0.976735]\n",
      "[Epoch 0/1] [Batch 2621/3551] [D loss: 0.029195] [G loss: 0.987097]\n",
      "[Epoch 0/1] [Batch 2622/3551] [D loss: 0.043318] [G loss: 0.972726]\n",
      "[Epoch 0/1] [Batch 2623/3551] [D loss: 0.037559] [G loss: 0.981798]\n",
      "[Epoch 0/1] [Batch 2624/3551] [D loss: 0.037046] [G loss: 0.979399]\n",
      "[Epoch 0/1] [Batch 2625/3551] [D loss: 0.031057] [G loss: 0.982148]\n",
      "[Epoch 0/1] [Batch 2626/3551] [D loss: 0.020093] [G loss: 0.979636]\n",
      "[Epoch 0/1] [Batch 2627/3551] [D loss: 0.047616] [G loss: 0.982157]\n",
      "[Epoch 0/1] [Batch 2628/3551] [D loss: 0.033041] [G loss: 0.984601]\n",
      "[Epoch 0/1] [Batch 2629/3551] [D loss: 0.038185] [G loss: 0.986645]\n",
      "[Epoch 0/1] [Batch 2630/3551] [D loss: 0.040553] [G loss: 0.980520]\n",
      "[Epoch 0/1] [Batch 2631/3551] [D loss: 0.023588] [G loss: 0.975407]\n",
      "[Epoch 0/1] [Batch 2632/3551] [D loss: 0.041228] [G loss: 0.972275]\n",
      "[Epoch 0/1] [Batch 2633/3551] [D loss: 0.045789] [G loss: 0.992584]\n",
      "[Epoch 0/1] [Batch 2634/3551] [D loss: 0.019680] [G loss: 0.977935]\n",
      "[Epoch 0/1] [Batch 2635/3551] [D loss: 0.024159] [G loss: 0.979902]\n",
      "[Epoch 0/1] [Batch 2636/3551] [D loss: 0.029001] [G loss: 0.986722]\n",
      "[Epoch 0/1] [Batch 2637/3551] [D loss: 0.037051] [G loss: 0.978771]\n",
      "[Epoch 0/1] [Batch 2638/3551] [D loss: 0.067301] [G loss: 0.977733]\n",
      "[Epoch 0/1] [Batch 2639/3551] [D loss: 0.029163] [G loss: 0.984163]\n",
      "[Epoch 0/1] [Batch 2640/3551] [D loss: 0.038855] [G loss: 0.983897]\n",
      "[Epoch 0/1] [Batch 2641/3551] [D loss: 0.041183] [G loss: 0.971797]\n",
      "[Epoch 0/1] [Batch 2642/3551] [D loss: 0.026048] [G loss: 0.983722]\n",
      "[Epoch 0/1] [Batch 2643/3551] [D loss: 0.024023] [G loss: 0.984759]\n",
      "[Epoch 0/1] [Batch 2644/3551] [D loss: 0.023281] [G loss: 0.982389]\n",
      "[Epoch 0/1] [Batch 2645/3551] [D loss: 0.039465] [G loss: 0.998120]\n",
      "[Epoch 0/1] [Batch 2646/3551] [D loss: 0.046692] [G loss: 0.995104]\n",
      "[Epoch 0/1] [Batch 2647/3551] [D loss: 0.040626] [G loss: 0.993440]\n",
      "[Epoch 0/1] [Batch 2648/3551] [D loss: 0.051591] [G loss: 0.987451]\n",
      "[Epoch 0/1] [Batch 2649/3551] [D loss: 0.044441] [G loss: 0.997064]\n",
      "[Epoch 0/1] [Batch 2650/3551] [D loss: 0.043181] [G loss: 0.991006]\n",
      "[Epoch 0/1] [Batch 2651/3551] [D loss: 0.040093] [G loss: 1.001835]\n",
      "[Epoch 0/1] [Batch 2652/3551] [D loss: 0.021388] [G loss: 0.979227]\n",
      "[Epoch 0/1] [Batch 2653/3551] [D loss: 0.022919] [G loss: 0.979802]\n",
      "[Epoch 0/1] [Batch 2654/3551] [D loss: 0.030153] [G loss: 0.982515]\n",
      "[Epoch 0/1] [Batch 2655/3551] [D loss: 0.015989] [G loss: 0.969477]\n",
      "[Epoch 0/1] [Batch 2656/3551] [D loss: 0.041057] [G loss: 0.974568]\n",
      "[Epoch 0/1] [Batch 2657/3551] [D loss: 0.022499] [G loss: 0.978909]\n",
      "[Epoch 0/1] [Batch 2658/3551] [D loss: 0.036991] [G loss: 0.987444]\n",
      "[Epoch 0/1] [Batch 2659/3551] [D loss: 0.046037] [G loss: 0.975754]\n",
      "[Epoch 0/1] [Batch 2660/3551] [D loss: 0.024985] [G loss: 0.983273]\n",
      "[Epoch 0/1] [Batch 2661/3551] [D loss: 0.029641] [G loss: 0.972073]\n",
      "[Epoch 0/1] [Batch 2662/3551] [D loss: 0.027017] [G loss: 0.977032]\n",
      "[Epoch 0/1] [Batch 2663/3551] [D loss: 0.037034] [G loss: 0.989810]\n",
      "[Epoch 0/1] [Batch 2664/3551] [D loss: 0.025126] [G loss: 0.976314]\n",
      "[Epoch 0/1] [Batch 2665/3551] [D loss: 0.049298] [G loss: 0.984303]\n",
      "[Epoch 0/1] [Batch 2666/3551] [D loss: 0.028885] [G loss: 0.986667]\n",
      "[Epoch 0/1] [Batch 2667/3551] [D loss: 0.028673] [G loss: 0.990163]\n",
      "[Epoch 0/1] [Batch 2668/3551] [D loss: 0.030160] [G loss: 0.991630]\n",
      "[Epoch 0/1] [Batch 2669/3551] [D loss: 0.042375] [G loss: 0.974808]\n",
      "[Epoch 0/1] [Batch 2670/3551] [D loss: 0.033025] [G loss: 0.961807]\n",
      "[Epoch 0/1] [Batch 2671/3551] [D loss: 0.029430] [G loss: 0.981963]\n",
      "[Epoch 0/1] [Batch 2672/3551] [D loss: 0.062434] [G loss: 0.985739]\n",
      "[Epoch 0/1] [Batch 2673/3551] [D loss: 0.034348] [G loss: 0.978496]\n",
      "[Epoch 0/1] [Batch 2674/3551] [D loss: 0.045717] [G loss: 0.989606]\n",
      "[Epoch 0/1] [Batch 2675/3551] [D loss: 0.037515] [G loss: 0.982413]\n",
      "[Epoch 0/1] [Batch 2676/3551] [D loss: 0.026667] [G loss: 0.980789]\n",
      "[Epoch 0/1] [Batch 2677/3551] [D loss: 0.027618] [G loss: 0.978493]\n",
      "[Epoch 0/1] [Batch 2678/3551] [D loss: 0.033088] [G loss: 0.992199]\n",
      "[Epoch 0/1] [Batch 2679/3551] [D loss: 0.023661] [G loss: 0.993837]\n",
      "[Epoch 0/1] [Batch 2680/3551] [D loss: 0.046023] [G loss: 0.985244]\n",
      "[Epoch 0/1] [Batch 2681/3551] [D loss: 0.021419] [G loss: 0.994129]\n",
      "[Epoch 0/1] [Batch 2682/3551] [D loss: 0.033210] [G loss: 0.984900]\n",
      "[Epoch 0/1] [Batch 2683/3551] [D loss: 0.035444] [G loss: 0.991685]\n",
      "[Epoch 0/1] [Batch 2684/3551] [D loss: 0.039137] [G loss: 0.983810]\n",
      "[Epoch 0/1] [Batch 2685/3551] [D loss: 0.047170] [G loss: 0.975804]\n",
      "[Epoch 0/1] [Batch 2686/3551] [D loss: 0.030379] [G loss: 0.994431]\n",
      "[Epoch 0/1] [Batch 2687/3551] [D loss: 0.039650] [G loss: 0.985220]\n",
      "[Epoch 0/1] [Batch 2688/3551] [D loss: 0.032848] [G loss: 0.985026]\n",
      "[Epoch 0/1] [Batch 2689/3551] [D loss: 0.031216] [G loss: 0.991509]\n",
      "[Epoch 0/1] [Batch 2690/3551] [D loss: 0.041140] [G loss: 0.988046]\n",
      "[Epoch 0/1] [Batch 2691/3551] [D loss: 0.045853] [G loss: 0.981300]\n",
      "[Epoch 0/1] [Batch 2692/3551] [D loss: 0.033240] [G loss: 0.983512]\n",
      "[Epoch 0/1] [Batch 2693/3551] [D loss: 0.031709] [G loss: 0.982579]\n",
      "[Epoch 0/1] [Batch 2694/3551] [D loss: 0.026943] [G loss: 0.981132]\n",
      "[Epoch 0/1] [Batch 2695/3551] [D loss: 0.026713] [G loss: 0.978858]\n",
      "[Epoch 0/1] [Batch 2696/3551] [D loss: 0.030988] [G loss: 0.980533]\n",
      "[Epoch 0/1] [Batch 2697/3551] [D loss: 0.040802] [G loss: 0.992609]\n",
      "[Epoch 0/1] [Batch 2698/3551] [D loss: 0.030579] [G loss: 0.978388]\n",
      "[Epoch 0/1] [Batch 2699/3551] [D loss: 0.019797] [G loss: 0.975920]\n",
      "[Epoch 0/1] [Batch 2700/3551] [D loss: 0.043896] [G loss: 0.980573]\n",
      "[Epoch 0/1] [Batch 2701/3551] [D loss: 0.038497] [G loss: 0.991602]\n",
      "[Epoch 0/1] [Batch 2702/3551] [D loss: 0.035458] [G loss: 0.973407]\n",
      "[Epoch 0/1] [Batch 2703/3551] [D loss: 0.045629] [G loss: 0.982708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2704/3551] [D loss: 0.030842] [G loss: 0.978703]\n",
      "[Epoch 0/1] [Batch 2705/3551] [D loss: 0.052383] [G loss: 0.982395]\n",
      "[Epoch 0/1] [Batch 2706/3551] [D loss: 0.032062] [G loss: 0.996160]\n",
      "[Epoch 0/1] [Batch 2707/3551] [D loss: 0.033414] [G loss: 0.980262]\n",
      "[Epoch 0/1] [Batch 2708/3551] [D loss: 0.032931] [G loss: 0.975465]\n",
      "[Epoch 0/1] [Batch 2709/3551] [D loss: 0.038315] [G loss: 0.989340]\n",
      "[Epoch 0/1] [Batch 2710/3551] [D loss: 0.036314] [G loss: 0.980085]\n",
      "[Epoch 0/1] [Batch 2711/3551] [D loss: 0.041429] [G loss: 0.987928]\n",
      "[Epoch 0/1] [Batch 2712/3551] [D loss: 0.029356] [G loss: 0.982638]\n",
      "[Epoch 0/1] [Batch 2713/3551] [D loss: 0.039823] [G loss: 0.981427]\n",
      "[Epoch 0/1] [Batch 2714/3551] [D loss: 0.049538] [G loss: 0.972025]\n",
      "[Epoch 0/1] [Batch 2715/3551] [D loss: 0.016701] [G loss: 0.980626]\n",
      "[Epoch 0/1] [Batch 2716/3551] [D loss: 0.037551] [G loss: 0.974762]\n",
      "[Epoch 0/1] [Batch 2717/3551] [D loss: 0.031207] [G loss: 0.993321]\n",
      "[Epoch 0/1] [Batch 2718/3551] [D loss: 0.031779] [G loss: 0.978072]\n",
      "[Epoch 0/1] [Batch 2719/3551] [D loss: 0.026392] [G loss: 0.983141]\n",
      "[Epoch 0/1] [Batch 2720/3551] [D loss: 0.029772] [G loss: 0.975104]\n",
      "[Epoch 0/1] [Batch 2721/3551] [D loss: 0.036182] [G loss: 0.993786]\n",
      "[Epoch 0/1] [Batch 2722/3551] [D loss: 0.040113] [G loss: 0.992727]\n",
      "[Epoch 0/1] [Batch 2723/3551] [D loss: 0.027934] [G loss: 0.973751]\n",
      "[Epoch 0/1] [Batch 2724/3551] [D loss: 0.016426] [G loss: 0.984366]\n",
      "[Epoch 0/1] [Batch 2725/3551] [D loss: 0.049161] [G loss: 0.997181]\n",
      "[Epoch 0/1] [Batch 2726/3551] [D loss: 0.037084] [G loss: 0.987839]\n",
      "[Epoch 0/1] [Batch 2727/3551] [D loss: 0.027519] [G loss: 0.987059]\n",
      "[Epoch 0/1] [Batch 2728/3551] [D loss: 0.029756] [G loss: 0.980673]\n",
      "[Epoch 0/1] [Batch 2729/3551] [D loss: 0.046218] [G loss: 0.985257]\n",
      "[Epoch 0/1] [Batch 2730/3551] [D loss: 0.020993] [G loss: 0.976662]\n",
      "[Epoch 0/1] [Batch 2731/3551] [D loss: 0.023479] [G loss: 0.977308]\n",
      "[Epoch 0/1] [Batch 2732/3551] [D loss: 0.027062] [G loss: 0.984619]\n",
      "[Epoch 0/1] [Batch 2733/3551] [D loss: 0.035939] [G loss: 0.978757]\n",
      "[Epoch 0/1] [Batch 2734/3551] [D loss: 0.024078] [G loss: 0.979403]\n",
      "[Epoch 0/1] [Batch 2735/3551] [D loss: 0.019716] [G loss: 0.989548]\n",
      "[Epoch 0/1] [Batch 2736/3551] [D loss: 0.023801] [G loss: 0.992886]\n",
      "[Epoch 0/1] [Batch 2737/3551] [D loss: 0.036574] [G loss: 0.983660]\n",
      "[Epoch 0/1] [Batch 2738/3551] [D loss: 0.024168] [G loss: 0.989136]\n",
      "[Epoch 0/1] [Batch 2739/3551] [D loss: 0.025557] [G loss: 0.977185]\n",
      "[Epoch 0/1] [Batch 2740/3551] [D loss: 0.021446] [G loss: 0.981143]\n",
      "[Epoch 0/1] [Batch 2741/3551] [D loss: 0.024424] [G loss: 0.981277]\n",
      "[Epoch 0/1] [Batch 2742/3551] [D loss: 0.053169] [G loss: 0.980223]\n",
      "[Epoch 0/1] [Batch 2743/3551] [D loss: 0.030910] [G loss: 0.974265]\n",
      "[Epoch 0/1] [Batch 2744/3551] [D loss: 0.034098] [G loss: 0.971658]\n",
      "[Epoch 0/1] [Batch 2745/3551] [D loss: 0.025949] [G loss: 0.990792]\n",
      "[Epoch 0/1] [Batch 2746/3551] [D loss: 0.043215] [G loss: 0.996682]\n",
      "[Epoch 0/1] [Batch 2747/3551] [D loss: 0.032116] [G loss: 0.986166]\n",
      "[Epoch 0/1] [Batch 2748/3551] [D loss: 0.031507] [G loss: 0.976016]\n",
      "[Epoch 0/1] [Batch 2749/3551] [D loss: 0.034284] [G loss: 0.982258]\n",
      "[Epoch 0/1] [Batch 2750/3551] [D loss: 0.023851] [G loss: 0.993745]\n",
      "[Epoch 0/1] [Batch 2751/3551] [D loss: 0.023854] [G loss: 0.976381]\n",
      "[Epoch 0/1] [Batch 2752/3551] [D loss: 0.031269] [G loss: 0.985621]\n",
      "[Epoch 0/1] [Batch 2753/3551] [D loss: 0.030694] [G loss: 0.989162]\n",
      "[Epoch 0/1] [Batch 2754/3551] [D loss: 0.030602] [G loss: 0.993452]\n",
      "[Epoch 0/1] [Batch 2755/3551] [D loss: 0.043946] [G loss: 0.979585]\n",
      "[Epoch 0/1] [Batch 2756/3551] [D loss: 0.033429] [G loss: 0.979804]\n",
      "[Epoch 0/1] [Batch 2757/3551] [D loss: 0.021860] [G loss: 0.968850]\n",
      "[Epoch 0/1] [Batch 2758/3551] [D loss: 0.026135] [G loss: 0.984002]\n",
      "[Epoch 0/1] [Batch 2759/3551] [D loss: 0.026674] [G loss: 0.979635]\n",
      "[Epoch 0/1] [Batch 2760/3551] [D loss: 0.026442] [G loss: 0.987808]\n",
      "[Epoch 0/1] [Batch 2761/3551] [D loss: 0.059279] [G loss: 0.984580]\n",
      "[Epoch 0/1] [Batch 2762/3551] [D loss: 0.029446] [G loss: 0.980207]\n",
      "[Epoch 0/1] [Batch 2763/3551] [D loss: 0.051491] [G loss: 0.975364]\n",
      "[Epoch 0/1] [Batch 2764/3551] [D loss: 0.045637] [G loss: 0.978406]\n",
      "[Epoch 0/1] [Batch 2765/3551] [D loss: 0.016051] [G loss: 0.974091]\n",
      "[Epoch 0/1] [Batch 2766/3551] [D loss: 0.031524] [G loss: 0.967400]\n",
      "[Epoch 0/1] [Batch 2767/3551] [D loss: 0.025375] [G loss: 0.986034]\n",
      "[Epoch 0/1] [Batch 2768/3551] [D loss: 0.030656] [G loss: 0.987121]\n",
      "[Epoch 0/1] [Batch 2769/3551] [D loss: 0.037716] [G loss: 0.981704]\n",
      "[Epoch 0/1] [Batch 2770/3551] [D loss: 0.030955] [G loss: 0.981835]\n",
      "[Epoch 0/1] [Batch 2771/3551] [D loss: 0.039869] [G loss: 0.979662]\n",
      "[Epoch 0/1] [Batch 2772/3551] [D loss: 0.031565] [G loss: 0.994521]\n",
      "[Epoch 0/1] [Batch 2773/3551] [D loss: 0.030508] [G loss: 0.982003]\n",
      "[Epoch 0/1] [Batch 2774/3551] [D loss: 0.036824] [G loss: 0.992042]\n",
      "[Epoch 0/1] [Batch 2775/3551] [D loss: 0.023760] [G loss: 0.995430]\n",
      "[Epoch 0/1] [Batch 2776/3551] [D loss: 0.019610] [G loss: 0.988946]\n",
      "[Epoch 0/1] [Batch 2777/3551] [D loss: 0.029774] [G loss: 0.989310]\n",
      "[Epoch 0/1] [Batch 2778/3551] [D loss: 0.031851] [G loss: 0.985787]\n",
      "[Epoch 0/1] [Batch 2779/3551] [D loss: 0.032738] [G loss: 0.984196]\n",
      "[Epoch 0/1] [Batch 2780/3551] [D loss: 0.039041] [G loss: 0.989388]\n",
      "[Epoch 0/1] [Batch 2781/3551] [D loss: 0.061741] [G loss: 0.983420]\n",
      "[Epoch 0/1] [Batch 2782/3551] [D loss: 0.035740] [G loss: 0.997979]\n",
      "[Epoch 0/1] [Batch 2783/3551] [D loss: 0.028655] [G loss: 0.986667]\n",
      "[Epoch 0/1] [Batch 2784/3551] [D loss: 0.040406] [G loss: 0.976736]\n",
      "[Epoch 0/1] [Batch 2785/3551] [D loss: 0.021027] [G loss: 0.971875]\n",
      "[Epoch 0/1] [Batch 2786/3551] [D loss: 0.014043] [G loss: 0.978762]\n",
      "[Epoch 0/1] [Batch 2787/3551] [D loss: 0.030470] [G loss: 0.997259]\n",
      "[Epoch 0/1] [Batch 2788/3551] [D loss: 0.032841] [G loss: 0.983326]\n",
      "[Epoch 0/1] [Batch 2789/3551] [D loss: 0.039006] [G loss: 0.982315]\n",
      "[Epoch 0/1] [Batch 2790/3551] [D loss: 0.032721] [G loss: 0.981542]\n",
      "[Epoch 0/1] [Batch 2791/3551] [D loss: 0.033328] [G loss: 0.984751]\n",
      "[Epoch 0/1] [Batch 2792/3551] [D loss: 0.038282] [G loss: 0.982766]\n",
      "[Epoch 0/1] [Batch 2793/3551] [D loss: 0.017690] [G loss: 0.980267]\n",
      "[Epoch 0/1] [Batch 2794/3551] [D loss: 0.042994] [G loss: 0.980125]\n",
      "[Epoch 0/1] [Batch 2795/3551] [D loss: 0.039882] [G loss: 0.966783]\n",
      "[Epoch 0/1] [Batch 2796/3551] [D loss: 0.020372] [G loss: 0.992735]\n",
      "[Epoch 0/1] [Batch 2797/3551] [D loss: 0.030804] [G loss: 0.976825]\n",
      "[Epoch 0/1] [Batch 2798/3551] [D loss: 0.030497] [G loss: 0.967989]\n",
      "[Epoch 0/1] [Batch 2799/3551] [D loss: 0.035867] [G loss: 0.976758]\n",
      "[Epoch 0/1] [Batch 2800/3551] [D loss: 0.039341] [G loss: 0.986772]\n",
      "[Epoch 0/1] [Batch 2801/3551] [D loss: 0.024558] [G loss: 0.983559]\n",
      "[Epoch 0/1] [Batch 2802/3551] [D loss: 0.022657] [G loss: 0.992163]\n",
      "[Epoch 0/1] [Batch 2803/3551] [D loss: 0.035179] [G loss: 0.971954]\n",
      "[Epoch 0/1] [Batch 2804/3551] [D loss: 0.033592] [G loss: 0.990981]\n",
      "[Epoch 0/1] [Batch 2805/3551] [D loss: 0.049375] [G loss: 0.974176]\n",
      "[Epoch 0/1] [Batch 2806/3551] [D loss: 0.030611] [G loss: 0.967272]\n",
      "[Epoch 0/1] [Batch 2807/3551] [D loss: 0.033667] [G loss: 0.997255]\n",
      "[Epoch 0/1] [Batch 2808/3551] [D loss: 0.040728] [G loss: 0.984045]\n",
      "[Epoch 0/1] [Batch 2809/3551] [D loss: 0.038485] [G loss: 0.973734]\n",
      "[Epoch 0/1] [Batch 2810/3551] [D loss: 0.050339] [G loss: 0.976853]\n",
      "[Epoch 0/1] [Batch 2811/3551] [D loss: 0.023891] [G loss: 0.974384]\n",
      "[Epoch 0/1] [Batch 2812/3551] [D loss: 0.031844] [G loss: 0.986776]\n",
      "[Epoch 0/1] [Batch 2813/3551] [D loss: 0.028033] [G loss: 0.977028]\n",
      "[Epoch 0/1] [Batch 2814/3551] [D loss: 0.029646] [G loss: 0.979793]\n",
      "[Epoch 0/1] [Batch 2815/3551] [D loss: 0.033648] [G loss: 0.978608]\n",
      "[Epoch 0/1] [Batch 2816/3551] [D loss: 0.023158] [G loss: 0.970869]\n",
      "[Epoch 0/1] [Batch 2817/3551] [D loss: 0.025742] [G loss: 0.976609]\n",
      "[Epoch 0/1] [Batch 2818/3551] [D loss: 0.032404] [G loss: 0.972832]\n",
      "[Epoch 0/1] [Batch 2819/3551] [D loss: 0.030181] [G loss: 0.983296]\n",
      "[Epoch 0/1] [Batch 2820/3551] [D loss: 0.026588] [G loss: 0.975461]\n",
      "[Epoch 0/1] [Batch 2821/3551] [D loss: 0.024138] [G loss: 0.987112]\n",
      "[Epoch 0/1] [Batch 2822/3551] [D loss: 0.028041] [G loss: 0.963517]\n",
      "[Epoch 0/1] [Batch 2823/3551] [D loss: 0.022801] [G loss: 0.985796]\n",
      "[Epoch 0/1] [Batch 2824/3551] [D loss: 0.029486] [G loss: 0.981245]\n",
      "[Epoch 0/1] [Batch 2825/3551] [D loss: 0.020121] [G loss: 0.988515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2826/3551] [D loss: 0.082068] [G loss: 0.982506]\n",
      "[Epoch 0/1] [Batch 2827/3551] [D loss: 0.020856] [G loss: 0.979268]\n",
      "[Epoch 0/1] [Batch 2828/3551] [D loss: 0.022039] [G loss: 0.972499]\n",
      "[Epoch 0/1] [Batch 2829/3551] [D loss: 0.029116] [G loss: 0.984236]\n",
      "[Epoch 0/1] [Batch 2830/3551] [D loss: 0.033570] [G loss: 0.975175]\n",
      "[Epoch 0/1] [Batch 2831/3551] [D loss: 0.039055] [G loss: 0.970590]\n",
      "[Epoch 0/1] [Batch 2832/3551] [D loss: 0.028915] [G loss: 0.984470]\n",
      "[Epoch 0/1] [Batch 2833/3551] [D loss: 0.038727] [G loss: 0.970742]\n",
      "[Epoch 0/1] [Batch 2834/3551] [D loss: 0.035820] [G loss: 0.967354]\n",
      "[Epoch 0/1] [Batch 2835/3551] [D loss: 0.050936] [G loss: 0.986567]\n",
      "[Epoch 0/1] [Batch 2836/3551] [D loss: 0.042192] [G loss: 0.972481]\n",
      "[Epoch 0/1] [Batch 2837/3551] [D loss: 0.040515] [G loss: 0.980933]\n",
      "[Epoch 0/1] [Batch 2838/3551] [D loss: 0.041547] [G loss: 0.972453]\n",
      "[Epoch 0/1] [Batch 2839/3551] [D loss: 0.030027] [G loss: 0.995126]\n",
      "[Epoch 0/1] [Batch 2840/3551] [D loss: 0.028805] [G loss: 0.958719]\n",
      "[Epoch 0/1] [Batch 2841/3551] [D loss: 0.041575] [G loss: 0.967965]\n",
      "[Epoch 0/1] [Batch 2842/3551] [D loss: 0.029938] [G loss: 0.996583]\n",
      "[Epoch 0/1] [Batch 2843/3551] [D loss: 0.026583] [G loss: 0.993761]\n",
      "[Epoch 0/1] [Batch 2844/3551] [D loss: 0.019624] [G loss: 0.967309]\n",
      "[Epoch 0/1] [Batch 2845/3551] [D loss: 0.042719] [G loss: 0.982622]\n",
      "[Epoch 0/1] [Batch 2846/3551] [D loss: 0.030340] [G loss: 0.989740]\n",
      "[Epoch 0/1] [Batch 2847/3551] [D loss: 0.041423] [G loss: 0.974852]\n",
      "[Epoch 0/1] [Batch 2848/3551] [D loss: 0.031120] [G loss: 0.989897]\n",
      "[Epoch 0/1] [Batch 2849/3551] [D loss: 0.019623] [G loss: 0.983053]\n",
      "[Epoch 0/1] [Batch 2850/3551] [D loss: 0.053746] [G loss: 0.980238]\n",
      "[Epoch 0/1] [Batch 2851/3551] [D loss: 0.030053] [G loss: 0.985507]\n",
      "[Epoch 0/1] [Batch 2852/3551] [D loss: 0.012926] [G loss: 0.976676]\n",
      "[Epoch 0/1] [Batch 2853/3551] [D loss: 0.042286] [G loss: 0.982520]\n",
      "[Epoch 0/1] [Batch 2854/3551] [D loss: 0.073711] [G loss: 0.982187]\n",
      "[Epoch 0/1] [Batch 2855/3551] [D loss: 0.028209] [G loss: 0.975559]\n",
      "[Epoch 0/1] [Batch 2856/3551] [D loss: 0.039516] [G loss: 0.979675]\n",
      "[Epoch 0/1] [Batch 2857/3551] [D loss: 0.026255] [G loss: 0.988724]\n",
      "[Epoch 0/1] [Batch 2858/3551] [D loss: 0.031056] [G loss: 0.966142]\n",
      "[Epoch 0/1] [Batch 2859/3551] [D loss: 0.033367] [G loss: 0.983527]\n",
      "[Epoch 0/1] [Batch 2860/3551] [D loss: 0.027276] [G loss: 0.998311]\n",
      "[Epoch 0/1] [Batch 2861/3551] [D loss: 0.020107] [G loss: 0.982444]\n",
      "[Epoch 0/1] [Batch 2862/3551] [D loss: 0.032473] [G loss: 0.971832]\n",
      "[Epoch 0/1] [Batch 2863/3551] [D loss: 0.040952] [G loss: 0.984822]\n",
      "[Epoch 0/1] [Batch 2864/3551] [D loss: 0.026815] [G loss: 0.985460]\n",
      "[Epoch 0/1] [Batch 2865/3551] [D loss: 0.025492] [G loss: 0.989569]\n",
      "[Epoch 0/1] [Batch 2866/3551] [D loss: 0.021007] [G loss: 0.984956]\n",
      "[Epoch 0/1] [Batch 2867/3551] [D loss: 0.025118] [G loss: 0.980471]\n",
      "[Epoch 0/1] [Batch 2868/3551] [D loss: 0.029842] [G loss: 0.991064]\n",
      "[Epoch 0/1] [Batch 2869/3551] [D loss: 0.029921] [G loss: 0.988402]\n",
      "[Epoch 0/1] [Batch 2870/3551] [D loss: 0.031610] [G loss: 0.984361]\n",
      "[Epoch 0/1] [Batch 2871/3551] [D loss: 0.039113] [G loss: 0.982609]\n",
      "[Epoch 0/1] [Batch 2872/3551] [D loss: 0.022181] [G loss: 0.976152]\n",
      "[Epoch 0/1] [Batch 2873/3551] [D loss: 0.038922] [G loss: 0.975884]\n",
      "[Epoch 0/1] [Batch 2874/3551] [D loss: 0.020525] [G loss: 0.977805]\n",
      "[Epoch 0/1] [Batch 2875/3551] [D loss: 0.047062] [G loss: 0.982630]\n",
      "[Epoch 0/1] [Batch 2876/3551] [D loss: 0.019949] [G loss: 0.975615]\n",
      "[Epoch 0/1] [Batch 2877/3551] [D loss: 0.040834] [G loss: 0.994179]\n",
      "[Epoch 0/1] [Batch 2878/3551] [D loss: 0.024623] [G loss: 0.977434]\n",
      "[Epoch 0/1] [Batch 2879/3551] [D loss: 0.026942] [G loss: 0.983246]\n",
      "[Epoch 0/1] [Batch 2880/3551] [D loss: 0.025111] [G loss: 0.987175]\n",
      "[Epoch 0/1] [Batch 2881/3551] [D loss: 0.035465] [G loss: 0.969617]\n",
      "[Epoch 0/1] [Batch 2882/3551] [D loss: 0.025011] [G loss: 0.980545]\n",
      "[Epoch 0/1] [Batch 2883/3551] [D loss: 0.031051] [G loss: 0.975618]\n",
      "[Epoch 0/1] [Batch 2884/3551] [D loss: 0.027419] [G loss: 0.971088]\n",
      "[Epoch 0/1] [Batch 2885/3551] [D loss: 0.042754] [G loss: 0.979699]\n",
      "[Epoch 0/1] [Batch 2886/3551] [D loss: 0.025716] [G loss: 0.987146]\n",
      "[Epoch 0/1] [Batch 2887/3551] [D loss: 0.038145] [G loss: 0.974849]\n",
      "[Epoch 0/1] [Batch 2888/3551] [D loss: 0.049145] [G loss: 0.983046]\n",
      "[Epoch 0/1] [Batch 2889/3551] [D loss: 0.025943] [G loss: 0.970437]\n",
      "[Epoch 0/1] [Batch 2890/3551] [D loss: 0.049265] [G loss: 0.987557]\n",
      "[Epoch 0/1] [Batch 2891/3551] [D loss: 0.032986] [G loss: 0.968724]\n",
      "[Epoch 0/1] [Batch 2892/3551] [D loss: 0.027833] [G loss: 0.977594]\n",
      "[Epoch 0/1] [Batch 2893/3551] [D loss: 0.037922] [G loss: 0.986159]\n",
      "[Epoch 0/1] [Batch 2894/3551] [D loss: 0.044112] [G loss: 0.970376]\n",
      "[Epoch 0/1] [Batch 2895/3551] [D loss: 0.031383] [G loss: 0.983819]\n",
      "[Epoch 0/1] [Batch 2896/3551] [D loss: 0.025174] [G loss: 0.975206]\n",
      "[Epoch 0/1] [Batch 2897/3551] [D loss: 0.051021] [G loss: 0.974048]\n",
      "[Epoch 0/1] [Batch 2898/3551] [D loss: 0.022594] [G loss: 0.970158]\n",
      "[Epoch 0/1] [Batch 2899/3551] [D loss: 0.031904] [G loss: 0.985636]\n",
      "[Epoch 0/1] [Batch 2900/3551] [D loss: 0.022246] [G loss: 0.979049]\n",
      "[Epoch 0/1] [Batch 2901/3551] [D loss: 0.031365] [G loss: 0.971060]\n",
      "[Epoch 0/1] [Batch 2902/3551] [D loss: 0.023646] [G loss: 0.977979]\n",
      "[Epoch 0/1] [Batch 2903/3551] [D loss: 0.031267] [G loss: 0.976025]\n",
      "[Epoch 0/1] [Batch 2904/3551] [D loss: 0.037469] [G loss: 0.972288]\n",
      "[Epoch 0/1] [Batch 2905/3551] [D loss: 0.022048] [G loss: 0.979820]\n",
      "[Epoch 0/1] [Batch 2906/3551] [D loss: 0.026997] [G loss: 0.985373]\n",
      "[Epoch 0/1] [Batch 2907/3551] [D loss: 0.019702] [G loss: 0.991450]\n",
      "[Epoch 0/1] [Batch 2908/3551] [D loss: 0.033814] [G loss: 0.976667]\n",
      "[Epoch 0/1] [Batch 2909/3551] [D loss: 0.044852] [G loss: 0.983729]\n",
      "[Epoch 0/1] [Batch 2910/3551] [D loss: 0.021519] [G loss: 0.979666]\n",
      "[Epoch 0/1] [Batch 2911/3551] [D loss: 0.034172] [G loss: 0.978948]\n",
      "[Epoch 0/1] [Batch 2912/3551] [D loss: 0.021029] [G loss: 0.967779]\n",
      "[Epoch 0/1] [Batch 2913/3551] [D loss: 0.033297] [G loss: 0.981906]\n",
      "[Epoch 0/1] [Batch 2914/3551] [D loss: 0.023820] [G loss: 0.973314]\n",
      "[Epoch 0/1] [Batch 2915/3551] [D loss: 0.055994] [G loss: 0.974006]\n",
      "[Epoch 0/1] [Batch 2916/3551] [D loss: 0.043697] [G loss: 0.981202]\n",
      "[Epoch 0/1] [Batch 2917/3551] [D loss: 0.039027] [G loss: 0.976474]\n",
      "[Epoch 0/1] [Batch 2918/3551] [D loss: 0.024460] [G loss: 0.982223]\n",
      "[Epoch 0/1] [Batch 2919/3551] [D loss: 0.032251] [G loss: 0.982667]\n",
      "[Epoch 0/1] [Batch 2920/3551] [D loss: 0.026056] [G loss: 0.995852]\n",
      "[Epoch 0/1] [Batch 2921/3551] [D loss: 0.022731] [G loss: 0.964111]\n",
      "[Epoch 0/1] [Batch 2922/3551] [D loss: 0.031756] [G loss: 0.967417]\n",
      "[Epoch 0/1] [Batch 2923/3551] [D loss: 0.046250] [G loss: 0.969286]\n",
      "[Epoch 0/1] [Batch 2924/3551] [D loss: 0.035726] [G loss: 0.984339]\n",
      "[Epoch 0/1] [Batch 2925/3551] [D loss: 0.027346] [G loss: 0.965198]\n",
      "[Epoch 0/1] [Batch 2926/3551] [D loss: 0.030919] [G loss: 0.990756]\n",
      "[Epoch 0/1] [Batch 2927/3551] [D loss: 0.038229] [G loss: 0.983983]\n",
      "[Epoch 0/1] [Batch 2928/3551] [D loss: 0.020416] [G loss: 0.976243]\n",
      "[Epoch 0/1] [Batch 2929/3551] [D loss: 0.043561] [G loss: 0.976429]\n",
      "[Epoch 0/1] [Batch 2930/3551] [D loss: 0.023852] [G loss: 0.969941]\n",
      "[Epoch 0/1] [Batch 2931/3551] [D loss: 0.032609] [G loss: 0.974189]\n",
      "[Epoch 0/1] [Batch 2932/3551] [D loss: 0.024841] [G loss: 0.978743]\n",
      "[Epoch 0/1] [Batch 2933/3551] [D loss: 0.030246] [G loss: 0.980849]\n",
      "[Epoch 0/1] [Batch 2934/3551] [D loss: 0.020467] [G loss: 0.982786]\n",
      "[Epoch 0/1] [Batch 2935/3551] [D loss: 0.035996] [G loss: 0.972709]\n",
      "[Epoch 0/1] [Batch 2936/3551] [D loss: 0.036723] [G loss: 0.986459]\n",
      "[Epoch 0/1] [Batch 2937/3551] [D loss: 0.015167] [G loss: 0.982304]\n",
      "[Epoch 0/1] [Batch 2938/3551] [D loss: 0.028932] [G loss: 0.976348]\n",
      "[Epoch 0/1] [Batch 2939/3551] [D loss: 0.037820] [G loss: 0.983441]\n",
      "[Epoch 0/1] [Batch 2940/3551] [D loss: 0.014777] [G loss: 0.967293]\n",
      "[Epoch 0/1] [Batch 2941/3551] [D loss: 0.028421] [G loss: 0.968030]\n",
      "[Epoch 0/1] [Batch 2942/3551] [D loss: 0.039468] [G loss: 0.966358]\n",
      "[Epoch 0/1] [Batch 2943/3551] [D loss: 0.024289] [G loss: 0.983449]\n",
      "[Epoch 0/1] [Batch 2944/3551] [D loss: 0.018005] [G loss: 0.981515]\n",
      "[Epoch 0/1] [Batch 2945/3551] [D loss: 0.033776] [G loss: 0.967388]\n",
      "[Epoch 0/1] [Batch 2946/3551] [D loss: 0.021718] [G loss: 0.959472]\n",
      "[Epoch 0/1] [Batch 2947/3551] [D loss: 0.032008] [G loss: 0.987108]\n",
      "[Epoch 0/1] [Batch 2948/3551] [D loss: 0.043543] [G loss: 0.964482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 2949/3551] [D loss: 0.040586] [G loss: 0.980000]\n",
      "[Epoch 0/1] [Batch 2950/3551] [D loss: 0.021086] [G loss: 0.977498]\n",
      "[Epoch 0/1] [Batch 2951/3551] [D loss: 0.021715] [G loss: 0.974206]\n",
      "[Epoch 0/1] [Batch 2952/3551] [D loss: 0.024550] [G loss: 0.987580]\n",
      "[Epoch 0/1] [Batch 2953/3551] [D loss: 0.026728] [G loss: 0.986230]\n",
      "[Epoch 0/1] [Batch 2954/3551] [D loss: 0.044944] [G loss: 0.984256]\n",
      "[Epoch 0/1] [Batch 2955/3551] [D loss: 0.035422] [G loss: 0.979987]\n",
      "[Epoch 0/1] [Batch 2956/3551] [D loss: 0.025386] [G loss: 0.991277]\n",
      "[Epoch 0/1] [Batch 2957/3551] [D loss: 0.028321] [G loss: 0.988235]\n",
      "[Epoch 0/1] [Batch 2958/3551] [D loss: 0.024419] [G loss: 0.987185]\n",
      "[Epoch 0/1] [Batch 2959/3551] [D loss: 0.042761] [G loss: 0.992422]\n",
      "[Epoch 0/1] [Batch 2960/3551] [D loss: 0.026715] [G loss: 0.981426]\n",
      "[Epoch 0/1] [Batch 2961/3551] [D loss: 0.028618] [G loss: 0.988262]\n",
      "[Epoch 0/1] [Batch 2962/3551] [D loss: 0.022932] [G loss: 0.978487]\n",
      "[Epoch 0/1] [Batch 2963/3551] [D loss: 0.019620] [G loss: 0.980811]\n",
      "[Epoch 0/1] [Batch 2964/3551] [D loss: 0.044074] [G loss: 0.978242]\n",
      "[Epoch 0/1] [Batch 2965/3551] [D loss: 0.038303] [G loss: 0.992002]\n",
      "[Epoch 0/1] [Batch 2966/3551] [D loss: 0.023828] [G loss: 0.977416]\n",
      "[Epoch 0/1] [Batch 2967/3551] [D loss: 0.035967] [G loss: 0.981097]\n",
      "[Epoch 0/1] [Batch 2968/3551] [D loss: 0.020863] [G loss: 0.982650]\n",
      "[Epoch 0/1] [Batch 2969/3551] [D loss: 0.022751] [G loss: 0.976405]\n",
      "[Epoch 0/1] [Batch 2970/3551] [D loss: 0.029006] [G loss: 0.975898]\n",
      "[Epoch 0/1] [Batch 2971/3551] [D loss: 0.044049] [G loss: 0.984549]\n",
      "[Epoch 0/1] [Batch 2972/3551] [D loss: 0.026053] [G loss: 0.979499]\n",
      "[Epoch 0/1] [Batch 2973/3551] [D loss: 0.020256] [G loss: 0.982509]\n",
      "[Epoch 0/1] [Batch 2974/3551] [D loss: 0.032082] [G loss: 0.982714]\n",
      "[Epoch 0/1] [Batch 2975/3551] [D loss: 0.026859] [G loss: 0.992844]\n",
      "[Epoch 0/1] [Batch 2976/3551] [D loss: 0.026127] [G loss: 0.975036]\n",
      "[Epoch 0/1] [Batch 2977/3551] [D loss: 0.029384] [G loss: 0.970214]\n",
      "[Epoch 0/1] [Batch 2978/3551] [D loss: 0.028906] [G loss: 0.970555]\n",
      "[Epoch 0/1] [Batch 2979/3551] [D loss: 0.031275] [G loss: 0.985244]\n",
      "[Epoch 0/1] [Batch 2980/3551] [D loss: 0.022269] [G loss: 0.969252]\n",
      "[Epoch 0/1] [Batch 2981/3551] [D loss: 0.029001] [G loss: 0.972213]\n",
      "[Epoch 0/1] [Batch 2982/3551] [D loss: 0.035122] [G loss: 0.991354]\n",
      "[Epoch 0/1] [Batch 2983/3551] [D loss: 0.027585] [G loss: 0.976750]\n",
      "[Epoch 0/1] [Batch 2984/3551] [D loss: 0.014834] [G loss: 0.983886]\n",
      "[Epoch 0/1] [Batch 2985/3551] [D loss: 0.041700] [G loss: 0.980661]\n",
      "[Epoch 0/1] [Batch 2986/3551] [D loss: 0.032273] [G loss: 0.979941]\n",
      "[Epoch 0/1] [Batch 2987/3551] [D loss: 0.022284] [G loss: 0.980154]\n",
      "[Epoch 0/1] [Batch 2988/3551] [D loss: 0.026974] [G loss: 0.999612]\n",
      "[Epoch 0/1] [Batch 2989/3551] [D loss: 0.025961] [G loss: 0.980592]\n",
      "[Epoch 0/1] [Batch 2990/3551] [D loss: 0.027235] [G loss: 0.968405]\n",
      "[Epoch 0/1] [Batch 2991/3551] [D loss: 0.035109] [G loss: 0.980370]\n",
      "[Epoch 0/1] [Batch 2992/3551] [D loss: 0.032154] [G loss: 0.975494]\n",
      "[Epoch 0/1] [Batch 2993/3551] [D loss: 0.028891] [G loss: 0.989651]\n",
      "[Epoch 0/1] [Batch 2994/3551] [D loss: 0.048490] [G loss: 0.975237]\n",
      "[Epoch 0/1] [Batch 2995/3551] [D loss: 0.030858] [G loss: 0.982912]\n",
      "[Epoch 0/1] [Batch 2996/3551] [D loss: 0.025767] [G loss: 0.980347]\n",
      "[Epoch 0/1] [Batch 2997/3551] [D loss: 0.022650] [G loss: 0.979393]\n",
      "[Epoch 0/1] [Batch 2998/3551] [D loss: 0.042515] [G loss: 0.967829]\n",
      "[Epoch 0/1] [Batch 2999/3551] [D loss: 0.034043] [G loss: 0.978288]\n",
      "[Epoch 0/1] [Batch 3000/3551] [D loss: 0.024590] [G loss: 0.974838]\n",
      "[Epoch 0/1] [Batch 3001/3551] [D loss: 0.028959] [G loss: 0.976414]\n",
      "[Epoch 0/1] [Batch 3002/3551] [D loss: 0.028010] [G loss: 0.973991]\n",
      "[Epoch 0/1] [Batch 3003/3551] [D loss: 0.046107] [G loss: 0.967201]\n",
      "[Epoch 0/1] [Batch 3004/3551] [D loss: 0.018961] [G loss: 0.971525]\n",
      "[Epoch 0/1] [Batch 3005/3551] [D loss: 0.023767] [G loss: 0.987934]\n",
      "[Epoch 0/1] [Batch 3006/3551] [D loss: 0.032965] [G loss: 0.981181]\n",
      "[Epoch 0/1] [Batch 3007/3551] [D loss: 0.028538] [G loss: 0.976361]\n",
      "[Epoch 0/1] [Batch 3008/3551] [D loss: 0.022961] [G loss: 0.987044]\n",
      "[Epoch 0/1] [Batch 3009/3551] [D loss: 0.024891] [G loss: 0.975587]\n",
      "[Epoch 0/1] [Batch 3010/3551] [D loss: 0.024064] [G loss: 0.972456]\n",
      "[Epoch 0/1] [Batch 3011/3551] [D loss: 0.029114] [G loss: 0.974363]\n",
      "[Epoch 0/1] [Batch 3012/3551] [D loss: 0.024785] [G loss: 0.981184]\n",
      "[Epoch 0/1] [Batch 3013/3551] [D loss: 0.038155] [G loss: 0.983588]\n",
      "[Epoch 0/1] [Batch 3014/3551] [D loss: 0.057525] [G loss: 0.980812]\n",
      "[Epoch 0/1] [Batch 3015/3551] [D loss: 0.031383] [G loss: 0.976940]\n",
      "[Epoch 0/1] [Batch 3016/3551] [D loss: 0.032894] [G loss: 0.973062]\n",
      "[Epoch 0/1] [Batch 3017/3551] [D loss: 0.020683] [G loss: 0.970113]\n",
      "[Epoch 0/1] [Batch 3018/3551] [D loss: 0.040329] [G loss: 0.970646]\n",
      "[Epoch 0/1] [Batch 3019/3551] [D loss: 0.027462] [G loss: 0.990066]\n",
      "[Epoch 0/1] [Batch 3020/3551] [D loss: 0.021543] [G loss: 0.970883]\n",
      "[Epoch 0/1] [Batch 3021/3551] [D loss: 0.023269] [G loss: 0.968770]\n",
      "[Epoch 0/1] [Batch 3022/3551] [D loss: 0.042971] [G loss: 0.985836]\n",
      "[Epoch 0/1] [Batch 3023/3551] [D loss: 0.042834] [G loss: 0.983759]\n",
      "[Epoch 0/1] [Batch 3024/3551] [D loss: 0.039161] [G loss: 0.980946]\n",
      "[Epoch 0/1] [Batch 3025/3551] [D loss: 0.029364] [G loss: 0.974119]\n",
      "[Epoch 0/1] [Batch 3026/3551] [D loss: 0.026280] [G loss: 0.969583]\n",
      "[Epoch 0/1] [Batch 3027/3551] [D loss: 0.029204] [G loss: 0.980046]\n",
      "[Epoch 0/1] [Batch 3028/3551] [D loss: 0.035031] [G loss: 0.975618]\n",
      "[Epoch 0/1] [Batch 3029/3551] [D loss: 0.033678] [G loss: 0.995123]\n",
      "[Epoch 0/1] [Batch 3030/3551] [D loss: 0.021907] [G loss: 0.976393]\n",
      "[Epoch 0/1] [Batch 3031/3551] [D loss: 0.020850] [G loss: 0.993880]\n",
      "[Epoch 0/1] [Batch 3032/3551] [D loss: 0.035124] [G loss: 0.986099]\n",
      "[Epoch 0/1] [Batch 3033/3551] [D loss: 0.025098] [G loss: 0.979641]\n",
      "[Epoch 0/1] [Batch 3034/3551] [D loss: 0.025683] [G loss: 0.976601]\n",
      "[Epoch 0/1] [Batch 3035/3551] [D loss: 0.031636] [G loss: 0.979509]\n",
      "[Epoch 0/1] [Batch 3036/3551] [D loss: 0.026996] [G loss: 0.979451]\n",
      "[Epoch 0/1] [Batch 3037/3551] [D loss: 0.038999] [G loss: 0.978581]\n",
      "[Epoch 0/1] [Batch 3038/3551] [D loss: 0.042716] [G loss: 0.975435]\n",
      "[Epoch 0/1] [Batch 3039/3551] [D loss: 0.027646] [G loss: 0.973990]\n",
      "[Epoch 0/1] [Batch 3040/3551] [D loss: 0.031460] [G loss: 0.983214]\n",
      "[Epoch 0/1] [Batch 3041/3551] [D loss: 0.032042] [G loss: 0.972301]\n",
      "[Epoch 0/1] [Batch 3042/3551] [D loss: 0.029312] [G loss: 0.973044]\n",
      "[Epoch 0/1] [Batch 3043/3551] [D loss: 0.028755] [G loss: 0.987888]\n",
      "[Epoch 0/1] [Batch 3044/3551] [D loss: 0.028088] [G loss: 0.971156]\n",
      "[Epoch 0/1] [Batch 3045/3551] [D loss: 0.036731] [G loss: 0.976178]\n",
      "[Epoch 0/1] [Batch 3046/3551] [D loss: 0.036280] [G loss: 0.971346]\n",
      "[Epoch 0/1] [Batch 3047/3551] [D loss: 0.032623] [G loss: 0.985919]\n",
      "[Epoch 0/1] [Batch 3048/3551] [D loss: 0.031736] [G loss: 0.973892]\n",
      "[Epoch 0/1] [Batch 3049/3551] [D loss: 0.035195] [G loss: 0.970165]\n",
      "[Epoch 0/1] [Batch 3050/3551] [D loss: 0.027406] [G loss: 0.972775]\n",
      "[Epoch 0/1] [Batch 3051/3551] [D loss: 0.022502] [G loss: 0.983644]\n",
      "[Epoch 0/1] [Batch 3052/3551] [D loss: 0.023722] [G loss: 0.972931]\n",
      "[Epoch 0/1] [Batch 3053/3551] [D loss: 0.022065] [G loss: 0.964838]\n",
      "[Epoch 0/1] [Batch 3054/3551] [D loss: 0.031807] [G loss: 0.972874]\n",
      "[Epoch 0/1] [Batch 3055/3551] [D loss: 0.028023] [G loss: 0.965873]\n",
      "[Epoch 0/1] [Batch 3056/3551] [D loss: 0.028275] [G loss: 0.980576]\n",
      "[Epoch 0/1] [Batch 3057/3551] [D loss: 0.050914] [G loss: 0.974169]\n",
      "[Epoch 0/1] [Batch 3058/3551] [D loss: 0.017585] [G loss: 0.973977]\n",
      "[Epoch 0/1] [Batch 3059/3551] [D loss: 0.029011] [G loss: 0.985511]\n",
      "[Epoch 0/1] [Batch 3060/3551] [D loss: 0.020366] [G loss: 0.968945]\n",
      "[Epoch 0/1] [Batch 3061/3551] [D loss: 0.036271] [G loss: 0.992253]\n",
      "[Epoch 0/1] [Batch 3062/3551] [D loss: 0.028579] [G loss: 0.971608]\n",
      "[Epoch 0/1] [Batch 3063/3551] [D loss: 0.025051] [G loss: 0.991358]\n",
      "[Epoch 0/1] [Batch 3064/3551] [D loss: 0.016496] [G loss: 0.975151]\n",
      "[Epoch 0/1] [Batch 3065/3551] [D loss: 0.020999] [G loss: 0.989950]\n",
      "[Epoch 0/1] [Batch 3066/3551] [D loss: 0.034545] [G loss: 0.971415]\n",
      "[Epoch 0/1] [Batch 3067/3551] [D loss: 0.024414] [G loss: 0.980276]\n",
      "[Epoch 0/1] [Batch 3068/3551] [D loss: 0.029424] [G loss: 0.981157]\n",
      "[Epoch 0/1] [Batch 3069/3551] [D loss: 0.025717] [G loss: 0.975273]\n",
      "[Epoch 0/1] [Batch 3070/3551] [D loss: 0.033550] [G loss: 0.985237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 3071/3551] [D loss: 0.028683] [G loss: 0.984249]\n",
      "[Epoch 0/1] [Batch 3072/3551] [D loss: 0.020165] [G loss: 0.980717]\n",
      "[Epoch 0/1] [Batch 3073/3551] [D loss: 0.045409] [G loss: 0.981708]\n",
      "[Epoch 0/1] [Batch 3074/3551] [D loss: 0.017595] [G loss: 0.981155]\n",
      "[Epoch 0/1] [Batch 3075/3551] [D loss: 0.025312] [G loss: 0.971439]\n",
      "[Epoch 0/1] [Batch 3076/3551] [D loss: 0.021952] [G loss: 0.988407]\n",
      "[Epoch 0/1] [Batch 3077/3551] [D loss: 0.030359] [G loss: 0.978659]\n",
      "[Epoch 0/1] [Batch 3078/3551] [D loss: 0.022185] [G loss: 0.969867]\n",
      "[Epoch 0/1] [Batch 3079/3551] [D loss: 0.021209] [G loss: 0.973828]\n",
      "[Epoch 0/1] [Batch 3080/3551] [D loss: 0.017061] [G loss: 0.975739]\n",
      "[Epoch 0/1] [Batch 3081/3551] [D loss: 0.047492] [G loss: 0.975054]\n",
      "[Epoch 0/1] [Batch 3082/3551] [D loss: 0.033609] [G loss: 0.985183]\n",
      "[Epoch 0/1] [Batch 3083/3551] [D loss: 0.046929] [G loss: 0.979153]\n",
      "[Epoch 0/1] [Batch 3084/3551] [D loss: 0.025076] [G loss: 0.979494]\n",
      "[Epoch 0/1] [Batch 3085/3551] [D loss: 0.021093] [G loss: 0.979175]\n",
      "[Epoch 0/1] [Batch 3086/3551] [D loss: 0.029815] [G loss: 0.991463]\n",
      "[Epoch 0/1] [Batch 3087/3551] [D loss: 0.024769] [G loss: 0.989015]\n",
      "[Epoch 0/1] [Batch 3088/3551] [D loss: 0.029080] [G loss: 0.970668]\n",
      "[Epoch 0/1] [Batch 3089/3551] [D loss: 0.042463] [G loss: 0.982196]\n",
      "[Epoch 0/1] [Batch 3090/3551] [D loss: 0.024253] [G loss: 0.984232]\n",
      "[Epoch 0/1] [Batch 3091/3551] [D loss: 0.037928] [G loss: 0.975617]\n",
      "[Epoch 0/1] [Batch 3092/3551] [D loss: 0.043047] [G loss: 0.979864]\n",
      "[Epoch 0/1] [Batch 3093/3551] [D loss: 0.029941] [G loss: 0.971913]\n",
      "[Epoch 0/1] [Batch 3094/3551] [D loss: 0.028170] [G loss: 0.982688]\n",
      "[Epoch 0/1] [Batch 3095/3551] [D loss: 0.038493] [G loss: 0.979975]\n",
      "[Epoch 0/1] [Batch 3096/3551] [D loss: 0.030468] [G loss: 0.979392]\n",
      "[Epoch 0/1] [Batch 3097/3551] [D loss: 0.028855] [G loss: 0.970065]\n",
      "[Epoch 0/1] [Batch 3098/3551] [D loss: 0.028228] [G loss: 0.973069]\n",
      "[Epoch 0/1] [Batch 3099/3551] [D loss: 0.021581] [G loss: 0.982946]\n",
      "[Epoch 0/1] [Batch 3100/3551] [D loss: 0.022288] [G loss: 0.991258]\n",
      "[Epoch 0/1] [Batch 3101/3551] [D loss: 0.043886] [G loss: 0.985174]\n",
      "[Epoch 0/1] [Batch 3102/3551] [D loss: 0.039540] [G loss: 0.977340]\n",
      "[Epoch 0/1] [Batch 3103/3551] [D loss: 0.022073] [G loss: 0.970886]\n",
      "[Epoch 0/1] [Batch 3104/3551] [D loss: 0.039596] [G loss: 0.986301]\n",
      "[Epoch 0/1] [Batch 3105/3551] [D loss: 0.026461] [G loss: 0.987304]\n",
      "[Epoch 0/1] [Batch 3106/3551] [D loss: 0.030692] [G loss: 0.981845]\n",
      "[Epoch 0/1] [Batch 3107/3551] [D loss: 0.019800] [G loss: 0.980065]\n",
      "[Epoch 0/1] [Batch 3108/3551] [D loss: 0.041412] [G loss: 0.977257]\n",
      "[Epoch 0/1] [Batch 3109/3551] [D loss: 0.036090] [G loss: 0.989160]\n",
      "[Epoch 0/1] [Batch 3110/3551] [D loss: 0.032185] [G loss: 0.969996]\n",
      "[Epoch 0/1] [Batch 3111/3551] [D loss: 0.022424] [G loss: 0.961190]\n",
      "[Epoch 0/1] [Batch 3112/3551] [D loss: 0.019532] [G loss: 0.970976]\n",
      "[Epoch 0/1] [Batch 3113/3551] [D loss: 0.022243] [G loss: 0.978578]\n",
      "[Epoch 0/1] [Batch 3114/3551] [D loss: 0.024417] [G loss: 0.978014]\n",
      "[Epoch 0/1] [Batch 3115/3551] [D loss: 0.045933] [G loss: 0.972904]\n",
      "[Epoch 0/1] [Batch 3116/3551] [D loss: 0.013796] [G loss: 0.973940]\n",
      "[Epoch 0/1] [Batch 3117/3551] [D loss: 0.030564] [G loss: 0.976521]\n",
      "[Epoch 0/1] [Batch 3118/3551] [D loss: 0.018848] [G loss: 0.963229]\n",
      "[Epoch 0/1] [Batch 3119/3551] [D loss: 0.036348] [G loss: 0.981378]\n",
      "[Epoch 0/1] [Batch 3120/3551] [D loss: 0.024402] [G loss: 0.974357]\n",
      "[Epoch 0/1] [Batch 3121/3551] [D loss: 0.023796] [G loss: 0.971388]\n",
      "[Epoch 0/1] [Batch 3122/3551] [D loss: 0.031001] [G loss: 0.981418]\n",
      "[Epoch 0/1] [Batch 3123/3551] [D loss: 0.028610] [G loss: 0.982377]\n",
      "[Epoch 0/1] [Batch 3124/3551] [D loss: 0.036535] [G loss: 0.971406]\n",
      "[Epoch 0/1] [Batch 3125/3551] [D loss: 0.024762] [G loss: 0.971493]\n",
      "[Epoch 0/1] [Batch 3126/3551] [D loss: 0.022827] [G loss: 0.975208]\n",
      "[Epoch 0/1] [Batch 3127/3551] [D loss: 0.028153] [G loss: 0.978703]\n",
      "[Epoch 0/1] [Batch 3128/3551] [D loss: 0.029582] [G loss: 0.984582]\n",
      "[Epoch 0/1] [Batch 3129/3551] [D loss: 0.024201] [G loss: 0.966817]\n",
      "[Epoch 0/1] [Batch 3130/3551] [D loss: 0.040774] [G loss: 0.988774]\n",
      "[Epoch 0/1] [Batch 3131/3551] [D loss: 0.022839] [G loss: 0.970545]\n",
      "[Epoch 0/1] [Batch 3132/3551] [D loss: 0.047975] [G loss: 0.980941]\n",
      "[Epoch 0/1] [Batch 3133/3551] [D loss: 0.047553] [G loss: 0.975955]\n",
      "[Epoch 0/1] [Batch 3134/3551] [D loss: 0.016557] [G loss: 0.976070]\n",
      "[Epoch 0/1] [Batch 3135/3551] [D loss: 0.021191] [G loss: 0.979262]\n",
      "[Epoch 0/1] [Batch 3136/3551] [D loss: 0.025824] [G loss: 0.973027]\n",
      "[Epoch 0/1] [Batch 3137/3551] [D loss: 0.042488] [G loss: 0.969730]\n",
      "[Epoch 0/1] [Batch 3138/3551] [D loss: 0.030271] [G loss: 0.984694]\n",
      "[Epoch 0/1] [Batch 3139/3551] [D loss: 0.016846] [G loss: 0.973437]\n",
      "[Epoch 0/1] [Batch 3140/3551] [D loss: 0.031696] [G loss: 0.987418]\n",
      "[Epoch 0/1] [Batch 3141/3551] [D loss: 0.031939] [G loss: 0.973095]\n",
      "[Epoch 0/1] [Batch 3142/3551] [D loss: 0.022837] [G loss: 0.979618]\n",
      "[Epoch 0/1] [Batch 3143/3551] [D loss: 0.031713] [G loss: 0.978563]\n",
      "[Epoch 0/1] [Batch 3144/3551] [D loss: 0.026053] [G loss: 0.988851]\n",
      "[Epoch 0/1] [Batch 3145/3551] [D loss: 0.023782] [G loss: 0.978198]\n",
      "[Epoch 0/1] [Batch 3146/3551] [D loss: 0.032022] [G loss: 0.979172]\n",
      "[Epoch 0/1] [Batch 3147/3551] [D loss: 0.033227] [G loss: 0.968450]\n",
      "[Epoch 0/1] [Batch 3148/3551] [D loss: 0.027621] [G loss: 0.983153]\n",
      "[Epoch 0/1] [Batch 3149/3551] [D loss: 0.040197] [G loss: 0.975714]\n",
      "[Epoch 0/1] [Batch 3150/3551] [D loss: 0.027651] [G loss: 0.985695]\n",
      "[Epoch 0/1] [Batch 3151/3551] [D loss: 0.025377] [G loss: 0.965905]\n",
      "[Epoch 0/1] [Batch 3152/3551] [D loss: 0.051371] [G loss: 0.967541]\n",
      "[Epoch 0/1] [Batch 3153/3551] [D loss: 0.024112] [G loss: 0.979963]\n",
      "[Epoch 0/1] [Batch 3154/3551] [D loss: 0.026259] [G loss: 0.979169]\n",
      "[Epoch 0/1] [Batch 3155/3551] [D loss: 0.025878] [G loss: 0.994800]\n",
      "[Epoch 0/1] [Batch 3156/3551] [D loss: 0.031761] [G loss: 0.980815]\n",
      "[Epoch 0/1] [Batch 3157/3551] [D loss: 0.029825] [G loss: 0.980565]\n",
      "[Epoch 0/1] [Batch 3158/3551] [D loss: 0.034239] [G loss: 0.977285]\n",
      "[Epoch 0/1] [Batch 3159/3551] [D loss: 0.033672] [G loss: 0.966770]\n",
      "[Epoch 0/1] [Batch 3160/3551] [D loss: 0.023989] [G loss: 0.984797]\n",
      "[Epoch 0/1] [Batch 3161/3551] [D loss: 0.031928] [G loss: 0.972777]\n",
      "[Epoch 0/1] [Batch 3162/3551] [D loss: 0.026283] [G loss: 0.988164]\n",
      "[Epoch 0/1] [Batch 3163/3551] [D loss: 0.040482] [G loss: 0.984721]\n",
      "[Epoch 0/1] [Batch 3164/3551] [D loss: 0.018645] [G loss: 0.986170]\n",
      "[Epoch 0/1] [Batch 3165/3551] [D loss: 0.023340] [G loss: 0.977829]\n",
      "[Epoch 0/1] [Batch 3166/3551] [D loss: 0.035530] [G loss: 0.983606]\n",
      "[Epoch 0/1] [Batch 3167/3551] [D loss: 0.019611] [G loss: 0.975606]\n",
      "[Epoch 0/1] [Batch 3168/3551] [D loss: 0.031420] [G loss: 0.971654]\n",
      "[Epoch 0/1] [Batch 3169/3551] [D loss: 0.040149] [G loss: 0.975517]\n",
      "[Epoch 0/1] [Batch 3170/3551] [D loss: 0.031446] [G loss: 0.986822]\n",
      "[Epoch 0/1] [Batch 3171/3551] [D loss: 0.015656] [G loss: 0.973688]\n",
      "[Epoch 0/1] [Batch 3172/3551] [D loss: 0.032232] [G loss: 0.979696]\n",
      "[Epoch 0/1] [Batch 3173/3551] [D loss: 0.023810] [G loss: 0.971705]\n",
      "[Epoch 0/1] [Batch 3174/3551] [D loss: 0.038156] [G loss: 0.978836]\n",
      "[Epoch 0/1] [Batch 3175/3551] [D loss: 0.027543] [G loss: 0.979173]\n",
      "[Epoch 0/1] [Batch 3176/3551] [D loss: 0.024555] [G loss: 0.971358]\n",
      "[Epoch 0/1] [Batch 3177/3551] [D loss: 0.025556] [G loss: 0.972074]\n",
      "[Epoch 0/1] [Batch 3178/3551] [D loss: 0.038452] [G loss: 0.968892]\n",
      "[Epoch 0/1] [Batch 3179/3551] [D loss: 0.014497] [G loss: 0.971536]\n",
      "[Epoch 0/1] [Batch 3180/3551] [D loss: 0.031992] [G loss: 0.978318]\n",
      "[Epoch 0/1] [Batch 3181/3551] [D loss: 0.018530] [G loss: 0.979476]\n",
      "[Epoch 0/1] [Batch 3182/3551] [D loss: 0.021774] [G loss: 0.982946]\n",
      "[Epoch 0/1] [Batch 3183/3551] [D loss: 0.024256] [G loss: 0.986343]\n",
      "[Epoch 0/1] [Batch 3184/3551] [D loss: 0.038370] [G loss: 0.981750]\n",
      "[Epoch 0/1] [Batch 3185/3551] [D loss: 0.018671] [G loss: 0.973649]\n",
      "[Epoch 0/1] [Batch 3186/3551] [D loss: 0.043170] [G loss: 0.980203]\n",
      "[Epoch 0/1] [Batch 3187/3551] [D loss: 0.027526] [G loss: 0.984570]\n",
      "[Epoch 0/1] [Batch 3188/3551] [D loss: 0.021803] [G loss: 0.983512]\n",
      "[Epoch 0/1] [Batch 3189/3551] [D loss: 0.023994] [G loss: 0.976436]\n",
      "[Epoch 0/1] [Batch 3190/3551] [D loss: 0.045164] [G loss: 0.978003]\n",
      "[Epoch 0/1] [Batch 3191/3551] [D loss: 0.028319] [G loss: 0.964710]\n",
      "[Epoch 0/1] [Batch 3192/3551] [D loss: 0.023001] [G loss: 0.980293]\n",
      "[Epoch 0/1] [Batch 3193/3551] [D loss: 0.027912] [G loss: 0.979044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 3194/3551] [D loss: 0.025153] [G loss: 0.985474]\n",
      "[Epoch 0/1] [Batch 3195/3551] [D loss: 0.019424] [G loss: 0.983867]\n",
      "[Epoch 0/1] [Batch 3196/3551] [D loss: 0.027259] [G loss: 0.976348]\n",
      "[Epoch 0/1] [Batch 3197/3551] [D loss: 0.018895] [G loss: 0.969808]\n",
      "[Epoch 0/1] [Batch 3198/3551] [D loss: 0.032107] [G loss: 0.972738]\n",
      "[Epoch 0/1] [Batch 3199/3551] [D loss: 0.024631] [G loss: 0.978126]\n",
      "[Epoch 0/1] [Batch 3200/3551] [D loss: 0.034788] [G loss: 0.974909]\n",
      "[Epoch 0/1] [Batch 3201/3551] [D loss: 0.020263] [G loss: 0.983109]\n",
      "[Epoch 0/1] [Batch 3202/3551] [D loss: 0.023654] [G loss: 0.982890]\n",
      "[Epoch 0/1] [Batch 3203/3551] [D loss: 0.017787] [G loss: 0.971471]\n",
      "[Epoch 0/1] [Batch 3204/3551] [D loss: 0.054601] [G loss: 0.978126]\n",
      "[Epoch 0/1] [Batch 3205/3551] [D loss: 0.018887] [G loss: 0.980836]\n",
      "[Epoch 0/1] [Batch 3206/3551] [D loss: 0.025993] [G loss: 0.984224]\n",
      "[Epoch 0/1] [Batch 3207/3551] [D loss: 0.010194] [G loss: 0.987515]\n",
      "[Epoch 0/1] [Batch 3208/3551] [D loss: 0.027338] [G loss: 0.976963]\n",
      "[Epoch 0/1] [Batch 3209/3551] [D loss: 0.047887] [G loss: 0.987429]\n",
      "[Epoch 0/1] [Batch 3210/3551] [D loss: 0.026880] [G loss: 0.986869]\n",
      "[Epoch 0/1] [Batch 3211/3551] [D loss: 0.029842] [G loss: 0.968053]\n",
      "[Epoch 0/1] [Batch 3212/3551] [D loss: 0.023033] [G loss: 0.977907]\n",
      "[Epoch 0/1] [Batch 3213/3551] [D loss: 0.025227] [G loss: 0.992324]\n",
      "[Epoch 0/1] [Batch 3214/3551] [D loss: 0.022785] [G loss: 0.988334]\n",
      "[Epoch 0/1] [Batch 3215/3551] [D loss: 0.026810] [G loss: 0.979164]\n",
      "[Epoch 0/1] [Batch 3216/3551] [D loss: 0.016463] [G loss: 0.978881]\n",
      "[Epoch 0/1] [Batch 3217/3551] [D loss: 0.025903] [G loss: 0.976289]\n",
      "[Epoch 0/1] [Batch 3218/3551] [D loss: 0.031823] [G loss: 0.983035]\n",
      "[Epoch 0/1] [Batch 3219/3551] [D loss: 0.025831] [G loss: 0.990135]\n",
      "[Epoch 0/1] [Batch 3220/3551] [D loss: 0.018959] [G loss: 0.988713]\n",
      "[Epoch 0/1] [Batch 3221/3551] [D loss: 0.026447] [G loss: 0.979268]\n",
      "[Epoch 0/1] [Batch 3222/3551] [D loss: 0.024734] [G loss: 0.987500]\n",
      "[Epoch 0/1] [Batch 3223/3551] [D loss: 0.023323] [G loss: 0.984678]\n",
      "[Epoch 0/1] [Batch 3224/3551] [D loss: 0.025022] [G loss: 0.986056]\n",
      "[Epoch 0/1] [Batch 3225/3551] [D loss: 0.021441] [G loss: 0.987444]\n",
      "[Epoch 0/1] [Batch 3226/3551] [D loss: 0.025455] [G loss: 0.987513]\n",
      "[Epoch 0/1] [Batch 3227/3551] [D loss: 0.026345] [G loss: 0.983064]\n",
      "[Epoch 0/1] [Batch 3228/3551] [D loss: 0.033557] [G loss: 0.975138]\n",
      "[Epoch 0/1] [Batch 3229/3551] [D loss: 0.023567] [G loss: 0.986936]\n",
      "[Epoch 0/1] [Batch 3230/3551] [D loss: 0.015277] [G loss: 0.987572]\n",
      "[Epoch 0/1] [Batch 3231/3551] [D loss: 0.022518] [G loss: 0.973458]\n",
      "[Epoch 0/1] [Batch 3232/3551] [D loss: 0.027160] [G loss: 0.986535]\n",
      "[Epoch 0/1] [Batch 3233/3551] [D loss: 0.058177] [G loss: 0.978548]\n",
      "[Epoch 0/1] [Batch 3234/3551] [D loss: 0.026658] [G loss: 0.957578]\n",
      "[Epoch 0/1] [Batch 3235/3551] [D loss: 0.021263] [G loss: 0.973835]\n",
      "[Epoch 0/1] [Batch 3236/3551] [D loss: 0.026481] [G loss: 0.975613]\n",
      "[Epoch 0/1] [Batch 3237/3551] [D loss: 0.026350] [G loss: 0.970511]\n",
      "[Epoch 0/1] [Batch 3238/3551] [D loss: 0.026185] [G loss: 0.985593]\n",
      "[Epoch 0/1] [Batch 3239/3551] [D loss: 0.014899] [G loss: 0.974785]\n",
      "[Epoch 0/1] [Batch 3240/3551] [D loss: 0.036404] [G loss: 0.979931]\n",
      "[Epoch 0/1] [Batch 3241/3551] [D loss: 0.018469] [G loss: 0.970179]\n",
      "[Epoch 0/1] [Batch 3242/3551] [D loss: 0.028794] [G loss: 0.976524]\n",
      "[Epoch 0/1] [Batch 3243/3551] [D loss: 0.033249] [G loss: 0.974069]\n",
      "[Epoch 0/1] [Batch 3244/3551] [D loss: 0.027718] [G loss: 0.985015]\n",
      "[Epoch 0/1] [Batch 3245/3551] [D loss: 0.024022] [G loss: 0.976749]\n",
      "[Epoch 0/1] [Batch 3246/3551] [D loss: 0.022309] [G loss: 0.977434]\n",
      "[Epoch 0/1] [Batch 3247/3551] [D loss: 0.014456] [G loss: 0.982408]\n",
      "[Epoch 0/1] [Batch 3248/3551] [D loss: 0.039335] [G loss: 0.973283]\n",
      "[Epoch 0/1] [Batch 3249/3551] [D loss: 0.031226] [G loss: 0.987361]\n",
      "[Epoch 0/1] [Batch 3250/3551] [D loss: 0.035451] [G loss: 0.976858]\n",
      "[Epoch 0/1] [Batch 3251/3551] [D loss: 0.026708] [G loss: 0.976225]\n",
      "[Epoch 0/1] [Batch 3252/3551] [D loss: 0.021697] [G loss: 0.980162]\n",
      "[Epoch 0/1] [Batch 3253/3551] [D loss: 0.027657] [G loss: 0.976967]\n",
      "[Epoch 0/1] [Batch 3254/3551] [D loss: 0.025482] [G loss: 0.981799]\n",
      "[Epoch 0/1] [Batch 3255/3551] [D loss: 0.030406] [G loss: 0.968642]\n",
      "[Epoch 0/1] [Batch 3256/3551] [D loss: 0.019623] [G loss: 0.975624]\n",
      "[Epoch 0/1] [Batch 3257/3551] [D loss: 0.014665] [G loss: 0.992458]\n",
      "[Epoch 0/1] [Batch 3258/3551] [D loss: 0.019084] [G loss: 0.990737]\n",
      "[Epoch 0/1] [Batch 3259/3551] [D loss: 0.020882] [G loss: 0.969172]\n",
      "[Epoch 0/1] [Batch 3260/3551] [D loss: 0.025663] [G loss: 0.988302]\n",
      "[Epoch 0/1] [Batch 3261/3551] [D loss: 0.023327] [G loss: 0.977298]\n",
      "[Epoch 0/1] [Batch 3262/3551] [D loss: 0.025569] [G loss: 0.981497]\n",
      "[Epoch 0/1] [Batch 3263/3551] [D loss: 0.022041] [G loss: 0.974626]\n",
      "[Epoch 0/1] [Batch 3264/3551] [D loss: 0.030048] [G loss: 0.983459]\n",
      "[Epoch 0/1] [Batch 3265/3551] [D loss: 0.030530] [G loss: 0.980892]\n",
      "[Epoch 0/1] [Batch 3266/3551] [D loss: 0.031494] [G loss: 0.975654]\n",
      "[Epoch 0/1] [Batch 3267/3551] [D loss: 0.022523] [G loss: 0.971416]\n",
      "[Epoch 0/1] [Batch 3268/3551] [D loss: 0.029463] [G loss: 0.983425]\n",
      "[Epoch 0/1] [Batch 3269/3551] [D loss: 0.023807] [G loss: 0.985956]\n",
      "[Epoch 0/1] [Batch 3270/3551] [D loss: 0.022188] [G loss: 0.980851]\n",
      "[Epoch 0/1] [Batch 3271/3551] [D loss: 0.009037] [G loss: 0.973847]\n",
      "[Epoch 0/1] [Batch 3272/3551] [D loss: 0.032300] [G loss: 0.974134]\n",
      "[Epoch 0/1] [Batch 3273/3551] [D loss: 0.028361] [G loss: 0.976356]\n",
      "[Epoch 0/1] [Batch 3274/3551] [D loss: 0.026654] [G loss: 0.977613]\n",
      "[Epoch 0/1] [Batch 3275/3551] [D loss: 0.027295] [G loss: 0.976888]\n",
      "[Epoch 0/1] [Batch 3276/3551] [D loss: 0.017245] [G loss: 0.972755]\n",
      "[Epoch 0/1] [Batch 3277/3551] [D loss: 0.017377] [G loss: 0.987436]\n",
      "[Epoch 0/1] [Batch 3278/3551] [D loss: 0.029273] [G loss: 0.976863]\n",
      "[Epoch 0/1] [Batch 3279/3551] [D loss: 0.027999] [G loss: 0.990916]\n",
      "[Epoch 0/1] [Batch 3280/3551] [D loss: 0.020512] [G loss: 0.988725]\n",
      "[Epoch 0/1] [Batch 3281/3551] [D loss: 0.020664] [G loss: 0.987127]\n",
      "[Epoch 0/1] [Batch 3282/3551] [D loss: 0.031616] [G loss: 0.981244]\n",
      "[Epoch 0/1] [Batch 3283/3551] [D loss: 0.024687] [G loss: 0.974343]\n",
      "[Epoch 0/1] [Batch 3284/3551] [D loss: 0.016655] [G loss: 0.978034]\n",
      "[Epoch 0/1] [Batch 3285/3551] [D loss: 0.020229] [G loss: 0.984734]\n",
      "[Epoch 0/1] [Batch 3286/3551] [D loss: 0.039574] [G loss: 0.975029]\n",
      "[Epoch 0/1] [Batch 3287/3551] [D loss: 0.015312] [G loss: 0.975099]\n",
      "[Epoch 0/1] [Batch 3288/3551] [D loss: 0.019650] [G loss: 0.985582]\n",
      "[Epoch 0/1] [Batch 3289/3551] [D loss: 0.031638] [G loss: 0.975922]\n",
      "[Epoch 0/1] [Batch 3290/3551] [D loss: 0.021244] [G loss: 0.987149]\n",
      "[Epoch 0/1] [Batch 3291/3551] [D loss: 0.016546] [G loss: 0.974294]\n",
      "[Epoch 0/1] [Batch 3292/3551] [D loss: 0.027098] [G loss: 0.982594]\n",
      "[Epoch 0/1] [Batch 3293/3551] [D loss: 0.027533] [G loss: 0.987002]\n",
      "[Epoch 0/1] [Batch 3294/3551] [D loss: 0.029349] [G loss: 0.982728]\n",
      "[Epoch 0/1] [Batch 3295/3551] [D loss: 0.029166] [G loss: 0.975389]\n",
      "[Epoch 0/1] [Batch 3296/3551] [D loss: 0.022536] [G loss: 0.973421]\n",
      "[Epoch 0/1] [Batch 3297/3551] [D loss: 0.034995] [G loss: 0.983581]\n",
      "[Epoch 0/1] [Batch 3298/3551] [D loss: 0.021001] [G loss: 0.982632]\n",
      "[Epoch 0/1] [Batch 3299/3551] [D loss: 0.027258] [G loss: 0.971939]\n",
      "[Epoch 0/1] [Batch 3300/3551] [D loss: 0.020463] [G loss: 0.978613]\n",
      "[Epoch 0/1] [Batch 3301/3551] [D loss: 0.034500] [G loss: 0.963152]\n",
      "[Epoch 0/1] [Batch 3302/3551] [D loss: 0.024690] [G loss: 0.987885]\n",
      "[Epoch 0/1] [Batch 3303/3551] [D loss: 0.033948] [G loss: 0.976721]\n",
      "[Epoch 0/1] [Batch 3304/3551] [D loss: 0.025535] [G loss: 0.963120]\n",
      "[Epoch 0/1] [Batch 3305/3551] [D loss: 0.031344] [G loss: 0.977197]\n",
      "[Epoch 0/1] [Batch 3306/3551] [D loss: 0.028420] [G loss: 0.976817]\n",
      "[Epoch 0/1] [Batch 3307/3551] [D loss: 0.037990] [G loss: 0.974165]\n",
      "[Epoch 0/1] [Batch 3308/3551] [D loss: 0.022430] [G loss: 0.971137]\n",
      "[Epoch 0/1] [Batch 3309/3551] [D loss: 0.019242] [G loss: 0.975729]\n",
      "[Epoch 0/1] [Batch 3310/3551] [D loss: 0.020793] [G loss: 0.988975]\n",
      "[Epoch 0/1] [Batch 3311/3551] [D loss: 0.029617] [G loss: 0.977939]\n",
      "[Epoch 0/1] [Batch 3312/3551] [D loss: 0.028877] [G loss: 0.978936]\n",
      "[Epoch 0/1] [Batch 3313/3551] [D loss: 0.033280] [G loss: 0.979194]\n",
      "[Epoch 0/1] [Batch 3314/3551] [D loss: 0.026037] [G loss: 0.974498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 3315/3551] [D loss: 0.028016] [G loss: 0.981144]\n",
      "[Epoch 0/1] [Batch 3316/3551] [D loss: 0.026365] [G loss: 0.972915]\n",
      "[Epoch 0/1] [Batch 3317/3551] [D loss: 0.034938] [G loss: 0.982694]\n",
      "[Epoch 0/1] [Batch 3318/3551] [D loss: 0.046454] [G loss: 0.980873]\n",
      "[Epoch 0/1] [Batch 3319/3551] [D loss: 0.024508] [G loss: 0.986972]\n",
      "[Epoch 0/1] [Batch 3320/3551] [D loss: 0.022265] [G loss: 0.981737]\n",
      "[Epoch 0/1] [Batch 3321/3551] [D loss: 0.041419] [G loss: 0.992406]\n",
      "[Epoch 0/1] [Batch 3322/3551] [D loss: 0.045416] [G loss: 0.989479]\n",
      "[Epoch 0/1] [Batch 3323/3551] [D loss: 0.026219] [G loss: 0.980128]\n",
      "[Epoch 0/1] [Batch 3324/3551] [D loss: 0.018750] [G loss: 0.972111]\n",
      "[Epoch 0/1] [Batch 3325/3551] [D loss: 0.016355] [G loss: 0.966149]\n",
      "[Epoch 0/1] [Batch 3326/3551] [D loss: 0.027042] [G loss: 0.981969]\n",
      "[Epoch 0/1] [Batch 3327/3551] [D loss: 0.027814] [G loss: 0.976784]\n",
      "[Epoch 0/1] [Batch 3328/3551] [D loss: 0.024376] [G loss: 0.973093]\n",
      "[Epoch 0/1] [Batch 3329/3551] [D loss: 0.029665] [G loss: 0.979864]\n",
      "[Epoch 0/1] [Batch 3330/3551] [D loss: 0.024524] [G loss: 0.979162]\n",
      "[Epoch 0/1] [Batch 3331/3551] [D loss: 0.030260] [G loss: 0.984651]\n",
      "[Epoch 0/1] [Batch 3332/3551] [D loss: 0.016198] [G loss: 0.976049]\n",
      "[Epoch 0/1] [Batch 3333/3551] [D loss: 0.022689] [G loss: 0.982820]\n",
      "[Epoch 0/1] [Batch 3334/3551] [D loss: 0.025023] [G loss: 0.984954]\n",
      "[Epoch 0/1] [Batch 3335/3551] [D loss: 0.032748] [G loss: 0.978472]\n",
      "[Epoch 0/1] [Batch 3336/3551] [D loss: 0.027286] [G loss: 0.986639]\n",
      "[Epoch 0/1] [Batch 3337/3551] [D loss: 0.017913] [G loss: 0.978560]\n",
      "[Epoch 0/1] [Batch 3338/3551] [D loss: 0.031227] [G loss: 0.980102]\n",
      "[Epoch 0/1] [Batch 3339/3551] [D loss: 0.037781] [G loss: 0.968849]\n",
      "[Epoch 0/1] [Batch 3340/3551] [D loss: 0.037230] [G loss: 0.981228]\n",
      "[Epoch 0/1] [Batch 3341/3551] [D loss: 0.018628] [G loss: 0.981807]\n",
      "[Epoch 0/1] [Batch 3342/3551] [D loss: 0.024901] [G loss: 0.982990]\n",
      "[Epoch 0/1] [Batch 3343/3551] [D loss: 0.024262] [G loss: 0.981030]\n",
      "[Epoch 0/1] [Batch 3344/3551] [D loss: 0.029900] [G loss: 0.977965]\n",
      "[Epoch 0/1] [Batch 3345/3551] [D loss: 0.014859] [G loss: 0.990120]\n",
      "[Epoch 0/1] [Batch 3346/3551] [D loss: 0.015544] [G loss: 0.982247]\n",
      "[Epoch 0/1] [Batch 3347/3551] [D loss: 0.026119] [G loss: 0.975035]\n",
      "[Epoch 0/1] [Batch 3348/3551] [D loss: 0.020956] [G loss: 0.982323]\n",
      "[Epoch 0/1] [Batch 3349/3551] [D loss: 0.028587] [G loss: 0.982922]\n",
      "[Epoch 0/1] [Batch 3350/3551] [D loss: 0.019882] [G loss: 0.989840]\n",
      "[Epoch 0/1] [Batch 3351/3551] [D loss: 0.026161] [G loss: 0.983324]\n",
      "[Epoch 0/1] [Batch 3352/3551] [D loss: 0.024742] [G loss: 0.981964]\n",
      "[Epoch 0/1] [Batch 3353/3551] [D loss: 0.026144] [G loss: 0.986662]\n",
      "[Epoch 0/1] [Batch 3354/3551] [D loss: 0.017170] [G loss: 0.973093]\n",
      "[Epoch 0/1] [Batch 3355/3551] [D loss: 0.019662] [G loss: 0.984938]\n",
      "[Epoch 0/1] [Batch 3356/3551] [D loss: 0.020221] [G loss: 0.973951]\n",
      "[Epoch 0/1] [Batch 3357/3551] [D loss: 0.019657] [G loss: 0.983533]\n",
      "[Epoch 0/1] [Batch 3358/3551] [D loss: 0.026932] [G loss: 0.978917]\n",
      "[Epoch 0/1] [Batch 3359/3551] [D loss: 0.027130] [G loss: 0.982756]\n",
      "[Epoch 0/1] [Batch 3360/3551] [D loss: 0.033605] [G loss: 0.982505]\n",
      "[Epoch 0/1] [Batch 3361/3551] [D loss: 0.018276] [G loss: 0.974336]\n",
      "[Epoch 0/1] [Batch 3362/3551] [D loss: 0.027181] [G loss: 0.993204]\n",
      "[Epoch 0/1] [Batch 3363/3551] [D loss: 0.023217] [G loss: 0.976107]\n",
      "[Epoch 0/1] [Batch 3364/3551] [D loss: 0.017729] [G loss: 0.994488]\n",
      "[Epoch 0/1] [Batch 3365/3551] [D loss: 0.031223] [G loss: 0.991191]\n",
      "[Epoch 0/1] [Batch 3366/3551] [D loss: 0.028025] [G loss: 0.976757]\n",
      "[Epoch 0/1] [Batch 3367/3551] [D loss: 0.026048] [G loss: 0.981775]\n",
      "[Epoch 0/1] [Batch 3368/3551] [D loss: 0.026440] [G loss: 0.983535]\n",
      "[Epoch 0/1] [Batch 3369/3551] [D loss: 0.028412] [G loss: 0.982114]\n",
      "[Epoch 0/1] [Batch 3370/3551] [D loss: 0.029300] [G loss: 0.979653]\n",
      "[Epoch 0/1] [Batch 3371/3551] [D loss: 0.023294] [G loss: 0.978304]\n",
      "[Epoch 0/1] [Batch 3372/3551] [D loss: 0.026098] [G loss: 0.986858]\n",
      "[Epoch 0/1] [Batch 3373/3551] [D loss: 0.024791] [G loss: 0.977629]\n",
      "[Epoch 0/1] [Batch 3374/3551] [D loss: 0.032190] [G loss: 0.986686]\n",
      "[Epoch 0/1] [Batch 3375/3551] [D loss: 0.022538] [G loss: 0.976236]\n",
      "[Epoch 0/1] [Batch 3376/3551] [D loss: 0.030156] [G loss: 0.984481]\n",
      "[Epoch 0/1] [Batch 3377/3551] [D loss: 0.026453] [G loss: 0.979583]\n",
      "[Epoch 0/1] [Batch 3378/3551] [D loss: 0.033459] [G loss: 0.966087]\n",
      "[Epoch 0/1] [Batch 3379/3551] [D loss: 0.018373] [G loss: 0.982362]\n",
      "[Epoch 0/1] [Batch 3380/3551] [D loss: 0.034102] [G loss: 0.982086]\n",
      "[Epoch 0/1] [Batch 3381/3551] [D loss: 0.018505] [G loss: 0.983756]\n",
      "[Epoch 0/1] [Batch 3382/3551] [D loss: 0.017417] [G loss: 0.981660]\n",
      "[Epoch 0/1] [Batch 3383/3551] [D loss: 0.018813] [G loss: 0.982926]\n",
      "[Epoch 0/1] [Batch 3384/3551] [D loss: 0.019284] [G loss: 0.977296]\n",
      "[Epoch 0/1] [Batch 3385/3551] [D loss: 0.018728] [G loss: 0.977674]\n",
      "[Epoch 0/1] [Batch 3386/3551] [D loss: 0.022229] [G loss: 0.980241]\n",
      "[Epoch 0/1] [Batch 3387/3551] [D loss: 0.019884] [G loss: 0.987915]\n",
      "[Epoch 0/1] [Batch 3388/3551] [D loss: 0.019785] [G loss: 0.983435]\n",
      "[Epoch 0/1] [Batch 3389/3551] [D loss: 0.022805] [G loss: 0.985736]\n",
      "[Epoch 0/1] [Batch 3390/3551] [D loss: 0.021200] [G loss: 0.989716]\n",
      "[Epoch 0/1] [Batch 3391/3551] [D loss: 0.032248] [G loss: 0.975595]\n",
      "[Epoch 0/1] [Batch 3392/3551] [D loss: 0.024378] [G loss: 0.987403]\n",
      "[Epoch 0/1] [Batch 3393/3551] [D loss: 0.029875] [G loss: 0.979679]\n",
      "[Epoch 0/1] [Batch 3394/3551] [D loss: 0.030209] [G loss: 0.980721]\n",
      "[Epoch 0/1] [Batch 3395/3551] [D loss: 0.017564] [G loss: 0.984837]\n",
      "[Epoch 0/1] [Batch 3396/3551] [D loss: 0.014109] [G loss: 0.984376]\n",
      "[Epoch 0/1] [Batch 3397/3551] [D loss: 0.012132] [G loss: 0.986150]\n",
      "[Epoch 0/1] [Batch 3398/3551] [D loss: 0.022165] [G loss: 0.986296]\n",
      "[Epoch 0/1] [Batch 3399/3551] [D loss: 0.022320] [G loss: 0.985758]\n",
      "[Epoch 0/1] [Batch 3400/3551] [D loss: 0.031845] [G loss: 0.978252]\n",
      "[Epoch 0/1] [Batch 3401/3551] [D loss: 0.020343] [G loss: 0.986012]\n",
      "[Epoch 0/1] [Batch 3402/3551] [D loss: 0.024903] [G loss: 0.985699]\n",
      "[Epoch 0/1] [Batch 3403/3551] [D loss: 0.029211] [G loss: 0.979624]\n",
      "[Epoch 0/1] [Batch 3404/3551] [D loss: 0.028559] [G loss: 0.988930]\n",
      "[Epoch 0/1] [Batch 3405/3551] [D loss: 0.018619] [G loss: 0.988844]\n",
      "[Epoch 0/1] [Batch 3406/3551] [D loss: 0.024522] [G loss: 0.984582]\n",
      "[Epoch 0/1] [Batch 3407/3551] [D loss: 0.033348] [G loss: 0.981667]\n",
      "[Epoch 0/1] [Batch 3408/3551] [D loss: 0.019055] [G loss: 0.993644]\n",
      "[Epoch 0/1] [Batch 3409/3551] [D loss: 0.016971] [G loss: 0.984829]\n",
      "[Epoch 0/1] [Batch 3410/3551] [D loss: 0.025711] [G loss: 0.970385]\n",
      "[Epoch 0/1] [Batch 3411/3551] [D loss: 0.030295] [G loss: 0.980242]\n",
      "[Epoch 0/1] [Batch 3412/3551] [D loss: 0.018698] [G loss: 0.986962]\n",
      "[Epoch 0/1] [Batch 3413/3551] [D loss: 0.017620] [G loss: 0.983552]\n",
      "[Epoch 0/1] [Batch 3414/3551] [D loss: 0.028990] [G loss: 0.984035]\n",
      "[Epoch 0/1] [Batch 3415/3551] [D loss: 0.024909] [G loss: 0.986908]\n",
      "[Epoch 0/1] [Batch 3416/3551] [D loss: 0.021451] [G loss: 0.982448]\n",
      "[Epoch 0/1] [Batch 3417/3551] [D loss: 0.018622] [G loss: 0.964658]\n",
      "[Epoch 0/1] [Batch 3418/3551] [D loss: 0.043506] [G loss: 0.987548]\n",
      "[Epoch 0/1] [Batch 3419/3551] [D loss: 0.021465] [G loss: 0.980059]\n",
      "[Epoch 0/1] [Batch 3420/3551] [D loss: 0.026250] [G loss: 0.983666]\n",
      "[Epoch 0/1] [Batch 3421/3551] [D loss: 0.040214] [G loss: 0.975266]\n",
      "[Epoch 0/1] [Batch 3422/3551] [D loss: 0.024636] [G loss: 0.987695]\n",
      "[Epoch 0/1] [Batch 3423/3551] [D loss: 0.026600] [G loss: 0.982545]\n",
      "[Epoch 0/1] [Batch 3424/3551] [D loss: 0.020643] [G loss: 0.979953]\n",
      "[Epoch 0/1] [Batch 3425/3551] [D loss: 0.025527] [G loss: 0.980871]\n",
      "[Epoch 0/1] [Batch 3426/3551] [D loss: 0.028768] [G loss: 0.990620]\n",
      "[Epoch 0/1] [Batch 3427/3551] [D loss: 0.035002] [G loss: 0.986505]\n",
      "[Epoch 0/1] [Batch 3428/3551] [D loss: 0.043112] [G loss: 0.985519]\n",
      "[Epoch 0/1] [Batch 3429/3551] [D loss: 0.014989] [G loss: 0.989024]\n",
      "[Epoch 0/1] [Batch 3430/3551] [D loss: 0.018851] [G loss: 0.989581]\n",
      "[Epoch 0/1] [Batch 3431/3551] [D loss: 0.026969] [G loss: 0.985937]\n",
      "[Epoch 0/1] [Batch 3432/3551] [D loss: 0.018034] [G loss: 0.986023]\n",
      "[Epoch 0/1] [Batch 3433/3551] [D loss: 0.022637] [G loss: 0.978691]\n",
      "[Epoch 0/1] [Batch 3434/3551] [D loss: 0.021682] [G loss: 0.971455]\n",
      "[Epoch 0/1] [Batch 3435/3551] [D loss: 0.035647] [G loss: 0.981766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1] [Batch 3436/3551] [D loss: 0.029679] [G loss: 0.981486]\n",
      "[Epoch 0/1] [Batch 3437/3551] [D loss: 0.023073] [G loss: 0.977968]\n",
      "[Epoch 0/1] [Batch 3438/3551] [D loss: 0.018779] [G loss: 0.982092]\n",
      "[Epoch 0/1] [Batch 3439/3551] [D loss: 0.027989] [G loss: 0.988923]\n",
      "[Epoch 0/1] [Batch 3440/3551] [D loss: 0.023976] [G loss: 0.983960]\n",
      "[Epoch 0/1] [Batch 3441/3551] [D loss: 0.033306] [G loss: 0.993209]\n",
      "[Epoch 0/1] [Batch 3442/3551] [D loss: 0.028473] [G loss: 0.993029]\n",
      "[Epoch 0/1] [Batch 3443/3551] [D loss: 0.032835] [G loss: 0.981339]\n",
      "[Epoch 0/1] [Batch 3444/3551] [D loss: 0.040709] [G loss: 0.985528]\n",
      "[Epoch 0/1] [Batch 3445/3551] [D loss: 0.035225] [G loss: 0.983149]\n",
      "[Epoch 0/1] [Batch 3446/3551] [D loss: 0.029992] [G loss: 0.982123]\n",
      "[Epoch 0/1] [Batch 3447/3551] [D loss: 0.029461] [G loss: 0.985182]\n",
      "[Epoch 0/1] [Batch 3448/3551] [D loss: 0.019005] [G loss: 0.980637]\n",
      "[Epoch 0/1] [Batch 3449/3551] [D loss: 0.024844] [G loss: 0.978543]\n",
      "[Epoch 0/1] [Batch 3450/3551] [D loss: 0.023676] [G loss: 0.984492]\n",
      "[Epoch 0/1] [Batch 3451/3551] [D loss: 0.024219] [G loss: 0.965870]\n",
      "[Epoch 0/1] [Batch 3452/3551] [D loss: 0.025098] [G loss: 0.979522]\n",
      "[Epoch 0/1] [Batch 3453/3551] [D loss: 0.027804] [G loss: 0.979271]\n",
      "[Epoch 0/1] [Batch 3454/3551] [D loss: 0.025441] [G loss: 0.979298]\n",
      "[Epoch 0/1] [Batch 3455/3551] [D loss: 0.028906] [G loss: 0.988332]\n",
      "[Epoch 0/1] [Batch 3456/3551] [D loss: 0.016315] [G loss: 0.979505]\n",
      "[Epoch 0/1] [Batch 3457/3551] [D loss: 0.024690] [G loss: 0.986271]\n",
      "[Epoch 0/1] [Batch 3458/3551] [D loss: 0.018908] [G loss: 0.984213]\n",
      "[Epoch 0/1] [Batch 3459/3551] [D loss: 0.026094] [G loss: 0.984649]\n",
      "[Epoch 0/1] [Batch 3460/3551] [D loss: 0.030906] [G loss: 0.979365]\n",
      "[Epoch 0/1] [Batch 3461/3551] [D loss: 0.030136] [G loss: 0.983570]\n",
      "[Epoch 0/1] [Batch 3462/3551] [D loss: 0.021128] [G loss: 0.978907]\n",
      "[Epoch 0/1] [Batch 3463/3551] [D loss: 0.023322] [G loss: 0.980939]\n",
      "[Epoch 0/1] [Batch 3464/3551] [D loss: 0.026485] [G loss: 0.980788]\n",
      "[Epoch 0/1] [Batch 3465/3551] [D loss: 0.026547] [G loss: 0.974280]\n",
      "[Epoch 0/1] [Batch 3466/3551] [D loss: 0.030195] [G loss: 0.975954]\n",
      "[Epoch 0/1] [Batch 3467/3551] [D loss: 0.016626] [G loss: 0.990549]\n",
      "[Epoch 0/1] [Batch 3468/3551] [D loss: 0.022627] [G loss: 0.983549]\n",
      "[Epoch 0/1] [Batch 3469/3551] [D loss: 0.016997] [G loss: 0.969417]\n",
      "[Epoch 0/1] [Batch 3470/3551] [D loss: 0.029942] [G loss: 0.971299]\n",
      "[Epoch 0/1] [Batch 3471/3551] [D loss: 0.021915] [G loss: 0.979731]\n",
      "[Epoch 0/1] [Batch 3472/3551] [D loss: 0.021957] [G loss: 0.974493]\n",
      "[Epoch 0/1] [Batch 3473/3551] [D loss: 0.028365] [G loss: 0.980805]\n",
      "[Epoch 0/1] [Batch 3474/3551] [D loss: 0.021994] [G loss: 0.974390]\n",
      "[Epoch 0/1] [Batch 3475/3551] [D loss: 0.019544] [G loss: 0.973692]\n",
      "[Epoch 0/1] [Batch 3476/3551] [D loss: 0.016165] [G loss: 0.978679]\n",
      "[Epoch 0/1] [Batch 3477/3551] [D loss: 0.032620] [G loss: 0.980588]\n",
      "[Epoch 0/1] [Batch 3478/3551] [D loss: 0.019778] [G loss: 0.970796]\n",
      "[Epoch 0/1] [Batch 3479/3551] [D loss: 0.023854] [G loss: 0.989221]\n",
      "[Epoch 0/1] [Batch 3480/3551] [D loss: 0.030310] [G loss: 0.982422]\n",
      "[Epoch 0/1] [Batch 3481/3551] [D loss: 0.019355] [G loss: 0.970656]\n",
      "[Epoch 0/1] [Batch 3482/3551] [D loss: 0.021841] [G loss: 0.980203]\n",
      "[Epoch 0/1] [Batch 3483/3551] [D loss: 0.031698] [G loss: 0.975391]\n",
      "[Epoch 0/1] [Batch 3484/3551] [D loss: 0.013363] [G loss: 0.969962]\n",
      "[Epoch 0/1] [Batch 3485/3551] [D loss: 0.018075] [G loss: 0.975944]\n",
      "[Epoch 0/1] [Batch 3486/3551] [D loss: 0.027666] [G loss: 0.979774]\n",
      "[Epoch 0/1] [Batch 3487/3551] [D loss: 0.017893] [G loss: 0.974356]\n",
      "[Epoch 0/1] [Batch 3488/3551] [D loss: 0.027395] [G loss: 0.987797]\n",
      "[Epoch 0/1] [Batch 3489/3551] [D loss: 0.022850] [G loss: 0.985470]\n",
      "[Epoch 0/1] [Batch 3490/3551] [D loss: 0.027219] [G loss: 0.973625]\n",
      "[Epoch 0/1] [Batch 3491/3551] [D loss: 0.033163] [G loss: 0.979021]\n",
      "[Epoch 0/1] [Batch 3492/3551] [D loss: 0.030105] [G loss: 0.965284]\n",
      "[Epoch 0/1] [Batch 3493/3551] [D loss: 0.024449] [G loss: 0.977392]\n",
      "[Epoch 0/1] [Batch 3494/3551] [D loss: 0.030530] [G loss: 0.975625]\n",
      "[Epoch 0/1] [Batch 3495/3551] [D loss: 0.022849] [G loss: 0.974320]\n",
      "[Epoch 0/1] [Batch 3496/3551] [D loss: 0.029633] [G loss: 0.982023]\n",
      "[Epoch 0/1] [Batch 3497/3551] [D loss: 0.037498] [G loss: 0.985509]\n",
      "[Epoch 0/1] [Batch 3498/3551] [D loss: 0.030224] [G loss: 0.974858]\n",
      "[Epoch 0/1] [Batch 3499/3551] [D loss: 0.030187] [G loss: 0.992691]\n",
      "[Epoch 0/1] [Batch 3500/3551] [D loss: 0.033065] [G loss: 0.979718]\n",
      "[Epoch 0/1] [Batch 3501/3551] [D loss: 0.020902] [G loss: 0.979170]\n",
      "[Epoch 0/1] [Batch 3502/3551] [D loss: 0.024810] [G loss: 0.973133]\n",
      "[Epoch 0/1] [Batch 3503/3551] [D loss: 0.039556] [G loss: 0.968510]\n",
      "[Epoch 0/1] [Batch 3504/3551] [D loss: 0.015083] [G loss: 0.980035]\n",
      "[Epoch 0/1] [Batch 3505/3551] [D loss: 0.024078] [G loss: 0.979466]\n",
      "[Epoch 0/1] [Batch 3506/3551] [D loss: 0.018903] [G loss: 0.987519]\n",
      "[Epoch 0/1] [Batch 3507/3551] [D loss: 0.023755] [G loss: 0.978620]\n",
      "[Epoch 0/1] [Batch 3508/3551] [D loss: 0.020995] [G loss: 0.978568]\n",
      "[Epoch 0/1] [Batch 3509/3551] [D loss: 0.027327] [G loss: 0.982258]\n",
      "[Epoch 0/1] [Batch 3510/3551] [D loss: 0.017280] [G loss: 0.986079]\n",
      "[Epoch 0/1] [Batch 3511/3551] [D loss: 0.018028] [G loss: 0.969279]\n",
      "[Epoch 0/1] [Batch 3512/3551] [D loss: 0.021083] [G loss: 0.979072]\n",
      "[Epoch 0/1] [Batch 3513/3551] [D loss: 0.017022] [G loss: 0.982322]\n",
      "[Epoch 0/1] [Batch 3514/3551] [D loss: 0.028186] [G loss: 0.985500]\n",
      "[Epoch 0/1] [Batch 3515/3551] [D loss: 0.028275] [G loss: 0.961403]\n",
      "[Epoch 0/1] [Batch 3516/3551] [D loss: 0.019270] [G loss: 0.993126]\n",
      "[Epoch 0/1] [Batch 3517/3551] [D loss: 0.021440] [G loss: 0.987621]\n",
      "[Epoch 0/1] [Batch 3518/3551] [D loss: 0.028560] [G loss: 0.993262]\n",
      "[Epoch 0/1] [Batch 3519/3551] [D loss: 0.018708] [G loss: 0.983313]\n",
      "[Epoch 0/1] [Batch 3520/3551] [D loss: 0.017390] [G loss: 0.985151]\n",
      "[Epoch 0/1] [Batch 3521/3551] [D loss: 0.036212] [G loss: 0.981080]\n",
      "[Epoch 0/1] [Batch 3522/3551] [D loss: 0.025410] [G loss: 0.982734]\n",
      "[Epoch 0/1] [Batch 3523/3551] [D loss: 0.029414] [G loss: 0.979104]\n",
      "[Epoch 0/1] [Batch 3524/3551] [D loss: 0.026986] [G loss: 0.973377]\n",
      "[Epoch 0/1] [Batch 3525/3551] [D loss: 0.021070] [G loss: 0.986444]\n",
      "[Epoch 0/1] [Batch 3526/3551] [D loss: 0.024483] [G loss: 0.979426]\n",
      "[Epoch 0/1] [Batch 3527/3551] [D loss: 0.022743] [G loss: 0.979703]\n",
      "[Epoch 0/1] [Batch 3528/3551] [D loss: 0.020664] [G loss: 0.977759]\n",
      "[Epoch 0/1] [Batch 3529/3551] [D loss: 0.023980] [G loss: 0.982708]\n",
      "[Epoch 0/1] [Batch 3530/3551] [D loss: 0.009004] [G loss: 0.980856]\n",
      "[Epoch 0/1] [Batch 3531/3551] [D loss: 0.031292] [G loss: 0.982900]\n",
      "[Epoch 0/1] [Batch 3532/3551] [D loss: 0.029348] [G loss: 0.984942]\n",
      "[Epoch 0/1] [Batch 3533/3551] [D loss: 0.016777] [G loss: 0.981230]\n",
      "[Epoch 0/1] [Batch 3534/3551] [D loss: 0.026200] [G loss: 0.981592]\n",
      "[Epoch 0/1] [Batch 3535/3551] [D loss: 0.033077] [G loss: 0.976282]\n",
      "[Epoch 0/1] [Batch 3536/3551] [D loss: 0.018111] [G loss: 0.979402]\n",
      "[Epoch 0/1] [Batch 3537/3551] [D loss: 0.025191] [G loss: 0.990521]\n",
      "[Epoch 0/1] [Batch 3538/3551] [D loss: 0.019441] [G loss: 0.978121]\n",
      "[Epoch 0/1] [Batch 3539/3551] [D loss: 0.016140] [G loss: 0.991112]\n",
      "[Epoch 0/1] [Batch 3540/3551] [D loss: 0.022884] [G loss: 0.972898]\n",
      "[Epoch 0/1] [Batch 3541/3551] [D loss: 0.025208] [G loss: 0.988000]\n",
      "[Epoch 0/1] [Batch 3542/3551] [D loss: 0.024181] [G loss: 0.981726]\n",
      "[Epoch 0/1] [Batch 3543/3551] [D loss: 0.034017] [G loss: 0.975092]\n",
      "[Epoch 0/1] [Batch 3544/3551] [D loss: 0.017464] [G loss: 0.971160]\n",
      "[Epoch 0/1] [Batch 3545/3551] [D loss: 0.016813] [G loss: 0.980316]\n",
      "[Epoch 0/1] [Batch 3546/3551] [D loss: 0.015729] [G loss: 0.991066]\n",
      "[Epoch 0/1] [Batch 3547/3551] [D loss: 0.015423] [G loss: 0.995668]\n",
      "[Epoch 0/1] [Batch 3548/3551] [D loss: 0.023319] [G loss: 0.986097]\n",
      "[Epoch 0/1] [Batch 3549/3551] [D loss: 0.027846] [G loss: 0.993092]\n",
      "[Epoch 0/1] [Batch 3550/3551] [D loss: 0.033172] [G loss: 0.988984]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        batch_size = len(imgs)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "        \n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor)) # 32x794\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, 1, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminator(gen_imgs, gen_labels)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        validity_real = discriminator(real_imgs, labels)\n",
    "        d_real_loss = adversarial_loss(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n",
    "        d_fake_loss = adversarial_loss(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, 1, i, len(dataloader),\n",
    "                                                            d_loss.item(), g_loss.item()))\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'generator': generator.model.state_dict(),\n",
    "            'discriminator': discriminator.model.state_dict(),\n",
    "            'optimizer_gen': optimizer_G.state_dict(),\n",
    "            'optimizer_dis': optimizer_D.state_dict(),\n",
    "            'G_loss': g_loss.item(),\n",
    "            'D_loss': d_loss.item()\n",
    "            }, 'saved_models/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "    m = model\n",
    "    m.load_state_dict(torch.load(path), strict=False)\n",
    "    return m.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quick Draw venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
